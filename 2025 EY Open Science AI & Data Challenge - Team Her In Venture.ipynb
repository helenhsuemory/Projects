{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bfb2ab5-5a0a-4ac7-92c9-082cc7c20002",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2025 EY Open Science AI & Data Challenge - Team Her In Venture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b48e8e0-5ead-4762-aed8-db19224f8082",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. Sentinel-2 Satellite Data Extraction\n",
    "We extracted Sentinel-2 satellite data to GeoTIFF file that is suitable for further analysis and can also be used to generate spectral index products using mathematical combinations of bands, such as NDVI. The baseline data is [Sentinel-2 Level-2A](https://planetarycomputer.microsoft.com/dataset/sentinel-2-l2a) data from the MS Planetary Computer catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a9ce65-407f-4525-bdaa-e9ea90a43541",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1.1 Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb36408-2072-46c0-8101-7fac7e3be2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import common GIS tools\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray as rio\n",
    "import rasterio\n",
    "from matplotlib.cm import RdYlGn,jet,RdBu\n",
    "\n",
    "# Import Planetary Computer tools\n",
    "import stackstac\n",
    "import pystac_client\n",
    "import planetary_computer \n",
    "from odc.stac import stac_load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9238de8-1b9d-4781-bc9e-3a32e52033d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2 Discover and load the data for analysis\n",
    "\n",
    "First, we defined our area of interest using latitude and longitude coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fc1642d-9e4b-4ba4-be2b-036b914f18a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bounding box for the entire data region using (Latitude, Longitude)\n",
    "# This is the region of New York City that contains our temperature dataset\n",
    "lower_left = (40.75, -74.01)\n",
    "upper_right = (40.88, -73.86)\n",
    "\n",
    "# Calculate the bounds for doing an archive data search\n",
    "# bounds = (min_lon, min_lat, max_lon, max_lat)\n",
    "bounds = (lower_left[1], lower_left[0], upper_right[1], upper_right[0])\n",
    "\n",
    "# Define the time window\n",
    "time_window = \"2021-06-01/2021-09-01\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03fe32e-86c6-4eec-9696-7a4b28bb1e50",
   "metadata": {},
   "source": [
    "Using the `pystac_client`, we searched the Planetary Computer's STAC endpoint for items matching our query parameters. We used a period of 3 months as a representative dataset for the region. The query searched for \"low cloud\" scenes with overall cloud cover <30%. The result is the number of scenes matching our search criteria that touch our area of interest. Some of these may be partial scenes or contain clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e252e3bf-83a4-4243-b394-d407713a7d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of scenes that touch our region: 10\n"
     ]
    }
   ],
   "source": [
    "stac = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "\n",
    "search = stac.search(\n",
    "    bbox=bounds, \n",
    "    datetime=time_window,\n",
    "    collections=[\"sentinel-2-l2a\"],\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 30}},\n",
    ")\n",
    "\n",
    "items = list(search.get_items())\n",
    "print('This is the number of scenes that touch our region:',len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca7675e2-7f43-4b13-910b-8736b90cb10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "signed_items = [planetary_computer.sign(item).to_dict() for item in items]\n",
    "\n",
    "# Define the pixel resolution for the final product\n",
    "# Define the scale according to our selected crs, so we will use degrees\n",
    "resolution = 10  # meters per pixel \n",
    "scale = resolution / 111320.0 # degrees per pixel for crs=4326 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38508d17-ebbd-4949-85e6-81882b9c0458",
   "metadata": {},
   "source": [
    "Next, we loaded the data into an [xarray](https://xarray.pydata.org/en/stable/) DataArray using [stackstac](https://stackstac.readthedocs.io/). We only kept the commonly used spectral bands (Red, Green, Blue, NIR, SWIR). There are also several other <b>important settings for the data</b>: We have changed the projection to epsg=4326 which is standard latitude-longitude in degrees. We have specified the spatial resolution of each pixel to be 10-meters. \n",
    "\n",
    "#### Sentinel-2 Bands Summary \n",
    "The following list of common bands can be loaded by the Open Data Cube (ODC) stac command.<br><br>\n",
    "B01 = Coastal Aerosol = 60m <br>\n",
    "B02 = Blue = 10m <br>\n",
    "B03 = Green = 10m <br>\n",
    "B04 = Red = 10m <br>\n",
    "B05 = Red Edge (704 nm) = 20m <br>\n",
    "B06 = Red Edge (740 nm) = 20m <br>\n",
    "B07 = Red Edge (780 nm) = 20m <br>\n",
    "B08 = NIR (833 nm) = 10m <br>\n",
    "B8A = NIR (narrow 864 nm) = 20m <br>\n",
    "B11 = SWIR (1.6 um) = 20m <br>\n",
    "B12 = SWIR (2.2 um) = 20m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35aa09fb-3c33-44dd-b517-afcadc1c2fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "html[data-theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 532MB\n",
       "Dimensions:      (latitude: 1448, longitude: 1671, time: 10)\n",
       "Coordinates:\n",
       "  * latitude     (latitude) float64 12kB 40.88 40.88 40.88 ... 40.75 40.75 40.75\n",
       "  * longitude    (longitude) float64 13kB -74.01 -74.01 -74.01 ... -73.86 -73.86\n",
       "    spatial_ref  int32 4B 4326\n",
       "  * time         (time) datetime64[ns] 80B 2021-06-06T15:38:09.024000 ... 202...\n",
       "Data variables:\n",
       "    B01          (time, latitude, longitude) uint16 48MB dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;\n",
       "    B02          (time, latitude, longitude) uint16 48MB dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;\n",
       "    B03          (time, latitude, longitude) uint16 48MB dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;\n",
       "    B04          (time, latitude, longitude) uint16 48MB dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;\n",
       "    B05          (time, latitude, longitude) uint16 48MB dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;\n",
       "    B06          (time, latitude, longitude) uint16 48MB dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;\n",
       "    B07          (time, latitude, longitude) uint16 48MB dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;\n",
       "    B08          (time, latitude, longitude) uint16 48MB dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;\n",
       "    B8A          (time, latitude, longitude) uint16 48MB dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;\n",
       "    B11          (time, latitude, longitude) uint16 48MB dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;\n",
       "    B12          (time, latitude, longitude) uint16 48MB dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-27fe6da1-0f68-4867-87e9-b2905a2db8f7' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-27fe6da1-0f68-4867-87e9-b2905a2db8f7' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>latitude</span>: 1448</li><li><span class='xr-has-index'>longitude</span>: 1671</li><li><span class='xr-has-index'>time</span>: 10</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-3ba466f5-197f-4399-9e0b-68650e312df5' class='xr-section-summary-in' type='checkbox'  checked><label for='section-3ba466f5-197f-4399-9e0b-68650e312df5' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>latitude</span></div><div class='xr-var-dims'>(latitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>40.88 40.88 40.88 ... 40.75 40.75</div><input id='attrs-a4190d03-7976-4f30-ae5c-9bf74eaac596' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-a4190d03-7976-4f30-ae5c-9bf74eaac596' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-8b1afa54-3840-4057-89e7-8eb6e70ab8b4' class='xr-var-data-in' type='checkbox'><label for='data-8b1afa54-3840-4057-89e7-8eb6e70ab8b4' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>resolution :</span></dt><dd>-8.983111749910169e-05</dd><dt><span>crs :</span></dt><dd>EPSG:4326</dd></dl></div><div class='xr-var-data'><pre>array([40.880031, 40.879941, 40.879851, ..., 40.750225, 40.750135, 40.750045])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>longitude</span></div><div class='xr-var-dims'>(longitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-74.01 -74.01 ... -73.86 -73.86</div><input id='attrs-4cb34841-aa62-415f-8e51-5ec610159d5b' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-4cb34841-aa62-415f-8e51-5ec610159d5b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-7400ac44-8f53-4fb7-aaf0-00ed8cc1d5a8' class='xr-var-data-in' type='checkbox'><label for='data-7400ac44-8f53-4fb7-aaf0-00ed8cc1d5a8' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>resolution :</span></dt><dd>8.983111749910169e-05</dd><dt><span>crs :</span></dt><dd>EPSG:4326</dd></dl></div><div class='xr-var-data'><pre>array([-74.010016, -74.009926, -74.009837, ..., -73.860178, -73.860088,\n",
       "       -73.859998])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>spatial_ref</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>4326</div><input id='attrs-d2efb832-5cc5-468f-aa9e-17dd83d7d868' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-d2efb832-5cc5-468f-aa9e-17dd83d7d868' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-8dba318f-b2f8-4818-8ca9-3b65fe32e7e4' class='xr-var-data-in' type='checkbox'><label for='data-8dba318f-b2f8-4818-8ca9-3b65fe32e7e4' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>spatial_ref :</span></dt><dd>GEOGCRS[&quot;WGS 84&quot;,ENSEMBLE[&quot;World Geodetic System 1984 ensemble&quot;,MEMBER[&quot;World Geodetic System 1984 (Transit)&quot;],MEMBER[&quot;World Geodetic System 1984 (G730)&quot;],MEMBER[&quot;World Geodetic System 1984 (G873)&quot;],MEMBER[&quot;World Geodetic System 1984 (G1150)&quot;],MEMBER[&quot;World Geodetic System 1984 (G1674)&quot;],MEMBER[&quot;World Geodetic System 1984 (G1762)&quot;],MEMBER[&quot;World Geodetic System 1984 (G2139)&quot;],ELLIPSOID[&quot;WGS 84&quot;,6378137,298.257223563,LENGTHUNIT[&quot;metre&quot;,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[&quot;Greenwich&quot;,0,ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],CS[ellipsoidal,2],AXIS[&quot;geodetic latitude (Lat)&quot;,north,ORDER[1],ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],AXIS[&quot;geodetic longitude (Lon)&quot;,east,ORDER[2],ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],USAGE[SCOPE[&quot;Horizontal component of 3D system.&quot;],AREA[&quot;World.&quot;],BBOX[-90,-180,90,180]],ID[&quot;EPSG&quot;,4326]]</dd><dt><span>crs_wkt :</span></dt><dd>GEOGCRS[&quot;WGS 84&quot;,ENSEMBLE[&quot;World Geodetic System 1984 ensemble&quot;,MEMBER[&quot;World Geodetic System 1984 (Transit)&quot;],MEMBER[&quot;World Geodetic System 1984 (G730)&quot;],MEMBER[&quot;World Geodetic System 1984 (G873)&quot;],MEMBER[&quot;World Geodetic System 1984 (G1150)&quot;],MEMBER[&quot;World Geodetic System 1984 (G1674)&quot;],MEMBER[&quot;World Geodetic System 1984 (G1762)&quot;],MEMBER[&quot;World Geodetic System 1984 (G2139)&quot;],ELLIPSOID[&quot;WGS 84&quot;,6378137,298.257223563,LENGTHUNIT[&quot;metre&quot;,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[&quot;Greenwich&quot;,0,ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],CS[ellipsoidal,2],AXIS[&quot;geodetic latitude (Lat)&quot;,north,ORDER[1],ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],AXIS[&quot;geodetic longitude (Lon)&quot;,east,ORDER[2],ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],USAGE[SCOPE[&quot;Horizontal component of 3D system.&quot;],AREA[&quot;World.&quot;],BBOX[-90,-180,90,180]],ID[&quot;EPSG&quot;,4326]]</dd><dt><span>semi_major_axis :</span></dt><dd>6378137.0</dd><dt><span>semi_minor_axis :</span></dt><dd>6356752.314245179</dd><dt><span>inverse_flattening :</span></dt><dd>298.257223563</dd><dt><span>reference_ellipsoid_name :</span></dt><dd>WGS 84</dd><dt><span>longitude_of_prime_meridian :</span></dt><dd>0.0</dd><dt><span>prime_meridian_name :</span></dt><dd>Greenwich</dd><dt><span>geographic_crs_name :</span></dt><dd>WGS 84</dd><dt><span>horizontal_datum_name :</span></dt><dd>World Geodetic System 1984 ensemble</dd><dt><span>grid_mapping_name :</span></dt><dd>latitude_longitude</dd><dt><span>GeoTransform :</span></dt><dd>-74.010061085159904337160697 0.00008983111749910169014 0 40.880075458138698252241738 0 -0.00008983111749910169014</dd></dl></div><div class='xr-var-data'><pre>array(4326, dtype=int32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2021-06-06T15:38:09.024000 ... 2...</div><input id='attrs-548a1271-7dd7-4828-9f6e-b2e299dfa945' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-548a1271-7dd7-4828-9f6e-b2e299dfa945' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-fa31b837-c78a-40bd-bd9e-21d8c6a7cc92' class='xr-var-data-in' type='checkbox'><label for='data-fa31b837-c78a-40bd-bd9e-21d8c6a7cc92' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2021-06-06T15:38:09.024000000&#x27;, &#x27;2021-06-16T15:38:09.024000000&#x27;,\n",
       "       &#x27;2021-06-24T15:49:11.024000000&#x27;, &#x27;2021-06-29T15:48:09.024000000&#x27;,\n",
       "       &#x27;2021-07-06T15:38:09.024000000&#x27;, &#x27;2021-07-14T15:49:11.024000000&#x27;,\n",
       "       &#x27;2021-07-16T15:38:09.024000000&#x27;, &#x27;2021-07-24T15:49:11.024000000&#x27;,\n",
       "       &#x27;2021-07-31T15:39:11.024000000&#x27;, &#x27;2021-08-13T15:49:11.024000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-75122401-2b25-4b3d-a7ea-5d96611bc2a1' class='xr-section-summary-in' type='checkbox'  checked><label for='section-75122401-2b25-4b3d-a7ea-5d96611bc2a1' class='xr-section-summary' >Data variables: <span>(11)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>B01</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>uint16</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;</div><input id='attrs-1d1f575b-1a4f-4b0a-893c-19f01a02a942' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-1d1f575b-1a4f-4b0a-893c-19f01a02a942' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4b87d1a2-dc3b-4848-833f-bf7e4ce584e1' class='xr-var-data-in' type='checkbox'><label for='data-4b87d1a2-dc3b-4848-833f-bf7e4ce584e1' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 46.15 MiB </td>\n",
       "                        <td> 4.62 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (10, 1448, 1671) </td>\n",
       "                        <td> (1, 1448, 1671) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 10 chunks in 3 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> uint16 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"194\" height=\"168\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"103\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"103\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"11\" y2=\"105\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"106\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"14\" y2=\"108\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"15\" y2=\"109\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"111\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"112\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"114\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"21\" y2=\"115\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"117\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 24.9485979497544,14.948597949754403 24.9485979497544,118.93423529266285 10.0,103.98563734290845\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"131\" y2=\"1\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"134\" y2=\"4\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"135\" y2=\"5\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"137\" y2=\"7\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"138\" y2=\"8\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"141\" y2=\"11\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"143\" y2=\"13\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 144.9485979497544,14.948597949754403 24.9485979497544,14.948597949754403\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"24\" y1=\"118\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"144\" y1=\"14\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"24.9485979497544,14.948597949754403 144.9485979497544,14.948597949754403 144.9485979497544,118.93423529266285 24.9485979497544,118.93423529266285\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"84.948598\" y=\"138.934235\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1671</text>\n",
       "  <text x=\"164.948598\" y=\"66.941417\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,164.948598,66.941417)\">1448</text>\n",
       "  <text x=\"7.474299\" y=\"131.459936\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,7.474299,131.459936)\">10</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>B02</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>uint16</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;</div><input id='attrs-6e690d53-d5d4-44cc-909b-3b885c399b93' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-6e690d53-d5d4-44cc-909b-3b885c399b93' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e01f515c-835e-483a-84d9-aa24897362fc' class='xr-var-data-in' type='checkbox'><label for='data-e01f515c-835e-483a-84d9-aa24897362fc' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 46.15 MiB </td>\n",
       "                        <td> 4.62 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (10, 1448, 1671) </td>\n",
       "                        <td> (1, 1448, 1671) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 10 chunks in 3 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> uint16 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"194\" height=\"168\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"103\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"103\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"11\" y2=\"105\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"106\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"14\" y2=\"108\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"15\" y2=\"109\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"111\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"112\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"114\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"21\" y2=\"115\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"117\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 24.9485979497544,14.948597949754403 24.9485979497544,118.93423529266285 10.0,103.98563734290845\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"131\" y2=\"1\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"134\" y2=\"4\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"135\" y2=\"5\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"137\" y2=\"7\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"138\" y2=\"8\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"141\" y2=\"11\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"143\" y2=\"13\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 144.9485979497544,14.948597949754403 24.9485979497544,14.948597949754403\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"24\" y1=\"118\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"144\" y1=\"14\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"24.9485979497544,14.948597949754403 144.9485979497544,14.948597949754403 144.9485979497544,118.93423529266285 24.9485979497544,118.93423529266285\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"84.948598\" y=\"138.934235\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1671</text>\n",
       "  <text x=\"164.948598\" y=\"66.941417\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,164.948598,66.941417)\">1448</text>\n",
       "  <text x=\"7.474299\" y=\"131.459936\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,7.474299,131.459936)\">10</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>B03</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>uint16</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;</div><input id='attrs-3a2e2f22-c472-4ee0-a635-ac0bf241d64c' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-3a2e2f22-c472-4ee0-a635-ac0bf241d64c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-5bfa6b31-c14a-4902-9db5-afeaf91005ec' class='xr-var-data-in' type='checkbox'><label for='data-5bfa6b31-c14a-4902-9db5-afeaf91005ec' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 46.15 MiB </td>\n",
       "                        <td> 4.62 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (10, 1448, 1671) </td>\n",
       "                        <td> (1, 1448, 1671) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 10 chunks in 3 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> uint16 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"194\" height=\"168\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"103\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"103\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"11\" y2=\"105\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"106\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"14\" y2=\"108\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"15\" y2=\"109\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"111\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"112\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"114\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"21\" y2=\"115\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"117\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 24.9485979497544,14.948597949754403 24.9485979497544,118.93423529266285 10.0,103.98563734290845\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"131\" y2=\"1\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"134\" y2=\"4\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"135\" y2=\"5\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"137\" y2=\"7\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"138\" y2=\"8\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"141\" y2=\"11\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"143\" y2=\"13\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 144.9485979497544,14.948597949754403 24.9485979497544,14.948597949754403\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"24\" y1=\"118\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"144\" y1=\"14\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"24.9485979497544,14.948597949754403 144.9485979497544,14.948597949754403 144.9485979497544,118.93423529266285 24.9485979497544,118.93423529266285\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"84.948598\" y=\"138.934235\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1671</text>\n",
       "  <text x=\"164.948598\" y=\"66.941417\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,164.948598,66.941417)\">1448</text>\n",
       "  <text x=\"7.474299\" y=\"131.459936\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,7.474299,131.459936)\">10</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>B04</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>uint16</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;</div><input id='attrs-b3695bc1-4709-4447-b713-fea0bbdd6477' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-b3695bc1-4709-4447-b713-fea0bbdd6477' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-9f3de891-a1fd-48fd-baba-96b31b6aa668' class='xr-var-data-in' type='checkbox'><label for='data-9f3de891-a1fd-48fd-baba-96b31b6aa668' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 46.15 MiB </td>\n",
       "                        <td> 4.62 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (10, 1448, 1671) </td>\n",
       "                        <td> (1, 1448, 1671) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 10 chunks in 3 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> uint16 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"194\" height=\"168\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"103\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"103\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"11\" y2=\"105\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"106\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"14\" y2=\"108\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"15\" y2=\"109\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"111\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"112\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"114\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"21\" y2=\"115\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"117\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 24.9485979497544,14.948597949754403 24.9485979497544,118.93423529266285 10.0,103.98563734290845\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"131\" y2=\"1\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"134\" y2=\"4\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"135\" y2=\"5\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"137\" y2=\"7\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"138\" y2=\"8\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"141\" y2=\"11\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"143\" y2=\"13\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 144.9485979497544,14.948597949754403 24.9485979497544,14.948597949754403\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"24\" y1=\"118\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"144\" y1=\"14\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"24.9485979497544,14.948597949754403 144.9485979497544,14.948597949754403 144.9485979497544,118.93423529266285 24.9485979497544,118.93423529266285\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"84.948598\" y=\"138.934235\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1671</text>\n",
       "  <text x=\"164.948598\" y=\"66.941417\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,164.948598,66.941417)\">1448</text>\n",
       "  <text x=\"7.474299\" y=\"131.459936\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,7.474299,131.459936)\">10</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>B05</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>uint16</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;</div><input id='attrs-47d274c5-ee44-43ec-9492-4e90fde31297' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-47d274c5-ee44-43ec-9492-4e90fde31297' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ef0fbb94-faed-46aa-9858-86334ebf969b' class='xr-var-data-in' type='checkbox'><label for='data-ef0fbb94-faed-46aa-9858-86334ebf969b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 46.15 MiB </td>\n",
       "                        <td> 4.62 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (10, 1448, 1671) </td>\n",
       "                        <td> (1, 1448, 1671) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 10 chunks in 3 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> uint16 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"194\" height=\"168\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"103\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"103\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"11\" y2=\"105\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"106\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"14\" y2=\"108\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"15\" y2=\"109\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"111\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"112\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"114\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"21\" y2=\"115\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"117\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 24.9485979497544,14.948597949754403 24.9485979497544,118.93423529266285 10.0,103.98563734290845\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"131\" y2=\"1\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"134\" y2=\"4\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"135\" y2=\"5\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"137\" y2=\"7\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"138\" y2=\"8\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"141\" y2=\"11\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"143\" y2=\"13\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 144.9485979497544,14.948597949754403 24.9485979497544,14.948597949754403\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"24\" y1=\"118\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"144\" y1=\"14\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"24.9485979497544,14.948597949754403 144.9485979497544,14.948597949754403 144.9485979497544,118.93423529266285 24.9485979497544,118.93423529266285\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"84.948598\" y=\"138.934235\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1671</text>\n",
       "  <text x=\"164.948598\" y=\"66.941417\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,164.948598,66.941417)\">1448</text>\n",
       "  <text x=\"7.474299\" y=\"131.459936\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,7.474299,131.459936)\">10</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>B06</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>uint16</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;</div><input id='attrs-0f4c48d9-1504-4187-a816-8a71548041e5' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-0f4c48d9-1504-4187-a816-8a71548041e5' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-7f0d4276-1a81-4eeb-b152-b96065faf377' class='xr-var-data-in' type='checkbox'><label for='data-7f0d4276-1a81-4eeb-b152-b96065faf377' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 46.15 MiB </td>\n",
       "                        <td> 4.62 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (10, 1448, 1671) </td>\n",
       "                        <td> (1, 1448, 1671) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 10 chunks in 3 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> uint16 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"194\" height=\"168\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"103\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"103\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"11\" y2=\"105\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"106\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"14\" y2=\"108\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"15\" y2=\"109\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"111\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"112\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"114\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"21\" y2=\"115\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"117\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 24.9485979497544,14.948597949754403 24.9485979497544,118.93423529266285 10.0,103.98563734290845\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"131\" y2=\"1\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"134\" y2=\"4\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"135\" y2=\"5\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"137\" y2=\"7\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"138\" y2=\"8\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"141\" y2=\"11\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"143\" y2=\"13\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 144.9485979497544,14.948597949754403 24.9485979497544,14.948597949754403\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"24\" y1=\"118\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"144\" y1=\"14\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"24.9485979497544,14.948597949754403 144.9485979497544,14.948597949754403 144.9485979497544,118.93423529266285 24.9485979497544,118.93423529266285\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"84.948598\" y=\"138.934235\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1671</text>\n",
       "  <text x=\"164.948598\" y=\"66.941417\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,164.948598,66.941417)\">1448</text>\n",
       "  <text x=\"7.474299\" y=\"131.459936\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,7.474299,131.459936)\">10</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>B07</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>uint16</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;</div><input id='attrs-cc725ce9-da77-4d69-85e5-e77a48f2bc42' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-cc725ce9-da77-4d69-85e5-e77a48f2bc42' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2d273665-b53a-4335-8180-8ac8667dfd83' class='xr-var-data-in' type='checkbox'><label for='data-2d273665-b53a-4335-8180-8ac8667dfd83' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 46.15 MiB </td>\n",
       "                        <td> 4.62 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (10, 1448, 1671) </td>\n",
       "                        <td> (1, 1448, 1671) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 10 chunks in 3 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> uint16 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"194\" height=\"168\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"103\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"103\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"11\" y2=\"105\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"106\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"14\" y2=\"108\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"15\" y2=\"109\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"111\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"112\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"114\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"21\" y2=\"115\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"117\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 24.9485979497544,14.948597949754403 24.9485979497544,118.93423529266285 10.0,103.98563734290845\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"131\" y2=\"1\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"134\" y2=\"4\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"135\" y2=\"5\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"137\" y2=\"7\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"138\" y2=\"8\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"141\" y2=\"11\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"143\" y2=\"13\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 144.9485979497544,14.948597949754403 24.9485979497544,14.948597949754403\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"24\" y1=\"118\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"144\" y1=\"14\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"24.9485979497544,14.948597949754403 144.9485979497544,14.948597949754403 144.9485979497544,118.93423529266285 24.9485979497544,118.93423529266285\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"84.948598\" y=\"138.934235\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1671</text>\n",
       "  <text x=\"164.948598\" y=\"66.941417\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,164.948598,66.941417)\">1448</text>\n",
       "  <text x=\"7.474299\" y=\"131.459936\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,7.474299,131.459936)\">10</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>B08</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>uint16</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;</div><input id='attrs-b22579b6-d650-4dd0-85f2-a70b32dd14ae' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-b22579b6-d650-4dd0-85f2-a70b32dd14ae' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-f06cae49-bcdb-4872-8ee6-686bdd0537c1' class='xr-var-data-in' type='checkbox'><label for='data-f06cae49-bcdb-4872-8ee6-686bdd0537c1' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 46.15 MiB </td>\n",
       "                        <td> 4.62 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (10, 1448, 1671) </td>\n",
       "                        <td> (1, 1448, 1671) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 10 chunks in 3 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> uint16 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"194\" height=\"168\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"103\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"103\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"11\" y2=\"105\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"106\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"14\" y2=\"108\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"15\" y2=\"109\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"111\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"112\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"114\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"21\" y2=\"115\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"117\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 24.9485979497544,14.948597949754403 24.9485979497544,118.93423529266285 10.0,103.98563734290845\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"131\" y2=\"1\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"134\" y2=\"4\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"135\" y2=\"5\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"137\" y2=\"7\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"138\" y2=\"8\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"141\" y2=\"11\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"143\" y2=\"13\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 144.9485979497544,14.948597949754403 24.9485979497544,14.948597949754403\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"24\" y1=\"118\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"144\" y1=\"14\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"24.9485979497544,14.948597949754403 144.9485979497544,14.948597949754403 144.9485979497544,118.93423529266285 24.9485979497544,118.93423529266285\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"84.948598\" y=\"138.934235\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1671</text>\n",
       "  <text x=\"164.948598\" y=\"66.941417\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,164.948598,66.941417)\">1448</text>\n",
       "  <text x=\"7.474299\" y=\"131.459936\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,7.474299,131.459936)\">10</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>B8A</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>uint16</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;</div><input id='attrs-a417f289-078d-4530-971b-e2ece2d24f73' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-a417f289-078d-4530-971b-e2ece2d24f73' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-3458df1a-80c5-41f6-a49f-a295dbfe693c' class='xr-var-data-in' type='checkbox'><label for='data-3458df1a-80c5-41f6-a49f-a295dbfe693c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 46.15 MiB </td>\n",
       "                        <td> 4.62 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (10, 1448, 1671) </td>\n",
       "                        <td> (1, 1448, 1671) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 10 chunks in 3 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> uint16 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"194\" height=\"168\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"103\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"103\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"11\" y2=\"105\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"106\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"14\" y2=\"108\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"15\" y2=\"109\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"111\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"112\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"114\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"21\" y2=\"115\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"117\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 24.9485979497544,14.948597949754403 24.9485979497544,118.93423529266285 10.0,103.98563734290845\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"131\" y2=\"1\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"134\" y2=\"4\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"135\" y2=\"5\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"137\" y2=\"7\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"138\" y2=\"8\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"141\" y2=\"11\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"143\" y2=\"13\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 144.9485979497544,14.948597949754403 24.9485979497544,14.948597949754403\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"24\" y1=\"118\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"144\" y1=\"14\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"24.9485979497544,14.948597949754403 144.9485979497544,14.948597949754403 144.9485979497544,118.93423529266285 24.9485979497544,118.93423529266285\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"84.948598\" y=\"138.934235\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1671</text>\n",
       "  <text x=\"164.948598\" y=\"66.941417\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,164.948598,66.941417)\">1448</text>\n",
       "  <text x=\"7.474299\" y=\"131.459936\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,7.474299,131.459936)\">10</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>B11</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>uint16</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;</div><input id='attrs-21163094-5f79-4037-80fb-9620586e507d' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-21163094-5f79-4037-80fb-9620586e507d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-3f2ce2e2-28a9-4289-9839-6c9df7f6844e' class='xr-var-data-in' type='checkbox'><label for='data-3f2ce2e2-28a9-4289-9839-6c9df7f6844e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 46.15 MiB </td>\n",
       "                        <td> 4.62 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (10, 1448, 1671) </td>\n",
       "                        <td> (1, 1448, 1671) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 10 chunks in 3 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> uint16 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"194\" height=\"168\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"103\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"103\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"11\" y2=\"105\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"106\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"14\" y2=\"108\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"15\" y2=\"109\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"111\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"112\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"114\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"21\" y2=\"115\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"117\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 24.9485979497544,14.948597949754403 24.9485979497544,118.93423529266285 10.0,103.98563734290845\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"131\" y2=\"1\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"134\" y2=\"4\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"135\" y2=\"5\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"137\" y2=\"7\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"138\" y2=\"8\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"141\" y2=\"11\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"143\" y2=\"13\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 144.9485979497544,14.948597949754403 24.9485979497544,14.948597949754403\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"24\" y1=\"118\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"144\" y1=\"14\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"24.9485979497544,14.948597949754403 144.9485979497544,14.948597949754403 144.9485979497544,118.93423529266285 24.9485979497544,118.93423529266285\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"84.948598\" y=\"138.934235\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1671</text>\n",
       "  <text x=\"164.948598\" y=\"66.941417\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,164.948598,66.941417)\">1448</text>\n",
       "  <text x=\"7.474299\" y=\"131.459936\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,7.474299,131.459936)\">10</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>B12</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>uint16</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 1448, 1671), meta=np.ndarray&gt;</div><input id='attrs-13679fad-b654-477c-a428-e0f36e99afc8' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-13679fad-b654-477c-a428-e0f36e99afc8' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-810419cf-12ed-41dd-80a8-e500520689f3' class='xr-var-data-in' type='checkbox'><label for='data-810419cf-12ed-41dd-80a8-e500520689f3' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 46.15 MiB </td>\n",
       "                        <td> 4.62 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (10, 1448, 1671) </td>\n",
       "                        <td> (1, 1448, 1671) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 10 chunks in 3 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> uint16 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"194\" height=\"168\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"103\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"103\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"11\" y2=\"105\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"106\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"14\" y2=\"108\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"15\" y2=\"109\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"111\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"112\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"114\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"21\" y2=\"115\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"117\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 24.9485979497544,14.948597949754403 24.9485979497544,118.93423529266285 10.0,103.98563734290845\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"131\" y2=\"1\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"134\" y2=\"4\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"135\" y2=\"5\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"137\" y2=\"7\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"138\" y2=\"8\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"141\" y2=\"11\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"143\" y2=\"13\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 144.9485979497544,14.948597949754403 24.9485979497544,14.948597949754403\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"24\" y1=\"118\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"144\" y1=\"14\" x2=\"144\" y2=\"118\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"24.9485979497544,14.948597949754403 144.9485979497544,14.948597949754403 144.9485979497544,118.93423529266285 24.9485979497544,118.93423529266285\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"84.948598\" y=\"138.934235\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1671</text>\n",
       "  <text x=\"164.948598\" y=\"66.941417\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,164.948598,66.941417)\">1448</text>\n",
       "  <text x=\"7.474299\" y=\"131.459936\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,7.474299,131.459936)\">10</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li></ul></div></li><li class='xr-section-item'><input id='section-a2e91684-4070-4d5a-a0cf-88f46a6e737c' class='xr-section-summary-in' type='checkbox'  ><label for='section-a2e91684-4070-4d5a-a0cf-88f46a6e737c' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>latitude</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-a371a0f7-2b98-4ff5-b804-93f7781e8e23' class='xr-index-data-in' type='checkbox'/><label for='index-a371a0f7-2b98-4ff5-b804-93f7781e8e23' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([ 40.88003054257995,  40.87994071146245, 40.879850880344954,\n",
       "       40.879761049227454, 40.879671218109955, 40.879581386992456,\n",
       "        40.87949155587496,  40.87940172475746,  40.87931189363996,\n",
       "        40.87922206252246,\n",
       "       ...\n",
       "        40.75085339561625,  40.75076356449875,  40.75067373338125,\n",
       "        40.75058390226375,  40.75049407114625,  40.75040424002875,\n",
       "        40.75031440891125,  40.75022457779375,  40.75013474667625,\n",
       "        40.75004491555875],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;latitude&#x27;, length=1448))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>longitude</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-f00f19be-7472-4011-baaf-5ba7f88142c5' class='xr-index-data-in' type='checkbox'/><label for='index-f00f19be-7472-4011-baaf-5ba7f88142c5' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([-74.01001616960116, -74.00992633848367, -74.00983650736616,\n",
       "       -74.00974667624867, -74.00965684513116, -74.00956701401367,\n",
       "       -74.00947718289616, -74.00938735177867, -74.00929752066116,\n",
       "       -74.00920768954367,\n",
       "       ...\n",
       "       -73.86080668343514, -73.86071685231765, -73.86062702120016,\n",
       "       -73.86053719008265, -73.86044735896516, -73.86035752784765,\n",
       "       -73.86026769673016, -73.86017786561266, -73.86008803449516,\n",
       "       -73.85999820337766],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;longitude&#x27;, length=1671))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-6b15645c-9db2-4f51-978c-801cd40e1b7e' class='xr-index-data-in' type='checkbox'/><label for='index-6b15645c-9db2-4f51-978c-801cd40e1b7e' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2021-06-06 15:38:09.024000&#x27;, &#x27;2021-06-16 15:38:09.024000&#x27;,\n",
       "               &#x27;2021-06-24 15:49:11.024000&#x27;, &#x27;2021-06-29 15:48:09.024000&#x27;,\n",
       "               &#x27;2021-07-06 15:38:09.024000&#x27;, &#x27;2021-07-14 15:49:11.024000&#x27;,\n",
       "               &#x27;2021-07-16 15:38:09.024000&#x27;, &#x27;2021-07-24 15:49:11.024000&#x27;,\n",
       "               &#x27;2021-07-31 15:39:11.024000&#x27;, &#x27;2021-08-13 15:49:11.024000&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, freq=None))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-15f4c7a8-7c26-48d3-9734-372db165acf1' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-15f4c7a8-7c26-48d3-9734-372db165acf1' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset> Size: 532MB\n",
       "Dimensions:      (latitude: 1448, longitude: 1671, time: 10)\n",
       "Coordinates:\n",
       "  * latitude     (latitude) float64 12kB 40.88 40.88 40.88 ... 40.75 40.75 40.75\n",
       "  * longitude    (longitude) float64 13kB -74.01 -74.01 -74.01 ... -73.86 -73.86\n",
       "    spatial_ref  int32 4B 4326\n",
       "  * time         (time) datetime64[ns] 80B 2021-06-06T15:38:09.024000 ... 202...\n",
       "Data variables:\n",
       "    B01          (time, latitude, longitude) uint16 48MB dask.array<chunksize=(1, 1448, 1671), meta=np.ndarray>\n",
       "    B02          (time, latitude, longitude) uint16 48MB dask.array<chunksize=(1, 1448, 1671), meta=np.ndarray>\n",
       "    B03          (time, latitude, longitude) uint16 48MB dask.array<chunksize=(1, 1448, 1671), meta=np.ndarray>\n",
       "    B04          (time, latitude, longitude) uint16 48MB dask.array<chunksize=(1, 1448, 1671), meta=np.ndarray>\n",
       "    B05          (time, latitude, longitude) uint16 48MB dask.array<chunksize=(1, 1448, 1671), meta=np.ndarray>\n",
       "    B06          (time, latitude, longitude) uint16 48MB dask.array<chunksize=(1, 1448, 1671), meta=np.ndarray>\n",
       "    B07          (time, latitude, longitude) uint16 48MB dask.array<chunksize=(1, 1448, 1671), meta=np.ndarray>\n",
       "    B08          (time, latitude, longitude) uint16 48MB dask.array<chunksize=(1, 1448, 1671), meta=np.ndarray>\n",
       "    B8A          (time, latitude, longitude) uint16 48MB dask.array<chunksize=(1, 1448, 1671), meta=np.ndarray>\n",
       "    B11          (time, latitude, longitude) uint16 48MB dask.array<chunksize=(1, 1448, 1671), meta=np.ndarray>\n",
       "    B12          (time, latitude, longitude) uint16 48MB dask.array<chunksize=(1, 1448, 1671), meta=np.ndarray>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = stac_load(\n",
    "    items,\n",
    "    bands=[\"B01\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B8A\", \"B11\", \"B12\"],\n",
    "    crs=\"EPSG:4326\", # Latitude-Longitude\n",
    "    resolution=scale, # Degrees\n",
    "    chunks={\"x\": 2048, \"y\": 2048},\n",
    "    dtype=\"uint16\",\n",
    "    patch_url=planetary_computer.sign,\n",
    "    bbox=bounds\n",
    ")\n",
    "\n",
    "# View the dimensions of our XARRAY and the loaded variables\n",
    "# This insures we have the right coordinates and spectral bands in our xarray\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d318615-f011-470b-b5ef-82b889fe4703",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.3 Save the output data in a GeoTIFF file\n",
    "We selected a single date (July 24, 2021) to create a GeoTIFF output product. This date is the same as the ground temperature data collection date. Though this image contains some clouds, it will be used as the baseline for the benchmark notebook. Participants in the data challenge may desire to use other single scenes with less cloud cover or create a median mosaic that statistically filters the clouds over a time series stack of data (see the median dataset above).\n",
    "<br><br>The output product below only contains 7 selected bands that will be used in our model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00d279fd-2388-42fb-9d83-f63cf15acf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"S2.tiff\"\n",
    "\n",
    "# We will pick a single time slice from the time series (time=7) \n",
    "# This time slice is the date of July 24, 2021\n",
    "data_slice = data.isel(time=7)\n",
    "\n",
    "# Calculate the dimensions of the file\n",
    "# height = median.dims[\"latitude\"]\n",
    "# width = median.dims[\"longitude\"]\n",
    "height = data_slice.dims[\"latitude\"]\n",
    "width = data_slice.dims[\"longitude\"]\n",
    "\n",
    "# Define the Coordinate Reference System (CRS) to be common Lat-Lon coordinates\n",
    "# Define the tranformation using our bounding box so the Lat-Lon information is written to the GeoTIFF\n",
    "gt = rasterio.transform.from_bounds(lower_left[1],lower_left[0],upper_right[1],upper_right[0],width,height)\n",
    "data_slice.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "data_slice.rio.write_transform(transform=gt, inplace=True);\n",
    "\n",
    "# Create the GeoTIFF output file using the defined parameters \n",
    "with rasterio.open(filename,'w',driver='GTiff',width=width,height=height,\n",
    "                   crs='epsg:4326',transform=gt,count=7,compress='lzw',dtype='float64') as dst:\n",
    "    dst.write(data_slice.B01,1)\n",
    "    dst.write(data_slice.B04,2)\n",
    "    dst.write(data_slice.B06,3) \n",
    "    dst.write(data_slice.B08,4)\n",
    "    dst.write(data_slice.B02,5)\n",
    "    dst.write(data_slice.B03,6)\n",
    "    dst.write(data_slice.B11,7)\n",
    "    dst.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa67bd1-c263-46d4-9b38-5e054bcdfda2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2. Landsat Land Surface Temperature (LST) Data Extraction\n",
    "\n",
    "We extracted Landsat Land Surface Temperature (LST) data to GeoTIFF file product. The baseline data is [Landsat Collection-2 Level-2](https://www.usgs.gov/landsat-missions/landsat-collection-2) data from the MS Planetary Computer catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869a6b16-0e71-4e4f-8f9f-ba47be3c4637",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1 Discover and load the data for analysis\n",
    "\n",
    "We used our area of interest previously defined when processing Sentinel-2 Satellite Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97e1b919-100c-4cec-8727-0a0e46af5944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of scenes that touch our region: 8\n"
     ]
    }
   ],
   "source": [
    "stac = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "\n",
    "search = stac.search(\n",
    "    bbox=bounds, \n",
    "    datetime=time_window,\n",
    "    collections=[\"landsat-c2-l2\"],\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 50},\"platform\": {\"in\": [\"landsat-8\"]}},\n",
    ")\n",
    "\n",
    "items = list(search.get_items())\n",
    "print('This is the number of scenes that touch our region:',len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa7b3d7f-0499-45b2-be96-8ad75c3140be",
   "metadata": {},
   "outputs": [],
   "source": [
    "signed_items = [planetary_computer.sign(item).to_dict() for item in items]\n",
    "\n",
    "# Define the pixel resolution for the final product\n",
    "# Define the scale according to our selected crs, so we will use degrees\n",
    "resolution = 30  # meters per pixel \n",
    "scale = resolution / 111320.0 # degrees per pixel for crs=4326 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb6632a-04c5-4bf4-a4c9-87834f05509a",
   "metadata": {},
   "source": [
    "Next, we loaded the data into an [xarray](https://xarray.pydata.org/en/stable/) DataArray using [stackstac](https://stackstac.readthedocs.io/). We only kept the commonly used spectral bands (Red, Green, Blue, NIR, Surface Temperature). There are also several other <b>important settings for the data</b>: We have changed the projection to epsg=4326 which is standard latitude-longitude in degrees. We have specified the spatial resolution of each pixel to be 30-meters. \n",
    "\n",
    "#### Landsat Band Summary \n",
    "The following list of bands will be loaded by the Open Data Cube (ODC) stac command:<br>\n",
    "We will use two load commands to separate the RGB data from the Surface Temperature data.<br><br>\n",
    "Band 2 = blue = 30m<br>\n",
    "Band 3 = green = 30m<br>\n",
    "Band 4 = red = 30m<br>\n",
    "Band 5 = nir08 (near infrared) = 30m<br>\n",
    "Band 11 = Surface Temperature = lwir11 = 100m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66e62a55-3eb4-4d8d-9c79-0413cb95d368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "html[data-theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 17MB\n",
       "Dimensions:      (latitude: 484, longitude: 558, time: 8)\n",
       "Coordinates:\n",
       "  * latitude     (latitude) float64 4kB 40.88 40.88 40.88 ... 40.75 40.75 40.75\n",
       "  * longitude    (longitude) float64 4kB -74.01 -74.01 -74.01 ... -73.86 -73.86\n",
       "    spatial_ref  int32 4B 4326\n",
       "  * time         (time) datetime64[ns] 64B 2021-06-07T15:39:15.904901 ... 202...\n",
       "Data variables:\n",
       "    red          (time, latitude, longitude) uint16 4MB dask.array&lt;chunksize=(1, 484, 558), meta=np.ndarray&gt;\n",
       "    green        (time, latitude, longitude) uint16 4MB dask.array&lt;chunksize=(1, 484, 558), meta=np.ndarray&gt;\n",
       "    blue         (time, latitude, longitude) uint16 4MB dask.array&lt;chunksize=(1, 484, 558), meta=np.ndarray&gt;\n",
       "    nir08        (time, latitude, longitude) uint16 4MB dask.array&lt;chunksize=(1, 484, 558), meta=np.ndarray&gt;</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-078bc1c2-b176-4bac-9d40-382be6b38b85' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-078bc1c2-b176-4bac-9d40-382be6b38b85' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>latitude</span>: 484</li><li><span class='xr-has-index'>longitude</span>: 558</li><li><span class='xr-has-index'>time</span>: 8</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-1007ccc1-8e7c-49a8-9e8a-f328b549d8e9' class='xr-section-summary-in' type='checkbox'  checked><label for='section-1007ccc1-8e7c-49a8-9e8a-f328b549d8e9' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>latitude</span></div><div class='xr-var-dims'>(latitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>40.88 40.88 40.88 ... 40.75 40.75</div><input id='attrs-872e65c8-865f-4921-8da1-4e6930aca3de' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-872e65c8-865f-4921-8da1-4e6930aca3de' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2be43389-38e3-4acf-8242-e86cfd4a7137' class='xr-var-data-in' type='checkbox'><label for='data-2be43389-38e3-4acf-8242-e86cfd4a7137' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>resolution :</span></dt><dd>-0.00026949335249730504</dd><dt><span>crs :</span></dt><dd>EPSG:4326</dd></dl></div><div class='xr-var-data'><pre>array([40.88012 , 40.879851, 40.879581, ..., 40.750494, 40.750225, 40.749955])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>longitude</span></div><div class='xr-var-dims'>(longitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-74.01 -74.01 ... -73.86 -73.86</div><input id='attrs-84e21a67-06a6-4c15-a4c4-239f400ef8fd' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-84e21a67-06a6-4c15-a4c4-239f400ef8fd' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-09d2f014-41f2-4d2f-b092-1ce940161a13' class='xr-var-data-in' type='checkbox'><label for='data-09d2f014-41f2-4d2f-b092-1ce940161a13' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>resolution :</span></dt><dd>0.00026949335249730504</dd><dt><span>crs :</span></dt><dd>EPSG:4326</dd></dl></div><div class='xr-var-data'><pre>array([-74.010016, -74.009747, -74.009477, ..., -73.860447, -73.860178,\n",
       "       -73.859908])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>spatial_ref</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>4326</div><input id='attrs-4ac7f773-f7ea-4c48-9700-c939499095b0' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-4ac7f773-f7ea-4c48-9700-c939499095b0' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-81edd444-1715-4f2a-919b-9652b28268a1' class='xr-var-data-in' type='checkbox'><label for='data-81edd444-1715-4f2a-919b-9652b28268a1' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>spatial_ref :</span></dt><dd>GEOGCRS[&quot;WGS 84&quot;,ENSEMBLE[&quot;World Geodetic System 1984 ensemble&quot;,MEMBER[&quot;World Geodetic System 1984 (Transit)&quot;],MEMBER[&quot;World Geodetic System 1984 (G730)&quot;],MEMBER[&quot;World Geodetic System 1984 (G873)&quot;],MEMBER[&quot;World Geodetic System 1984 (G1150)&quot;],MEMBER[&quot;World Geodetic System 1984 (G1674)&quot;],MEMBER[&quot;World Geodetic System 1984 (G1762)&quot;],MEMBER[&quot;World Geodetic System 1984 (G2139)&quot;],ELLIPSOID[&quot;WGS 84&quot;,6378137,298.257223563,LENGTHUNIT[&quot;metre&quot;,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[&quot;Greenwich&quot;,0,ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],CS[ellipsoidal,2],AXIS[&quot;geodetic latitude (Lat)&quot;,north,ORDER[1],ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],AXIS[&quot;geodetic longitude (Lon)&quot;,east,ORDER[2],ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],USAGE[SCOPE[&quot;Horizontal component of 3D system.&quot;],AREA[&quot;World.&quot;],BBOX[-90,-180,90,180]],ID[&quot;EPSG&quot;,4326]]</dd><dt><span>crs_wkt :</span></dt><dd>GEOGCRS[&quot;WGS 84&quot;,ENSEMBLE[&quot;World Geodetic System 1984 ensemble&quot;,MEMBER[&quot;World Geodetic System 1984 (Transit)&quot;],MEMBER[&quot;World Geodetic System 1984 (G730)&quot;],MEMBER[&quot;World Geodetic System 1984 (G873)&quot;],MEMBER[&quot;World Geodetic System 1984 (G1150)&quot;],MEMBER[&quot;World Geodetic System 1984 (G1674)&quot;],MEMBER[&quot;World Geodetic System 1984 (G1762)&quot;],MEMBER[&quot;World Geodetic System 1984 (G2139)&quot;],ELLIPSOID[&quot;WGS 84&quot;,6378137,298.257223563,LENGTHUNIT[&quot;metre&quot;,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[&quot;Greenwich&quot;,0,ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],CS[ellipsoidal,2],AXIS[&quot;geodetic latitude (Lat)&quot;,north,ORDER[1],ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],AXIS[&quot;geodetic longitude (Lon)&quot;,east,ORDER[2],ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],USAGE[SCOPE[&quot;Horizontal component of 3D system.&quot;],AREA[&quot;World.&quot;],BBOX[-90,-180,90,180]],ID[&quot;EPSG&quot;,4326]]</dd><dt><span>semi_major_axis :</span></dt><dd>6378137.0</dd><dt><span>semi_minor_axis :</span></dt><dd>6356752.314245179</dd><dt><span>inverse_flattening :</span></dt><dd>298.257223563</dd><dt><span>reference_ellipsoid_name :</span></dt><dd>WGS 84</dd><dt><span>longitude_of_prime_meridian :</span></dt><dd>0.0</dd><dt><span>prime_meridian_name :</span></dt><dd>Greenwich</dd><dt><span>geographic_crs_name :</span></dt><dd>WGS 84</dd><dt><span>horizontal_datum_name :</span></dt><dd>World Geodetic System 1984 ensemble</dd><dt><span>grid_mapping_name :</span></dt><dd>latitude_longitude</dd><dt><span>GeoTransform :</span></dt><dd>-74.010150916277396504483477 0.000269493352497305043314 0 40.880255120373696797742014 0 -0.000269493352497305043314</dd></dl></div><div class='xr-var-data'><pre>array(4326, dtype=int32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2021-06-07T15:39:15.904901 ... 2...</div><input id='attrs-f1804e85-bcf4-4c1e-898b-c3c8623a55d1' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-f1804e85-bcf4-4c1e-898b-c3c8623a55d1' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-be7896b8-2b92-4f23-b9f8-cf4ce1b1ed36' class='xr-var-data-in' type='checkbox'><label for='data-be7896b8-2b92-4f23-b9f8-cf4ce1b1ed36' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2021-06-07T15:39:15.904901000&#x27;, &#x27;2021-06-07T15:39:39.787469000&#x27;,\n",
       "       &#x27;2021-06-16T15:33:32.108022000&#x27;, &#x27;2021-06-23T15:39:20.838143000&#x27;,\n",
       "       &#x27;2021-06-23T15:39:44.720711000&#x27;, &#x27;2021-07-18T15:33:37.770322000&#x27;,\n",
       "       &#x27;2021-08-26T15:39:40.063072000&#x27;, &#x27;2021-08-26T15:40:03.949876000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-bf4eefb7-fe1d-4afa-902f-8e6b516dd170' class='xr-section-summary-in' type='checkbox'  checked><label for='section-bf4eefb7-fe1d-4afa-902f-8e6b516dd170' class='xr-section-summary' >Data variables: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>red</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>uint16</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 484, 558), meta=np.ndarray&gt;</div><input id='attrs-0a9ff076-c4a0-4be1-a260-831974ca2de9' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-0a9ff076-c4a0-4be1-a260-831974ca2de9' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-48521433-be6d-4ca8-8d53-3213eb36f38e' class='xr-var-data-in' type='checkbox'><label for='data-48521433-be6d-4ca8-8d53-3213eb36f38e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>nodata :</span></dt><dd>0</dd></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 4.12 MiB </td>\n",
       "                        <td> 527.48 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (8, 484, 558) </td>\n",
       "                        <td> (1, 484, 558) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 8 chunks in 3 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> uint16 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"196\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"26\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"104\" x2=\"26\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"104\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"106\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"14\" y2=\"108\" />\n",
       "  <line x1=\"16\" y1=\"6\" x2=\"16\" y2=\"110\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"112\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"114\" />\n",
       "  <line x1=\"22\" y1=\"12\" x2=\"22\" y2=\"116\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 26.011678628854686,16.011678628854686 26.011678628854686,120.09770013423102 10.0,104.08602150537634\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"134\" y2=\"4\" />\n",
       "  <line x1=\"16\" y1=\"6\" x2=\"136\" y2=\"6\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"138\" y2=\"8\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"22\" y1=\"12\" x2=\"142\" y2=\"12\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"146\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"26\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"146\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 146.0116786288547,16.011678628854686 26.011678628854686,16.011678628854686\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"146\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"26\" y1=\"120\" x2=\"146\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"146\" y1=\"16\" x2=\"146\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"26.011678628854686,16.011678628854686 146.0116786288547,16.011678628854686 146.0116786288547,120.09770013423102 26.011678628854686,120.09770013423102\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"86.011679\" y=\"140.097700\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >558</text>\n",
       "  <text x=\"166.011679\" y=\"68.054689\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,166.011679,68.054689)\">484</text>\n",
       "  <text x=\"8.005839\" y=\"132.091861\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,8.005839,132.091861)\">8</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>green</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>uint16</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 484, 558), meta=np.ndarray&gt;</div><input id='attrs-6f2126ee-2960-4976-b6a7-64a75573c9bf' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-6f2126ee-2960-4976-b6a7-64a75573c9bf' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b1af6674-afd7-4ba6-a262-8b024168405e' class='xr-var-data-in' type='checkbox'><label for='data-b1af6674-afd7-4ba6-a262-8b024168405e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>nodata :</span></dt><dd>0</dd></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 4.12 MiB </td>\n",
       "                        <td> 527.48 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (8, 484, 558) </td>\n",
       "                        <td> (1, 484, 558) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 8 chunks in 3 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> uint16 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"196\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"26\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"104\" x2=\"26\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"104\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"106\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"14\" y2=\"108\" />\n",
       "  <line x1=\"16\" y1=\"6\" x2=\"16\" y2=\"110\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"112\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"114\" />\n",
       "  <line x1=\"22\" y1=\"12\" x2=\"22\" y2=\"116\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 26.011678628854686,16.011678628854686 26.011678628854686,120.09770013423102 10.0,104.08602150537634\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"134\" y2=\"4\" />\n",
       "  <line x1=\"16\" y1=\"6\" x2=\"136\" y2=\"6\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"138\" y2=\"8\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"22\" y1=\"12\" x2=\"142\" y2=\"12\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"146\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"26\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"146\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 146.0116786288547,16.011678628854686 26.011678628854686,16.011678628854686\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"146\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"26\" y1=\"120\" x2=\"146\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"146\" y1=\"16\" x2=\"146\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"26.011678628854686,16.011678628854686 146.0116786288547,16.011678628854686 146.0116786288547,120.09770013423102 26.011678628854686,120.09770013423102\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"86.011679\" y=\"140.097700\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >558</text>\n",
       "  <text x=\"166.011679\" y=\"68.054689\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,166.011679,68.054689)\">484</text>\n",
       "  <text x=\"8.005839\" y=\"132.091861\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,8.005839,132.091861)\">8</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>blue</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>uint16</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 484, 558), meta=np.ndarray&gt;</div><input id='attrs-b223d778-5f72-4622-b167-3f4f62b6d9b5' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-b223d778-5f72-4622-b167-3f4f62b6d9b5' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-f7c093f7-adbb-4d4d-91f2-a11e7587a5e6' class='xr-var-data-in' type='checkbox'><label for='data-f7c093f7-adbb-4d4d-91f2-a11e7587a5e6' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>nodata :</span></dt><dd>0</dd></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 4.12 MiB </td>\n",
       "                        <td> 527.48 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (8, 484, 558) </td>\n",
       "                        <td> (1, 484, 558) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 8 chunks in 3 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> uint16 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"196\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"26\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"104\" x2=\"26\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"104\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"106\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"14\" y2=\"108\" />\n",
       "  <line x1=\"16\" y1=\"6\" x2=\"16\" y2=\"110\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"112\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"114\" />\n",
       "  <line x1=\"22\" y1=\"12\" x2=\"22\" y2=\"116\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 26.011678628854686,16.011678628854686 26.011678628854686,120.09770013423102 10.0,104.08602150537634\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"134\" y2=\"4\" />\n",
       "  <line x1=\"16\" y1=\"6\" x2=\"136\" y2=\"6\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"138\" y2=\"8\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"22\" y1=\"12\" x2=\"142\" y2=\"12\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"146\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"26\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"146\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 146.0116786288547,16.011678628854686 26.011678628854686,16.011678628854686\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"146\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"26\" y1=\"120\" x2=\"146\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"146\" y1=\"16\" x2=\"146\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"26.011678628854686,16.011678628854686 146.0116786288547,16.011678628854686 146.0116786288547,120.09770013423102 26.011678628854686,120.09770013423102\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"86.011679\" y=\"140.097700\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >558</text>\n",
       "  <text x=\"166.011679\" y=\"68.054689\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,166.011679,68.054689)\">484</text>\n",
       "  <text x=\"8.005839\" y=\"132.091861\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,8.005839,132.091861)\">8</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>nir08</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>uint16</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 484, 558), meta=np.ndarray&gt;</div><input id='attrs-42858c62-d03e-4458-9f5a-3040f476a4f7' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-42858c62-d03e-4458-9f5a-3040f476a4f7' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-94162676-69a7-4f5d-b48e-46f78922e78a' class='xr-var-data-in' type='checkbox'><label for='data-94162676-69a7-4f5d-b48e-46f78922e78a' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>nodata :</span></dt><dd>0</dd></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 4.12 MiB </td>\n",
       "                        <td> 527.48 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (8, 484, 558) </td>\n",
       "                        <td> (1, 484, 558) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 8 chunks in 3 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> uint16 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"196\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"26\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"104\" x2=\"26\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"104\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"106\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"14\" y2=\"108\" />\n",
       "  <line x1=\"16\" y1=\"6\" x2=\"16\" y2=\"110\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"112\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"114\" />\n",
       "  <line x1=\"22\" y1=\"12\" x2=\"22\" y2=\"116\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 26.011678628854686,16.011678628854686 26.011678628854686,120.09770013423102 10.0,104.08602150537634\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"134\" y2=\"4\" />\n",
       "  <line x1=\"16\" y1=\"6\" x2=\"136\" y2=\"6\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"138\" y2=\"8\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"22\" y1=\"12\" x2=\"142\" y2=\"12\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"146\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"26\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"146\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 146.0116786288547,16.011678628854686 26.011678628854686,16.011678628854686\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"146\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"26\" y1=\"120\" x2=\"146\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"146\" y1=\"16\" x2=\"146\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"26.011678628854686,16.011678628854686 146.0116786288547,16.011678628854686 146.0116786288547,120.09770013423102 26.011678628854686,120.09770013423102\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"86.011679\" y=\"140.097700\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >558</text>\n",
       "  <text x=\"166.011679\" y=\"68.054689\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,166.011679,68.054689)\">484</text>\n",
       "  <text x=\"8.005839\" y=\"132.091861\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,8.005839,132.091861)\">8</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li></ul></div></li><li class='xr-section-item'><input id='section-473d6e87-e96f-4f86-9b31-52e56620a6e6' class='xr-section-summary-in' type='checkbox'  ><label for='section-473d6e87-e96f-4f86-9b31-52e56620a6e6' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>latitude</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-ecda1950-632b-467b-9b56-ca47a62a7d93' class='xr-index-data-in' type='checkbox'/><label for='index-ecda1950-632b-467b-9b56-ca47a62a7d93' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([ 40.88012037369745, 40.879850880344954, 40.879581386992456,\n",
       "        40.87931189363996,  40.87904240028746,  40.87877290693496,\n",
       "       40.878503413582465, 40.878233920229974, 40.877964426877476,\n",
       "        40.87769493352498,\n",
       "       ...\n",
       "        40.75238052461373,  40.75211103126123,  40.75184153790873,\n",
       "       40.751572044556234,  40.75130255120374, 40.751033057851245,\n",
       "        40.75076356449875,  40.75049407114625,  40.75022457779375,\n",
       "       40.749955084441254],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;latitude&#x27;, length=484))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>longitude</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-ab8fb378-648f-499b-8b77-a912eb07f54e' class='xr-index-data-in' type='checkbox'/><label for='index-ab8fb378-648f-499b-8b77-a912eb07f54e' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([-74.01001616960114, -74.00974667624865, -74.00947718289615,\n",
       "       -74.00920768954366, -74.00893819619115, -74.00866870283866,\n",
       "       -74.00839920948616, -74.00812971613367, -74.00786022278116,\n",
       "       -74.00759072942867,\n",
       "       ...\n",
       "       -73.86233381243262, -73.86206431908012, -73.86179482572763,\n",
       "       -73.86152533237512, -73.86125583902263, -73.86098634567013,\n",
       "       -73.86071685231764, -73.86044735896515, -73.86017786561264,\n",
       "       -73.85990837226015],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;longitude&#x27;, length=558))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-15cf401d-7fb2-4600-afd7-7e0c96687ecc' class='xr-index-data-in' type='checkbox'/><label for='index-15cf401d-7fb2-4600-afd7-7e0c96687ecc' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2021-06-07 15:39:15.904901&#x27;, &#x27;2021-06-07 15:39:39.787469&#x27;,\n",
       "               &#x27;2021-06-16 15:33:32.108022&#x27;, &#x27;2021-06-23 15:39:20.838143&#x27;,\n",
       "               &#x27;2021-06-23 15:39:44.720711&#x27;, &#x27;2021-07-18 15:33:37.770322&#x27;,\n",
       "               &#x27;2021-08-26 15:39:40.063072&#x27;, &#x27;2021-08-26 15:40:03.949876&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, freq=None))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-90b723a2-6252-4251-b8ef-823f5517399a' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-90b723a2-6252-4251-b8ef-823f5517399a' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset> Size: 17MB\n",
       "Dimensions:      (latitude: 484, longitude: 558, time: 8)\n",
       "Coordinates:\n",
       "  * latitude     (latitude) float64 4kB 40.88 40.88 40.88 ... 40.75 40.75 40.75\n",
       "  * longitude    (longitude) float64 4kB -74.01 -74.01 -74.01 ... -73.86 -73.86\n",
       "    spatial_ref  int32 4B 4326\n",
       "  * time         (time) datetime64[ns] 64B 2021-06-07T15:39:15.904901 ... 202...\n",
       "Data variables:\n",
       "    red          (time, latitude, longitude) uint16 4MB dask.array<chunksize=(1, 484, 558), meta=np.ndarray>\n",
       "    green        (time, latitude, longitude) uint16 4MB dask.array<chunksize=(1, 484, 558), meta=np.ndarray>\n",
       "    blue         (time, latitude, longitude) uint16 4MB dask.array<chunksize=(1, 484, 558), meta=np.ndarray>\n",
       "    nir08        (time, latitude, longitude) uint16 4MB dask.array<chunksize=(1, 484, 558), meta=np.ndarray>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "html[data-theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 4MB\n",
       "Dimensions:      (latitude: 484, longitude: 558, time: 8)\n",
       "Coordinates:\n",
       "  * latitude     (latitude) float64 4kB 40.88 40.88 40.88 ... 40.75 40.75 40.75\n",
       "  * longitude    (longitude) float64 4kB -74.01 -74.01 -74.01 ... -73.86 -73.86\n",
       "    spatial_ref  int32 4B 4326\n",
       "  * time         (time) datetime64[ns] 64B 2021-06-07T15:39:15.904901 ... 202...\n",
       "Data variables:\n",
       "    lwir11       (time, latitude, longitude) uint16 4MB dask.array&lt;chunksize=(1, 484, 558), meta=np.ndarray&gt;</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-f0f76c7e-7f84-438f-aa3d-d8dcce565472' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-f0f76c7e-7f84-438f-aa3d-d8dcce565472' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>latitude</span>: 484</li><li><span class='xr-has-index'>longitude</span>: 558</li><li><span class='xr-has-index'>time</span>: 8</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-32a2dff3-be6e-48ec-9f5e-dfaa21d47026' class='xr-section-summary-in' type='checkbox'  checked><label for='section-32a2dff3-be6e-48ec-9f5e-dfaa21d47026' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>latitude</span></div><div class='xr-var-dims'>(latitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>40.88 40.88 40.88 ... 40.75 40.75</div><input id='attrs-9aa87b5e-0f8b-4cb1-9db2-a7a934dba881' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-9aa87b5e-0f8b-4cb1-9db2-a7a934dba881' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-f58b3c4c-bfd3-4107-a993-af7badadb1a6' class='xr-var-data-in' type='checkbox'><label for='data-f58b3c4c-bfd3-4107-a993-af7badadb1a6' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>resolution :</span></dt><dd>-0.00026949335249730504</dd><dt><span>crs :</span></dt><dd>EPSG:4326</dd></dl></div><div class='xr-var-data'><pre>array([40.88012 , 40.879851, 40.879581, ..., 40.750494, 40.750225, 40.749955])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>longitude</span></div><div class='xr-var-dims'>(longitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-74.01 -74.01 ... -73.86 -73.86</div><input id='attrs-e10408ae-4114-4f6f-977b-1b3febc35d26' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-e10408ae-4114-4f6f-977b-1b3febc35d26' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ced1107f-0543-4a41-8fdc-061db40befc4' class='xr-var-data-in' type='checkbox'><label for='data-ced1107f-0543-4a41-8fdc-061db40befc4' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>resolution :</span></dt><dd>0.00026949335249730504</dd><dt><span>crs :</span></dt><dd>EPSG:4326</dd></dl></div><div class='xr-var-data'><pre>array([-74.010016, -74.009747, -74.009477, ..., -73.860447, -73.860178,\n",
       "       -73.859908])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>spatial_ref</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>4326</div><input id='attrs-d15dc552-416f-40bd-8dd2-af8db2885cef' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-d15dc552-416f-40bd-8dd2-af8db2885cef' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-84ceee32-8a19-4d40-a0d0-c5b5a78dac53' class='xr-var-data-in' type='checkbox'><label for='data-84ceee32-8a19-4d40-a0d0-c5b5a78dac53' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>spatial_ref :</span></dt><dd>GEOGCRS[&quot;WGS 84&quot;,ENSEMBLE[&quot;World Geodetic System 1984 ensemble&quot;,MEMBER[&quot;World Geodetic System 1984 (Transit)&quot;],MEMBER[&quot;World Geodetic System 1984 (G730)&quot;],MEMBER[&quot;World Geodetic System 1984 (G873)&quot;],MEMBER[&quot;World Geodetic System 1984 (G1150)&quot;],MEMBER[&quot;World Geodetic System 1984 (G1674)&quot;],MEMBER[&quot;World Geodetic System 1984 (G1762)&quot;],MEMBER[&quot;World Geodetic System 1984 (G2139)&quot;],ELLIPSOID[&quot;WGS 84&quot;,6378137,298.257223563,LENGTHUNIT[&quot;metre&quot;,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[&quot;Greenwich&quot;,0,ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],CS[ellipsoidal,2],AXIS[&quot;geodetic latitude (Lat)&quot;,north,ORDER[1],ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],AXIS[&quot;geodetic longitude (Lon)&quot;,east,ORDER[2],ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],USAGE[SCOPE[&quot;Horizontal component of 3D system.&quot;],AREA[&quot;World.&quot;],BBOX[-90,-180,90,180]],ID[&quot;EPSG&quot;,4326]]</dd><dt><span>crs_wkt :</span></dt><dd>GEOGCRS[&quot;WGS 84&quot;,ENSEMBLE[&quot;World Geodetic System 1984 ensemble&quot;,MEMBER[&quot;World Geodetic System 1984 (Transit)&quot;],MEMBER[&quot;World Geodetic System 1984 (G730)&quot;],MEMBER[&quot;World Geodetic System 1984 (G873)&quot;],MEMBER[&quot;World Geodetic System 1984 (G1150)&quot;],MEMBER[&quot;World Geodetic System 1984 (G1674)&quot;],MEMBER[&quot;World Geodetic System 1984 (G1762)&quot;],MEMBER[&quot;World Geodetic System 1984 (G2139)&quot;],ELLIPSOID[&quot;WGS 84&quot;,6378137,298.257223563,LENGTHUNIT[&quot;metre&quot;,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[&quot;Greenwich&quot;,0,ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],CS[ellipsoidal,2],AXIS[&quot;geodetic latitude (Lat)&quot;,north,ORDER[1],ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],AXIS[&quot;geodetic longitude (Lon)&quot;,east,ORDER[2],ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],USAGE[SCOPE[&quot;Horizontal component of 3D system.&quot;],AREA[&quot;World.&quot;],BBOX[-90,-180,90,180]],ID[&quot;EPSG&quot;,4326]]</dd><dt><span>semi_major_axis :</span></dt><dd>6378137.0</dd><dt><span>semi_minor_axis :</span></dt><dd>6356752.314245179</dd><dt><span>inverse_flattening :</span></dt><dd>298.257223563</dd><dt><span>reference_ellipsoid_name :</span></dt><dd>WGS 84</dd><dt><span>longitude_of_prime_meridian :</span></dt><dd>0.0</dd><dt><span>prime_meridian_name :</span></dt><dd>Greenwich</dd><dt><span>geographic_crs_name :</span></dt><dd>WGS 84</dd><dt><span>horizontal_datum_name :</span></dt><dd>World Geodetic System 1984 ensemble</dd><dt><span>grid_mapping_name :</span></dt><dd>latitude_longitude</dd><dt><span>GeoTransform :</span></dt><dd>-74.010150916277396504483477 0.000269493352497305043314 0 40.880255120373696797742014 0 -0.000269493352497305043314</dd></dl></div><div class='xr-var-data'><pre>array(4326, dtype=int32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2021-06-07T15:39:15.904901 ... 2...</div><input id='attrs-b896e1b2-fbe8-4bbe-973f-440ae2dc8c59' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-b896e1b2-fbe8-4bbe-973f-440ae2dc8c59' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-74933f33-6a9a-4a0e-8eb1-bde7b4e97eec' class='xr-var-data-in' type='checkbox'><label for='data-74933f33-6a9a-4a0e-8eb1-bde7b4e97eec' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2021-06-07T15:39:15.904901000&#x27;, &#x27;2021-06-07T15:39:39.787469000&#x27;,\n",
       "       &#x27;2021-06-16T15:33:32.108022000&#x27;, &#x27;2021-06-23T15:39:20.838143000&#x27;,\n",
       "       &#x27;2021-06-23T15:39:44.720711000&#x27;, &#x27;2021-07-18T15:33:37.770322000&#x27;,\n",
       "       &#x27;2021-08-26T15:39:40.063072000&#x27;, &#x27;2021-08-26T15:40:03.949876000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-04c04f5f-487d-457e-9895-5e2b933f41fe' class='xr-section-summary-in' type='checkbox'  checked><label for='section-04c04f5f-487d-457e-9895-5e2b933f41fe' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>lwir11</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>uint16</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 484, 558), meta=np.ndarray&gt;</div><input id='attrs-2e98d2e2-7edf-48a9-aad2-6629cc7a0bc8' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-2e98d2e2-7edf-48a9-aad2-6629cc7a0bc8' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1b87a5df-50f8-45ed-84cc-f6e38a4f0c44' class='xr-var-data-in' type='checkbox'><label for='data-1b87a5df-50f8-45ed-84cc-f6e38a4f0c44' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>nodata :</span></dt><dd>0</dd></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 4.12 MiB </td>\n",
       "                        <td> 527.48 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (8, 484, 558) </td>\n",
       "                        <td> (1, 484, 558) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 8 chunks in 3 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> uint16 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"196\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"26\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"104\" x2=\"26\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"104\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"106\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"14\" y2=\"108\" />\n",
       "  <line x1=\"16\" y1=\"6\" x2=\"16\" y2=\"110\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"112\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"114\" />\n",
       "  <line x1=\"22\" y1=\"12\" x2=\"22\" y2=\"116\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"118\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 26.011678628854686,16.011678628854686 26.011678628854686,120.09770013423102 10.0,104.08602150537634\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"134\" y2=\"4\" />\n",
       "  <line x1=\"16\" y1=\"6\" x2=\"136\" y2=\"6\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"138\" y2=\"8\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"22\" y1=\"12\" x2=\"142\" y2=\"12\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"146\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"26\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"146\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 146.0116786288547,16.011678628854686 26.011678628854686,16.011678628854686\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"146\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"26\" y1=\"120\" x2=\"146\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"146\" y1=\"16\" x2=\"146\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"26.011678628854686,16.011678628854686 146.0116786288547,16.011678628854686 146.0116786288547,120.09770013423102 26.011678628854686,120.09770013423102\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"86.011679\" y=\"140.097700\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >558</text>\n",
       "  <text x=\"166.011679\" y=\"68.054689\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,166.011679,68.054689)\">484</text>\n",
       "  <text x=\"8.005839\" y=\"132.091861\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,8.005839,132.091861)\">8</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li></ul></div></li><li class='xr-section-item'><input id='section-04d0e4f4-eed8-48ac-a8c4-bb47f6177469' class='xr-section-summary-in' type='checkbox'  ><label for='section-04d0e4f4-eed8-48ac-a8c4-bb47f6177469' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>latitude</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-7aecbef6-f551-4f8f-9081-f31836873d0b' class='xr-index-data-in' type='checkbox'/><label for='index-7aecbef6-f551-4f8f-9081-f31836873d0b' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([ 40.88012037369745, 40.879850880344954, 40.879581386992456,\n",
       "        40.87931189363996,  40.87904240028746,  40.87877290693496,\n",
       "       40.878503413582465, 40.878233920229974, 40.877964426877476,\n",
       "        40.87769493352498,\n",
       "       ...\n",
       "        40.75238052461373,  40.75211103126123,  40.75184153790873,\n",
       "       40.751572044556234,  40.75130255120374, 40.751033057851245,\n",
       "        40.75076356449875,  40.75049407114625,  40.75022457779375,\n",
       "       40.749955084441254],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;latitude&#x27;, length=484))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>longitude</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-c1c8ddce-fd58-4439-8641-1797518f8c88' class='xr-index-data-in' type='checkbox'/><label for='index-c1c8ddce-fd58-4439-8641-1797518f8c88' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([-74.01001616960114, -74.00974667624865, -74.00947718289615,\n",
       "       -74.00920768954366, -74.00893819619115, -74.00866870283866,\n",
       "       -74.00839920948616, -74.00812971613367, -74.00786022278116,\n",
       "       -74.00759072942867,\n",
       "       ...\n",
       "       -73.86233381243262, -73.86206431908012, -73.86179482572763,\n",
       "       -73.86152533237512, -73.86125583902263, -73.86098634567013,\n",
       "       -73.86071685231764, -73.86044735896515, -73.86017786561264,\n",
       "       -73.85990837226015],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;longitude&#x27;, length=558))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-e9a00169-8101-4fa9-9cdf-9398f5581e45' class='xr-index-data-in' type='checkbox'/><label for='index-e9a00169-8101-4fa9-9cdf-9398f5581e45' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2021-06-07 15:39:15.904901&#x27;, &#x27;2021-06-07 15:39:39.787469&#x27;,\n",
       "               &#x27;2021-06-16 15:33:32.108022&#x27;, &#x27;2021-06-23 15:39:20.838143&#x27;,\n",
       "               &#x27;2021-06-23 15:39:44.720711&#x27;, &#x27;2021-07-18 15:33:37.770322&#x27;,\n",
       "               &#x27;2021-08-26 15:39:40.063072&#x27;, &#x27;2021-08-26 15:40:03.949876&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, freq=None))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-39b16bfd-b7c0-44ce-827a-ee8b68e2f286' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-39b16bfd-b7c0-44ce-827a-ee8b68e2f286' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset> Size: 4MB\n",
       "Dimensions:      (latitude: 484, longitude: 558, time: 8)\n",
       "Coordinates:\n",
       "  * latitude     (latitude) float64 4kB 40.88 40.88 40.88 ... 40.75 40.75 40.75\n",
       "  * longitude    (longitude) float64 4kB -74.01 -74.01 -74.01 ... -73.86 -73.86\n",
       "    spatial_ref  int32 4B 4326\n",
       "  * time         (time) datetime64[ns] 64B 2021-06-07T15:39:15.904901 ... 202...\n",
       "Data variables:\n",
       "    lwir11       (time, latitude, longitude) uint16 4MB dask.array<chunksize=(1, 484, 558), meta=np.ndarray>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data1 = stac_load(\n",
    "    items,\n",
    "    bands=[\"red\", \"green\", \"blue\", \"nir08\"],\n",
    "    crs=\"EPSG:4326\", # Latitude-Longitude\n",
    "    resolution=scale, # Degrees\n",
    "    chunks={\"x\": 2048, \"y\": 2048},\n",
    "    dtype=\"uint16\",\n",
    "    patch_url=planetary_computer.sign,\n",
    "    bbox=bounds\n",
    ")\n",
    "\n",
    "data2 = stac_load(\n",
    "    items,\n",
    "    bands=[\"lwir11\"],\n",
    "    crs=\"EPSG:4326\", # Latitude-Longitude\n",
    "    resolution=scale, # Degrees\n",
    "    chunks={\"x\": 2048, \"y\": 2048},\n",
    "    dtype=\"uint16\",\n",
    "    patch_url=planetary_computer.sign,\n",
    "    bbox=bounds\n",
    ")\n",
    "\n",
    "# View the dimensions of our XARRAY and the loaded variables\n",
    "# This insures we have the right coordinates and spectral bands in our xarray\n",
    "display(data1)\n",
    "display(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56d275fa-bfe5-4ea6-a3d6-1ecda95c5a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Factors for the RGB and NIR bands \n",
    "scale1 = 0.0000275 \n",
    "offset1 = -0.2 \n",
    "data1 = data1.astype(float) * scale1 + offset1\n",
    "\n",
    "# Scale Factors for the Surface Temperature band\n",
    "scale2 = 0.00341802 \n",
    "offset2 = 149.0 \n",
    "kelvin_celsius = 273.15 # convert from Kelvin to Celsius\n",
    "data2 = data2.astype(float) * scale2 + offset2 - kelvin_celsius"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3935caa1-dc9d-4277-b913-a9d40c9cbf16",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2 Save the output data in a GeoTIFF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29dfd0e9-83ba-4bf2-ac70-30ed62b9cd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one of the scenes above (numbering starts with 0)\n",
    "scene = 2\n",
    "\n",
    "filename = \"Landsat_LST.tiff\"\n",
    "\n",
    "# Only select one of the time slices to output\n",
    "data3 = data2.isel(time=scene)\n",
    "\n",
    "# Calculate the dimensions of the file\n",
    "height = data3.dims[\"latitude\"]\n",
    "width = data3.dims[\"longitude\"]\n",
    "\n",
    "# Define the Coordinate Reference System (CRS) to be common Lat-Lon coordinates\n",
    "# Define the tranformation using our bounding box so the Lat-Lon information is written to the GeoTIFF\n",
    "gt = rasterio.transform.from_bounds(lower_left[1],lower_left[0],upper_right[1],upper_right[0],width,height)\n",
    "data3.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "data3.rio.write_transform(transform=gt, inplace=True);\n",
    "\n",
    "# Create the GeoTIFF output file using the defined parameters \n",
    "with rasterio.open(filename,'w',driver='GTiff',width=width,height=height,\n",
    "                   crs='epsg:4326',transform=gt,count=1,compress='lzw',dtype='float64') as dst:\n",
    "    dst.write(data3.lwir11,1)\n",
    "    dst.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e32c697-6d5d-48fa-baa5-dac9cc465c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NDVI for the median mosaic\n",
    "ndvi_data = (data1.isel(time=scene).nir08 - data1.isel(time=scene).red) / \\\n",
    "            (data1.isel(time=scene).nir08 + data1.isel(time=scene).red)\n",
    "\n",
    "filename = \"Landsat_NDVI.tiff\"\n",
    "\n",
    "# Use .sizes to get the dimension sizes\n",
    "height = ndvi_data.sizes[\"latitude\"]\n",
    "width = ndvi_data.sizes[\"longitude\"]\n",
    "\n",
    "# Define the Coordinate Reference System (CRS) to be common Lat-Lon coordinates\n",
    "# Define the transformation using our bounding box so the Lat-Lon information is written to the GeoTIFF\n",
    "gt = rasterio.transform.from_bounds(\n",
    "    lower_left[1], lower_left[0],\n",
    "    upper_right[1], upper_right[0],\n",
    "    width, height\n",
    ")\n",
    "\n",
    "# Write CRS and transform information to the xarray DataArray\n",
    "ndvi_data.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "ndvi_data.rio.write_transform(transform=gt, inplace=True)\n",
    "\n",
    "# Create the GeoTIFF output file using the defined parameters \n",
    "with rasterio.open(\n",
    "    filename, 'w', driver='GTiff', width=width, height=height,\n",
    "    crs='epsg:4326', transform=gt, count=1, compress='lzw', dtype='float64'\n",
    ") as dst:\n",
    "    dst.write(ndvi_data.values, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28b6014f-965e-4c6b-bb58-dc0f3d1a0801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landsat_LST.tiff  Landsat_NDVI.tiff S2.tiff           S2_sample.tiff\n"
     ]
    }
   ],
   "source": [
    "# Show the location and size of the new output file\n",
    "!ls *.tiff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796faca4-2200-4135-a31d-cb5f97354998",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3. Consolidating Training Data w/ S2 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81af3c5c-07f6-406a-a206-1754e51e199a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1 Load In Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be063b1f-9655-4e7a-8b5c-e3de973f7e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Data Science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Multi-dimensional arrays and datasets\n",
    "import xarray as xr\n",
    "\n",
    "# Geospatial raster data handling\n",
    "import rioxarray as rxr\n",
    "\n",
    "# Geospatial operations\n",
    "import rasterio\n",
    "from rasterio import windows  \n",
    "from rasterio import features  \n",
    "from rasterio import warp\n",
    "from rasterio.warp import transform_bounds \n",
    "from rasterio.windows import from_bounds \n",
    "\n",
    "# Image Processing\n",
    "from PIL import Image\n",
    "\n",
    "# Coordinate transformations\n",
    "from pyproj import Proj, Transformer, CRS\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Planetary Computer Tools\n",
    "import pystac_client\n",
    "import planetary_computer as pc\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "\n",
    "# Others\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1401035a-76c5-46e5-950e-048030d60f1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.2 Response Variable\n",
    "Before building the model, we need to load in the Urban Heat Island (UHI) index training dataset. We have curated data for the New York region. The dataset consists of geo-locations (Longitude and Latitude), with additional fields including date & time of data collection and the UHI index for each location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83c3ccfd-d1af-47c8-863b-041f4a12ce18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>datetime</th>\n",
       "      <th>UHI Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-73.909167</td>\n",
       "      <td>40.813107</td>\n",
       "      <td>24-07-2021 15:53</td>\n",
       "      <td>1.030289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-73.909187</td>\n",
       "      <td>40.813045</td>\n",
       "      <td>24-07-2021 15:53</td>\n",
       "      <td>1.030289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-73.909215</td>\n",
       "      <td>40.812978</td>\n",
       "      <td>24-07-2021 15:53</td>\n",
       "      <td>1.023798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-73.909242</td>\n",
       "      <td>40.812908</td>\n",
       "      <td>24-07-2021 15:53</td>\n",
       "      <td>1.023798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-73.909257</td>\n",
       "      <td>40.812845</td>\n",
       "      <td>24-07-2021 15:53</td>\n",
       "      <td>1.021634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Longitude   Latitude          datetime  UHI Index\n",
       "0 -73.909167  40.813107  24-07-2021 15:53   1.030289\n",
       "1 -73.909187  40.813045  24-07-2021 15:53   1.030289\n",
       "2 -73.909215  40.812978  24-07-2021 15:53   1.023798\n",
       "3 -73.909242  40.812908  24-07-2021 15:53   1.023798\n",
       "4 -73.909257  40.812845  24-07-2021 15:53   1.021634"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training data from csv file and display the first few rows to inspect the data\n",
    "ground_df = pd.read_csv(\"Training_data_uhi_index.csv\")\n",
    "ground_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804d4d4f-50a1-4827-b50c-7cb11cf9a370",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3 Predictor Variables\n",
    "We gathered the predictor variables from the Sentinel-2 dataset. Sentinel-2 optical data provides high-resolution imagery that is sensitive to land surface characteristics, which are crucial for understanding urban heat dynamics. Band values such as B01 (Coastal aerosol), B06 (Red Edge), and NDVI (Normalized Difference Vegetation Index) derived from B04 (Red) and B08 (Near Infrared) could help us in estimating the UHI index. Hence, we are choosing B01, B06, and NDVI as predictor variables for this experiment.</p>\n",
    "\n",
    "<ul> \n",
    "<li>B01 - Reflectance values from the Coastal aerosol band, which help in assessing aerosol presence and improving atmospheric correction.</li>\n",
    "\n",
    "<li>B06 - Reflectance values from the Red Edge band, which provide useful information for detecting vegetation, water bodies, and urban surfaces.</li>\n",
    "\n",
    "<li>NDVI - Derived from B04 (Red) and B08 (Near Infrared), NDVI is an important indicator for vegetation health and land cover.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18f8522-e1e4-4dcc-b748-4a82e6b5f63c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.3.1 Extracting S2 data from GeoTIFF file and integrate with training dataset\n",
    "Wen used the GeoTIFF file (S2.tiff) that we previously prepared to extract the band values for the geo-locations given in the training dataset to create the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36d57dfa-37eb-4299-838b-fefd5b7a8425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated UHI dataset saved to UHI_updated_S2_indices1.csv\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define file paths\n",
    "geotiff_path = \"S2.tiff\"\n",
    "uhi_data_path = \"Training_data_uhi_index.csv\"\n",
    "uhi_updated_path = \"UHI_updated_S2_indices1.csv\"\n",
    "\n",
    "# Read the GeoTIFF\n",
    "with rasterio.open(geotiff_path) as src:\n",
    "    if src.count < 7:\n",
    "        raise ValueError(f\"The GeoTIFF file must have at least 7 bands, but it has {src.count}.\")\n",
    "    \n",
    "    B01 = src.read(1)\n",
    "    B04 = src.read(2)\n",
    "    B06 = src.read(3)\n",
    "    B08 = src.read(4)\n",
    "    B02 = src.read(5)\n",
    "    B03 = src.read(6)\n",
    "    B11 = src.read(7)\n",
    "    \n",
    "    # Calculate Spectral Indices\n",
    "    NDVI = np.divide((B08 - B04), (B08 + B04), out=np.zeros_like(B04, dtype=float), where=(B08 + B04) != 0)\n",
    "    EVI = np.divide(2.5 * (B08 - B04), (B08 + 6 * B04 - 7.5 * B02 + 1), out=np.zeros_like(B04, dtype=float), where=(B08 + 6 * B04 - 7.5 * B02 + 1) != 0)\n",
    "    GNDVI = np.divide((B08 - B03), (B08 + B03), out=np.zeros_like(B03, dtype=float), where=(B08 + B03) != 0)\n",
    "    SAVI = np.divide((B08 - B04) * (1.5), (B08 + B04 + 0.5), out=np.zeros_like(B04, dtype=float), where=(B08 + B04 + 0.5) != 0)\n",
    "    NDBI = np.divide((B11 - B08), (B11 + B08), out=np.zeros_like(B08, dtype=float), where=(B11 + B08) != 0)\n",
    "    MNDWI = np.divide((B03 - B11), (B03 + B11), out=np.zeros_like(B03, dtype=float), where=(B03 + B11) != 0)\n",
    "    NDWI = np.divide((B03 - B08), (B03 + B08), out=np.zeros_like(B03, dtype=float), where=(B03 + B08) != 0)\n",
    "    LSWI = np.divide((B08 - B11), (B08 + B11), out=np.zeros_like(B08, dtype=float), where=(B08 + B11) != 0)\n",
    "    BI = np.sqrt(B11**2 + B04**2)\n",
    "    NBAI = np.divide((B11 - B08), (B11 + B08), out=np.zeros_like(B08, dtype=float), where=(B11 + B08) != 0)\n",
    "\n",
    "    \n",
    "    # Albedo Estimation (Approximation using Red, NIR, and SWIR bands)\n",
    "    Albedo = (B02 * 0.3 + B03 * 0.3 + B04 * 0.1 + B08 * 0.2 + B11 * 0.1) / 5.0\n",
    "    \n",
    "    # Index-Based Built-Up Index (IBI)\n",
    "    IBI = np.divide(NDBI - (NDVI + MNDWI), NDBI + (NDVI + MNDWI), out=np.zeros_like(NDBI, dtype=float), where=(NDBI + (NDVI + MNDWI)) != 0)\n",
    "\n",
    "    # Get metadata for georeferencing\n",
    "    transform = src.transform\n",
    "\n",
    "# Flatten arrays and associate them with spatial coordinates\n",
    "rows, cols = np.where(~np.isnan(NDVI))  # Exclude NaN values\n",
    "lon, lat = rasterio.transform.xy(transform, rows, cols, offset='center')\n",
    "\n",
    "# Create DataFrame with spectral indices\n",
    "indices_df = pd.DataFrame({\n",
    "    \"Longitude\": lon,\n",
    "    \"Latitude\": lat,\n",
    "    \"NDVI\": NDVI[rows, cols],\n",
    "    \"EVI\": EVI[rows, cols],\n",
    "    \"GNDVI\": GNDVI[rows, cols],\n",
    "    \"SAVI\": SAVI[rows, cols],\n",
    "    \"NDBI\": NDBI[rows, cols],\n",
    "    \"MNDWI\": MNDWI[rows, cols],\n",
    "    \"NDWI\": NDWI[rows, cols],\n",
    "    \"LSWI\": LSWI[rows, cols],\n",
    "    \"BI\": BI[rows, cols],\n",
    "    \"Albedo\": Albedo[rows, cols],\n",
    "    \"IBI\": IBI[rows, cols],\n",
    "    \"NBAI\": NBAI[rows, cols]\n",
    "})\n",
    "\n",
    "# Load UHI dataset\n",
    "uhi_df = pd.read_csv(uhi_data_path)\n",
    "\n",
    "# Merge indices with UHI dataset based on spatial proximity\n",
    "indices_tree = cKDTree(indices_df[[\"Longitude\", \"Latitude\"]].values)\n",
    "distances, indices = indices_tree.query(uhi_df[[\"Longitude\", \"Latitude\"]].values)\n",
    "\n",
    "# Remove Longitude and Latitude from indices_df before merging to avoid conflicts\n",
    "indices_df_cleaned = indices_df.drop(columns=[\"Longitude\", \"Latitude\"])\n",
    "\n",
    "# Concatenate UHI dataset with spectral indices\n",
    "uhi_df = pd.concat([uhi_df, indices_df_cleaned.iloc[indices].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Save updated UHI dataset\n",
    "uhi_df.to_csv(uhi_updated_path, index=False)\n",
    "print(f\"Updated UHI dataset saved to {uhi_updated_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaf07c9-e5e5-4f1a-9fa7-43b77b7e9085",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4. Consolidating Training Data w/ Landsat Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51d02e71-f9ec-415a-8fa6-f52c62b5b7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated UHI dataset with S2 and LST saved to UHI_updated_S2_indices_LST1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import rasterio\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# File paths\n",
    "uhi_updated_path = \"UHI_updated_S2_indices1.csv\"\n",
    "lst_tiff_path = \"Landsat_LST.tiff\"\n",
    "uhi_with_lst_path = \"UHI_updated_S2_indices_LST1.csv\"\n",
    "\n",
    "# Load the UHI dataset with NDVI\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Extract LST from the GeoTIFF\n",
    "with rasterio.open(lst_tiff_path) as src:\n",
    "    lst = src.read(1)\n",
    "    transform = src.transform\n",
    "    rows, cols = lst.shape\n",
    "    lon, lat = rasterio.transform.xy(transform, *np.meshgrid(range(cols), range(rows)))\n",
    "    lon = lon.flatten()\n",
    "    lat = lat.flatten()\n",
    "    lst_flat = lst.flatten()\n",
    "\n",
    "    # Combine into a DataFrame\n",
    "    lst_df = pd.DataFrame({\n",
    "        \"Longitude\": lon,\n",
    "        \"Latitude\": lat,\n",
    "        \"LST\": lst_flat\n",
    "    }).dropna()\n",
    "\n",
    "# Merge LST with UHI dataset using spatial proximity\n",
    "lst_tree = cKDTree(lst_df[[\"Longitude\", \"Latitude\"]].values)\n",
    "distances, indices = lst_tree.query(uhi_df[[\"Longitude\", \"Latitude\"]].values)\n",
    "uhi_df[\"LST\"] = lst_df.iloc[indices][\"LST\"].values\n",
    "\n",
    "# Save the updated UHI dataset with NDVI and LST\n",
    "uhi_df.to_csv(uhi_with_lst_path, index=False)\n",
    "print(f\"Updated UHI dataset with S2 and LST saved to {uhi_with_lst_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92e2f17-4f0d-45d3-b267-dbec03cfba47",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 5. Consolidating Training Data w/ Building Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0152c062-92e4-42e0-8a66-d94ce360f730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated UHI dataset saved to UHI_updated_S2_indices_LST_building_features_final.csv\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "\n",
    "# Load the UHI dataset\n",
    "uhi_path = \"UHI_updated_S2_indices_LST1.csv\"\n",
    "uhi_df = pd.read_csv(uhi_path)\n",
    "\n",
    "# Convert UHI points to Shapely Point objects\n",
    "uhi_df[\"geometry\"] = uhi_df.apply(lambda row: Point(row[\"Longitude\"], row[\"Latitude\"]), axis=1)\n",
    "\n",
    "# Load and Parse Building Footprint KML\n",
    "building_kml_path = \"Building_Footprint.kml\"\n",
    "tree = ET.parse(building_kml_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Namespace for KML\n",
    "ns = {\"kml\": \"http://www.opengis.net/kml/2.2\"}\n",
    "\n",
    "# Extract building footprint polygons and metadata\n",
    "building_data = []\n",
    "\n",
    "for placemark in root.findall(\".//kml:Placemark\", ns):\n",
    "    polygon = placemark.find(\".//kml:Polygon\", ns)\n",
    "    if polygon is not None:\n",
    "        coordinates = polygon.find(\".//kml:coordinates\", ns).text.strip()\n",
    "        coord_list = [tuple(map(float, coord.split(\",\")[:2])) for coord in coordinates.split()]\n",
    "        if len(coord_list) > 2:  # Valid polygon\n",
    "            poly = Polygon(coord_list)\n",
    "            centroid = poly.centroid  # Get centroid for nearest neighbor search\n",
    "            building_data.append({\"geometry\": centroid, \"area\": poly.area, \"perimeter\": poly.length})\n",
    "\n",
    "# Convert building data to DataFrame\n",
    "buildings_df = pd.DataFrame(building_data)\n",
    "\n",
    "# Create KDTree for nearest building search\n",
    "building_coords = np.array([(geom.x, geom.y) for geom in buildings_df[\"geometry\"]])\n",
    "building_tree = cKDTree(building_coords)\n",
    "\n",
    "# Find the nearest building for each UHI point\n",
    "uhi_coords = np.array([(geom.x, geom.y) for geom in uhi_df[\"geometry\"]])\n",
    "distances, indices = building_tree.query(uhi_coords)\n",
    "\n",
    "# Assign building features to UHI dataset\n",
    "uhi_df[\"nearest_building_area\"] = buildings_df.iloc[indices][\"area\"].values\n",
    "uhi_df[\"nearest_building_perimeter\"] = buildings_df.iloc[indices][\"perimeter\"].values\n",
    "\n",
    "# Compute building density using KDTree (efficiently count buildings within 100m radius)\n",
    "buffer_radius = 0.05  # ~5000 meters in degrees\n",
    "counts = building_tree.query_ball_point(uhi_coords, buffer_radius)\n",
    "uhi_df[\"building_density\"] = [len(c) for c in counts]\n",
    "\n",
    "# Save updated dataset\n",
    "output_path = \"UHI_updated_S2_indices_LST_building_features_final.csv\"\n",
    "uhi_df.drop(columns=[\"geometry\"]).to_csv(output_path, index=False)\n",
    "print(f\"Updated UHI dataset saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76d31857-713e-427a-bec6-f594db13edf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/dc70y46s5qb_49mhx2v_52dc0000gn/T/ipykernel_1314/2259919649.py:9: DtypeWarning: Columns (60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  uhi_df = pd.read_csv(uhi_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated UHI dataset saved to building1.csv\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "\n",
    "# Load the UHI dataset\n",
    "uhi_path = \"Merged_UHI_HHI_HVI_GreenRoof_SVI_UHII_Data.csv\"\n",
    "uhi_df = pd.read_csv(uhi_path)\n",
    "\n",
    "# Convert UHI points to Shapely Point objects\n",
    "uhi_df[\"geometry\"] = uhi_df.apply(lambda row: Point(row[\"longitude\"], row[\"latitude\"]), axis=1)\n",
    "\n",
    "# Load and Parse Building Footprint KML\n",
    "building_kml_path = \"Building_Footprint.kml\"\n",
    "tree = ET.parse(building_kml_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Namespace for KML\n",
    "ns = {\"kml\": \"http://www.opengis.net/kml/2.2\"}\n",
    "\n",
    "# Extract building footprint polygons and metadata\n",
    "building_data = []\n",
    "\n",
    "for placemark in root.findall(\".//kml:Placemark\", ns):\n",
    "    polygon = placemark.find(\".//kml:Polygon\", ns)\n",
    "    if polygon is not None:\n",
    "        coordinates = polygon.find(\".//kml:coordinates\", ns).text.strip()\n",
    "        coord_list = [tuple(map(float, coord.split(\",\")[:2])) for coord in coordinates.split()]\n",
    "        if len(coord_list) > 2:  # Valid polygon\n",
    "            poly = Polygon(coord_list)\n",
    "            centroid = poly.centroid  # Get centroid for nearest neighbor search\n",
    "            building_data.append({\"geometry\": centroid, \"area\": poly.area, \"perimeter\": poly.length})\n",
    "\n",
    "# Convert building data to DataFrame\n",
    "buildings_df = pd.DataFrame(building_data)\n",
    "\n",
    "# Create KDTree for nearest building search\n",
    "building_coords = np.array([(geom.x, geom.y) for geom in buildings_df[\"geometry\"]])\n",
    "building_tree = cKDTree(building_coords)\n",
    "\n",
    "# Find the nearest building for each UHI point\n",
    "uhi_coords = np.array([(geom.x, geom.y) for geom in uhi_df[\"geometry\"]])\n",
    "distances, indices = building_tree.query(uhi_coords)\n",
    "\n",
    "# Assign building features to UHI dataset\n",
    "uhi_df[\"nearest_building_area\"] = buildings_df.iloc[indices][\"area\"].values\n",
    "uhi_df[\"nearest_building_perimeter\"] = buildings_df.iloc[indices][\"perimeter\"].values\n",
    "\n",
    "# Compute building density using KDTree (efficiently count buildings within 100m radius)\n",
    "buffer_radius = 0.005  # ~5000 meters in degrees\n",
    "counts = building_tree.query_ball_point(uhi_coords, buffer_radius)\n",
    "uhi_df[\"building_density\"] = [len(c) for c in counts]\n",
    "\n",
    "# Save updated dataset\n",
    "output_path = \"building1.csv\"\n",
    "uhi_df.drop(columns=[\"geometry\"]).to_csv(output_path, index=False)\n",
    "print(f\"Updated UHI dataset saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2577c321-2df0-45c3-aaae-95daf21687fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 6. Consolidating Training Data w/ Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "673d2fd2-ea29-4355-95a8-c9f2c2a7d27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in UHI DataFrame before merge:\n",
      "Index(['Longitude', 'Latitude', 'datetime', 'UHI Index', 'NDVI', 'EVI',\n",
      "       'GNDVI', 'SAVI', 'NDBI', 'MNDWI', 'NDWI', 'LSWI', 'BI', 'Albedo', 'IBI',\n",
      "       'NBAI', 'LST', 'nearest_building_area', 'nearest_building_perimeter',\n",
      "       'building_density', 'nearest_datetime', 'nearest_Latitude',\n",
      "       'nearest_Longitude'],\n",
      "      dtype='object')\n",
      "Columns in Weather DataFrame before merge:\n",
      "Index(['datetime', 'Latitude', 'Longitude', 'elevation [feet]',\n",
      "       'temp_2m [degF]', 'relative_humidity [percent]',\n",
      "       'avg_wind_speed_merge [mile/hr]', 'max_wind_speed_merge [mile/hr]',\n",
      "       'wind_speed_stddev_merge [mile/hr]', 'wind_direction_merge [degrees]',\n",
      "       'wind_direction_stddev_merge [degrees]', 'solar_insolation [W/m^2]'],\n",
      "      dtype='object')\n",
      "Cleaned dataset saved successfully: final_merged_weather_uhi_cleaned2.csv\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# -------------------------\n",
    "# Load the Datasets\n",
    "# -------------------------\n",
    "weather_data_path = \"new weather data.csv\"  # Path to weather dataset\n",
    "uhi_data_path = \"UHI_updated_S2_indices_LST_building_features_final.csv\"  # Path to UHI dataset\n",
    "\n",
    "# Load the datasets\n",
    "weather_df = pd.read_csv(weather_data_path)\n",
    "uhi_df = pd.read_csv(uhi_data_path)\n",
    "\n",
    "# -------------------------\n",
    "# Preprocess Weather Dataset\n",
    "# -------------------------\n",
    "# Drop unnecessary columns\n",
    "weather_df.drop(columns=[\"station\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Rename columns to match standard format\n",
    "weather_df.rename(columns={\n",
    "    \"latitude [degrees_north]\": \"Latitude\",\n",
    "    \"longitude [degrees_east]\": \"Longitude\",\n",
    "    \"time\": \"datetime\"\n",
    "}, inplace=True)\n",
    "\n",
    "# -------------------------\n",
    "# Handle Datetime Parsing Issues\n",
    "# -------------------------\n",
    "def parse_datetime_column(df, column_name):\n",
    "    \"\"\"Parses datetime column, removes timezone information, and handles mixed formats.\"\"\"\n",
    "    df[column_name] = df[column_name].astype(str)  # Convert to string if necessary\n",
    "\n",
    "    # Attempt parsing with multiple formats\n",
    "    def safe_parse_datetime(value):\n",
    "        try:\n",
    "            dt = parser.parse(value)  # Let dateutil handle flexible parsing\n",
    "            return dt.replace(tzinfo=None)  # Remove timezone\n",
    "        except Exception:\n",
    "            return pd.NaT  # Return NaT for unparseable values\n",
    "\n",
    "    df[column_name] = df[column_name].apply(safe_parse_datetime)  # Apply parsing\n",
    "    df.dropna(subset=[column_name], inplace=True)  # Remove invalid rows\n",
    "    df[column_name] = df[column_name].dt.strftime(\"%d-%m-%Y %H:%M\")  # Convert to uniform format\n",
    "    return df\n",
    "\n",
    "# Apply datetime parsing\n",
    "weather_df = parse_datetime_column(weather_df, \"datetime\")\n",
    "uhi_df = parse_datetime_column(uhi_df, \"datetime\")\n",
    "\n",
    "# -------------------------\n",
    "# Find Nearest Datetime Matches\n",
    "# -------------------------\n",
    "weather_df[\"datetime\"] = pd.to_datetime(weather_df[\"datetime\"], format=\"%d-%m-%Y %H:%M\")\n",
    "uhi_df[\"datetime\"] = pd.to_datetime(uhi_df[\"datetime\"], format=\"%d-%m-%Y %H:%M\")\n",
    "\n",
    "def find_nearest_time(row, weather_times):\n",
    "    \"\"\"Finds the nearest datetime in the weather dataset for a given UHI datetime.\"\"\"\n",
    "    return weather_times[np.abs(weather_times - row).argmin()]\n",
    "\n",
    "# Convert weather datetime column to numpy array for fast searching\n",
    "weather_times = weather_df[\"datetime\"].values\n",
    "\n",
    "# Apply the function to find nearest timestamps\n",
    "uhi_df[\"nearest_datetime\"] = uhi_df[\"datetime\"].apply(lambda x: find_nearest_time(x.to_numpy(), weather_times))\n",
    "\n",
    "# -------------------------\n",
    "# Find Nearest Latitude and Longitude Matches\n",
    "# -------------------------\n",
    "# Build KDTree for fast nearest-neighbor lookup on Latitude & Longitude\n",
    "weather_tree = cKDTree(weather_df[[\"Latitude\", \"Longitude\"]].values)\n",
    "\n",
    "# Find the nearest Latitude & Longitude match for each UHI record\n",
    "distances, indices = weather_tree.query(uhi_df[[\"Latitude\", \"Longitude\"]].values, k=1)\n",
    "\n",
    "# Debugging: Ensure indices are assigned correctly\n",
    "if len(indices) != len(uhi_df):\n",
    "    raise ValueError(\"Nearest neighbor search failed. Mismatched indices.\")\n",
    "\n",
    "# Assign nearest Latitude and Longitude from the weather dataset\n",
    "uhi_df[\"nearest_Latitude\"] = weather_df.iloc[indices][\"Latitude\"].values\n",
    "uhi_df[\"nearest_Longitude\"] = weather_df.iloc[indices][\"Longitude\"].values\n",
    "\n",
    "# -------------------------\n",
    "# Debugging Check Before Merge\n",
    "# -------------------------\n",
    "print(\"Columns in UHI DataFrame before merge:\")\n",
    "print(uhi_df.columns)\n",
    "\n",
    "print(\"Columns in Weather DataFrame before merge:\")\n",
    "print(weather_df.columns)\n",
    "\n",
    "# -------------------------\n",
    "# Ensure Consistent Column Names Before Merging\n",
    "# -------------------------\n",
    "# Rename datetime in weather_df\n",
    "weather_df.rename(columns={\"datetime\": \"nearest_datetime\"}, inplace=True)\n",
    "\n",
    "# Also rename Latitude and Longitude in weather_df to match the merging columns\n",
    "weather_df.rename(columns={\"Latitude\": \"nearest_Latitude\", \"Longitude\": \"nearest_Longitude\"}, inplace=True)\n",
    "\n",
    "# -------------------------\n",
    "# Merge Datasets on Nearest Matches\n",
    "# -------------------------\n",
    "merged_df = pd.merge(\n",
    "    uhi_df.drop(columns=[\"datetime\"]), \n",
    "    weather_df, \n",
    "    on=[\"nearest_Latitude\", \"nearest_Longitude\", \"nearest_datetime\"], \n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Handle Missing Values\n",
    "# -------------------------\n",
    "# Drop rows where Latitude, Longitude, nearest_Latitude, or nearest_Longitude are missing\n",
    "cleaned_df = merged_df.dropna(subset=[\"nearest_Latitude\", \"nearest_Longitude\"])\n",
    "\n",
    "# Fill missing weather-related values with column mean\n",
    "weather_columns = [\"temp_2m [degF]\", \"relative_humidity [percent]\", \"solar_insolation [W/m^2]\"]\n",
    "cleaned_df[weather_columns] = cleaned_df[weather_columns].fillna(cleaned_df[weather_columns].mean())\n",
    "\n",
    "# Fill missing UHI-related values with column median\n",
    "uhi_columns = [\"UHI Index\", \"NDVI\", \"EVI\", \"GNDVI\", \"SAVI\", \"NDBI\", \"MNDWI\", \"NDWI\", \"LSWI\", \"BI\", \"Albedo\", \"IBI\", \"LST\", \n",
    "               \"nearest_building_area\", \"nearest_building_perimeter\", \"building_density\"]\n",
    "\n",
    "cleaned_df[uhi_columns] = cleaned_df[uhi_columns].fillna(cleaned_df[uhi_columns].median())\n",
    "\n",
    "# -------------------------\n",
    "# Rename Columns for Consistency\n",
    "# -------------------------\n",
    "cleaned_df.rename(columns={\"nearest_Latitude\": \"Latitude\", \"nearest_Longitude\": \"Longitude\"}, inplace=True)\n",
    "cleaned_df.drop(columns=[\"Latitude_x\", \"Longitude_x\"], errors=\"ignore\", inplace=True)\n",
    "\n",
    "# -------------------------\n",
    "# Save the Cleaned Dataset\n",
    "# -------------------------\n",
    "cleaned_file_path = \"final_merged_weather_uhi_cleaned2.csv\"\n",
    "cleaned_df.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned dataset saved successfully: {cleaned_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e791725-8a32-4f9c-922f-17652bf6d6ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 7. Consolidating w/ heatmap data\n",
    "https://github.com/NewYorkCityCouncil/heat_map/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6eaa540e-13bc-45f0-9822-39f2defbdc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mean_temp from f_mean_temp.tif...\n",
      "Extracting temp_deviation from f_deviation.tif...\n",
      "Extracting temp_deviation_smooth from f_deviation_smooth.tif...\n",
      "Updated dataset saved to: final_merged_weather_uhi_cleaned3.csv\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rasterio.transform import rowcol\n",
    "\n",
    "# Paths to your files\n",
    "training_data_path = \"final_merged_weather_uhi_cleaned2.csv\"\n",
    "heatmap_files = {\n",
    "    \"mean_temp\": \"f_mean_temp.tif\",\n",
    "    \"temp_deviation\": \"f_deviation.tif\",\n",
    "    \"temp_deviation_smooth\": \"f_deviation_smooth.tif\",\n",
    "}\n",
    "\n",
    "# Load the training dataset\n",
    "training_data = pd.read_csv(training_data_path)\n",
    "\n",
    "# Ensure the dataset has 'Longitude' and 'Latitude' instead of 'latitude' and 'longitude'\n",
    "training_data.rename(columns={\"Longitude\": \"longitude\", \"Latitude\": \"latitude\"}, inplace=True)\n",
    "\n",
    "# Optimized function for extracting raster values\n",
    "def extract_raster_values_optimized(raster_path, latitudes, longitudes):\n",
    "    \"\"\"\n",
    "    Extracts values from a raster file (GeoTIFF) based on given latitude and longitude points.\n",
    "\n",
    "    Parameters:\n",
    "        raster_path (str): Path to the raster file.\n",
    "        latitudes (list): List of latitude values.\n",
    "        longitudes (list): List of longitude values.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Extracted raster values, with NaN for missing values.\n",
    "    \"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        transform = src.transform\n",
    "        band = src.read(1)  # Read entire raster band for faster access\n",
    "        nodata_value = src.nodata  # Get nodata value from metadata\n",
    "\n",
    "        # Convert lat/lon to row/col indices\n",
    "        rows, cols = zip(*[rowcol(transform, lon, lat) for lat, lon in zip(latitudes, longitudes)])\n",
    "\n",
    "        # Extract values using numpy indexing\n",
    "        values = np.full(len(latitudes), np.nan)  # Initialize with NaNs for missing data handling\n",
    "        for i, (row, col) in enumerate(zip(rows, cols)):\n",
    "            try:\n",
    "                value = band[row, col]\n",
    "                if value != nodata_value:  # Handle nodata values\n",
    "                    values[i] = value\n",
    "            except IndexError:\n",
    "                continue  # Skip out-of-bounds points\n",
    "\n",
    "    return values\n",
    "\n",
    "# Extract values from each heatmap file\n",
    "for feature_name, file_path in heatmap_files.items():\n",
    "    print(f\"Extracting {feature_name} from {file_path}...\")\n",
    "    training_data[feature_name] = extract_raster_values_optimized(\n",
    "        file_path, training_data[\"latitude\"], training_data[\"longitude\"]\n",
    "    )\n",
    "\n",
    "# Save the enriched dataset\n",
    "output_path = \"final_merged_weather_uhi_cleaned3.csv\"\n",
    "training_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Updated dataset saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2474eca7-dafb-48bc-94b1-4ec4528439e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 8. Intergrating with Hyperlocal data\n",
    "https://data.cityofnewyork.us/dataset/Hyperlocal-Temperature-Monitoring/qdq3-9eqn/about_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04f74a5b-1be5-455f-b9d8-fe0dcbd322b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading UHI dataset...\n",
      "Processing Hyperlocal dataset in chunks...\n",
      "Sampling 10,000 points for spatial matching...\n",
      "Building KDTree for spatial lookup...\n",
      "Finding nearest temperature matches...\n",
      "Saving integrated dataset to final_merged_weather_uhi_cleaned3_hyperlocal.csv...\n",
      "Processing complete! Integrated dataset saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# File paths\n",
    "UHI_FILE = \"final_merged_weather_uhi_cleaned3.csv\"\n",
    "HYPERLOCAL_FILE = \"Hyperlocal_Temperature_Monitoring_20250312.csv\"\n",
    "OUTPUT_FILE = \"final_merged_weather_uhi_cleaned3_hyperlocal.csv\"\n",
    "\n",
    "# Load full UHI dataset (keep all columns including UHI Index)\n",
    "print(\"Loading UHI dataset...\")\n",
    "uhi_data = pd.read_csv(UHI_FILE)\n",
    "\n",
    "# Select only required columns for faster processing\n",
    "use_cols = [\"Latitude\", \"Longitude\", \"AirTemp\", \"Year\"]\n",
    "\n",
    "# Load Hyperlocal Temperature dataset in chunks\n",
    "chunk_size = 100000  # Adjust based on available memory\n",
    "filtered_data = []\n",
    "\n",
    "print(\"Processing Hyperlocal dataset in chunks...\")\n",
    "for chunk in pd.read_csv(HYPERLOCAL_FILE, usecols=use_cols, chunksize=chunk_size):\n",
    "    # Convert temperature from Fahrenheit to Celsius\n",
    "    chunk[\"AirTemp_C\"] = (chunk[\"AirTemp\"] - 32) * 5/9\n",
    "    \n",
    "    # Filter for the year 2019 (proxy for 2021)\n",
    "    chunk = chunk[chunk[\"Year\"] == 2019]\n",
    "    \n",
    "    # Append filtered chunk\n",
    "    filtered_data.append(chunk)\n",
    "\n",
    "# Combine filtered chunks\n",
    "hyperlocal_data = pd.concat(filtered_data, ignore_index=True)\n",
    "\n",
    "# Reduce size for efficient processing (sample 10,000 points)\n",
    "print(\"Sampling 10,000 points for spatial matching...\")\n",
    "hyperlocal_sample = hyperlocal_data.sample(n=10000, random_state=42)\n",
    "\n",
    "# Build KDTree for fast nearest-neighbor search\n",
    "print(\"Building KDTree for spatial lookup...\")\n",
    "tree = cKDTree(hyperlocal_sample[[\"Latitude\", \"Longitude\"]].values)\n",
    "\n",
    "# Find nearest temperature values for UHI dataset\n",
    "print(\"Finding nearest temperature matches...\")\n",
    "uhi_coords = uhi_data[[\"latitude\", \"longitude\"]].values\n",
    "_, nearest_idx = tree.query(uhi_coords, k=1)\n",
    "\n",
    "# Assign nearest temperature values\n",
    "uhi_data[\"Nearest_AirTemp_C\"] = hyperlocal_sample.iloc[nearest_idx][\"AirTemp_C\"].values\n",
    "\n",
    "# Compute Temperature Anomaly (deviation from mean temperature)\n",
    "mean_temp_c = uhi_data[\"Nearest_AirTemp_C\"].mean()\n",
    "uhi_data[\"Temp_Anomaly\"] = uhi_data[\"Nearest_AirTemp_C\"] - mean_temp_c\n",
    "\n",
    "# Save integrated dataset (keeping all original columns + new features)\n",
    "print(f\"Saving integrated dataset to {OUTPUT_FILE}...\")\n",
    "uhi_data.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(\"Processing complete! Integrated dataset saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37596df-6c6d-4ea9-8542-eb2cbcc378f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 9. Integrating morning heat index geotiff raster with fahrenheit values\n",
    "https://osf.io/j6eqr/?view_only=\n",
    "https://github.com/OpenStoryMap/geodata/blob/main/nyc-heat-watch-2021/air-quality.geojson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb1e412-6a23-4341-aac7-0b0a06cad129",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### af_hi_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acbe997e-eec1-43d0-8f35-d91247b28d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated training data with raster features saved to: final_merged_weather_uhi_cleaned3_hyperlocal_afhi.csv\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyproj import Transformer\n",
    "\n",
    "# Load the training dataset\n",
    "training_data_path = \"final_merged_weather_uhi_cleaned3_hyperlocal.csv\"  # Update path\n",
    "training_data = pd.read_csv(training_data_path)\n",
    "\n",
    "# Load the raster file\n",
    "raster_path = \"af_hi_f.tif\"  # Update path\n",
    "with rasterio.open(raster_path) as src:\n",
    "    raster_crs = src.crs  # Get CRS of raster\n",
    "    raster_transform = src.transform  # Get affine transform\n",
    "\n",
    "    # Transformer to convert lat/lon (WGS84) to raster CRS\n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", raster_crs, always_xy=True)\n",
    "\n",
    "    # Function to get raster values at lat/lon points\n",
    "    def get_raster_values(lat, lon):\n",
    "        try:\n",
    "            # Convert lat/lon to raster CRS\n",
    "            x, y = transformer.transform(lon, lat)\n",
    "            row, col = rasterio.transform.rowcol(raster_transform, x, y)\n",
    "\n",
    "            # Check if coordinates are within raster bounds\n",
    "            if 0 <= row < src.height and 0 <= col < src.width:\n",
    "                return src.read(1)[row, col]  # Extract raster value\n",
    "            else:\n",
    "                return np.nan  # Out of bounds\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    # Apply raster value extraction for each row in the dataset\n",
    "    training_data[\"af_hi_f_value\"] = training_data.apply(\n",
    "        lambda row: get_raster_values(row[\"latitude\"], row[\"longitude\"]), axis=1\n",
    "    )\n",
    "\n",
    "# Save the updated dataset to a new CSV file\n",
    "output_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_afhi.csv\"\n",
    "training_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Updated training data with raster features saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d38eee-9370-4c72-b7ec-38110c4ea282",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### am_hi_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0077dc87-516d-4723-83a5-988b651b8660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated training data with raster features saved to: final_merged_weather_uhi_cleaned3_hyperlocal_amhi.csv\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyproj import Transformer\n",
    "\n",
    "# Load the training dataset\n",
    "training_data_path = \"final_merged_weather_uhi_cleaned3_hyperlocal.csv\"  # Update path\n",
    "training_data = pd.read_csv(training_data_path)\n",
    "\n",
    "# Load the raster file\n",
    "raster_path = \"am_hi_f.tif\"  # Update path\n",
    "with rasterio.open(raster_path) as src:\n",
    "    raster_crs = src.crs  # Get CRS of raster\n",
    "    raster_transform = src.transform  # Get affine transform\n",
    "\n",
    "    # Transformer to convert lat/lon (WGS84) to raster CRS\n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", raster_crs, always_xy=True)\n",
    "\n",
    "    # Function to get raster values at lat/lon points\n",
    "    def get_raster_values(lat, lon):\n",
    "        try:\n",
    "            # Convert lat/lon to raster CRS\n",
    "            x, y = transformer.transform(lon, lat)\n",
    "            row, col = rasterio.transform.rowcol(raster_transform, x, y)\n",
    "\n",
    "            # Check if coordinates are within raster bounds\n",
    "            if 0 <= row < src.height and 0 <= col < src.width:\n",
    "                return src.read(1)[row, col]  # Extract raster value\n",
    "            else:\n",
    "                return np.nan  # Out of bounds\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    # Apply raster value extraction for each row in the dataset\n",
    "    training_data[\"am_hi_f_value\"] = training_data.apply(\n",
    "        lambda row: get_raster_values(row[\"latitude\"], row[\"longitude\"]), axis=1\n",
    "    )\n",
    "\n",
    "# Save the updated dataset to a new CSV file\n",
    "output_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_amhi.csv\"\n",
    "training_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Updated training data with raster features saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e4475f-6fbe-46d6-97df-5b374c8cd923",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### pm_hi_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c52fc905-bc5a-43f2-832e-fff1e392d8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated training data with raster features saved to: final_merged_weather_uhi_cleaned3_hyperlocal_pmhi.csv\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyproj import Transformer\n",
    "\n",
    "# Load the training dataset\n",
    "training_data_path = \"final_merged_weather_uhi_cleaned3_hyperlocal.csv\"  # Update path\n",
    "training_data = pd.read_csv(training_data_path)\n",
    "\n",
    "# Load the raster file\n",
    "raster_path = \"pm_hi_f.tif\"  # Update path\n",
    "with rasterio.open(raster_path) as src:\n",
    "    raster_crs = src.crs  # Get CRS of raster\n",
    "    raster_transform = src.transform  # Get affine transform\n",
    "\n",
    "    # Transformer to convert lat/lon (WGS84) to raster CRS\n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", raster_crs, always_xy=True)\n",
    "\n",
    "    # Function to get raster values at lat/lon points\n",
    "    def get_raster_values(lat, lon):\n",
    "        try:\n",
    "            # Convert lat/lon to raster CRS\n",
    "            x, y = transformer.transform(lon, lat)\n",
    "            row, col = rasterio.transform.rowcol(raster_transform, x, y)\n",
    "\n",
    "            # Check if coordinates are within raster bounds\n",
    "            if 0 <= row < src.height and 0 <= col < src.width:\n",
    "                return src.read(1)[row, col]  # Extract raster value\n",
    "            else:\n",
    "                return np.nan  # Out of bounds\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    # Apply raster value extraction for each row in the dataset\n",
    "    training_data[\"pm_hi_f_value\"] = training_data.apply(\n",
    "        lambda row: get_raster_values(row[\"latitude\"], row[\"longitude\"]), axis=1\n",
    "    )\n",
    "\n",
    "# Save the updated dataset to a new CSV file\n",
    "output_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_pmhi.csv\"\n",
    "training_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Updated training data with raster features saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d4b73f-1d6e-4642-a159-5e35290a09d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### af_t_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f103e06c-ddc9-408a-8e2c-c8ad0ed96f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated training data with raster features saved to: final_merged_weather_uhi_cleaned3_hyperlocal_aft.csv\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyproj import Transformer\n",
    "\n",
    "# Load the training dataset\n",
    "training_data_path = \"final_merged_weather_uhi_cleaned3_hyperlocal.csv\"  # Update path\n",
    "training_data = pd.read_csv(training_data_path)\n",
    "\n",
    "# Load the raster file\n",
    "raster_path = \"af_t_f.tif\"  # Update path\n",
    "with rasterio.open(raster_path) as src:\n",
    "    raster_crs = src.crs  # Get CRS of raster\n",
    "    raster_transform = src.transform  # Get affine transform\n",
    "\n",
    "    # Transformer to convert lat/lon (WGS84) to raster CRS\n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", raster_crs, always_xy=True)\n",
    "\n",
    "    # Function to get raster values at lat/lon points\n",
    "    def get_raster_values(lat, lon):\n",
    "        try:\n",
    "            # Convert lat/lon to raster CRS\n",
    "            x, y = transformer.transform(lon, lat)\n",
    "            row, col = rasterio.transform.rowcol(raster_transform, x, y)\n",
    "\n",
    "            # Check if coordinates are within raster bounds\n",
    "            if 0 <= row < src.height and 0 <= col < src.width:\n",
    "                return src.read(1)[row, col]  # Extract raster value\n",
    "            else:\n",
    "                return np.nan  # Out of bounds\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    # Apply raster value extraction for each row in the dataset\n",
    "    training_data[\"af_t_f_value\"] = training_data.apply(\n",
    "        lambda row: get_raster_values(row[\"latitude\"], row[\"longitude\"]), axis=1\n",
    "    )\n",
    "\n",
    "# Save the updated dataset to a new CSV file\n",
    "output_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_aft.csv\"\n",
    "training_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Updated training data with raster features saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4d12e1-08a2-452d-8758-e6fc5e78be39",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### am_t_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e8b75bb-fcab-45fb-ade3-8339164c1c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated training data with raster features saved to: final_merged_weather_uhi_cleaned3_hyperlocal_amt.csv\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyproj import Transformer\n",
    "\n",
    "# Load the training dataset\n",
    "training_data_path = \"final_merged_weather_uhi_cleaned3_hyperlocal.csv\"  # Update path\n",
    "training_data = pd.read_csv(training_data_path)\n",
    "\n",
    "# Load the raster file\n",
    "raster_path = \"am_t_f.tif\"  # Update path\n",
    "with rasterio.open(raster_path) as src:\n",
    "    raster_crs = src.crs  # Get CRS of raster\n",
    "    raster_transform = src.transform  # Get affine transform\n",
    "\n",
    "    # Transformer to convert lat/lon (WGS84) to raster CRS\n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", raster_crs, always_xy=True)\n",
    "\n",
    "    # Function to get raster values at lat/lon points\n",
    "    def get_raster_values(lat, lon):\n",
    "        try:\n",
    "            # Convert lat/lon to raster CRS\n",
    "            x, y = transformer.transform(lon, lat)\n",
    "            row, col = rasterio.transform.rowcol(raster_transform, x, y)\n",
    "\n",
    "            # Check if coordinates are within raster bounds\n",
    "            if 0 <= row < src.height and 0 <= col < src.width:\n",
    "                return src.read(1)[row, col]  # Extract raster value\n",
    "            else:\n",
    "                return np.nan  # Out of bounds\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    # Apply raster value extraction for each row in the dataset\n",
    "    training_data[\"am_t_f_value\"] = training_data.apply(\n",
    "        lambda row: get_raster_values(row[\"latitude\"], row[\"longitude\"]), axis=1\n",
    "    )\n",
    "\n",
    "# Save the updated dataset to a new CSV file\n",
    "output_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_amt.csv\"\n",
    "training_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Updated training data with raster features saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0992a826-1041-4003-b9a5-314daee6abcb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### pm_t_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73ae0720-3ad5-469d-8730-98642b4db438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated training data with raster features saved to: final_merged_weather_uhi_cleaned3_hyperlocal_pmt.csv\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyproj import Transformer\n",
    "\n",
    "# Load the training dataset\n",
    "training_data_path = \"final_merged_weather_uhi_cleaned3_hyperlocal.csv\"  # Update path\n",
    "training_data = pd.read_csv(training_data_path)\n",
    "\n",
    "# Load the raster file\n",
    "raster_path = \"pm_t_f.tif\"  # Update path\n",
    "with rasterio.open(raster_path) as src:\n",
    "    raster_crs = src.crs  # Get CRS of raster\n",
    "    raster_transform = src.transform  # Get affine transform\n",
    "\n",
    "    # Transformer to convert lat/lon (WGS84) to raster CRS\n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", raster_crs, always_xy=True)\n",
    "\n",
    "    # Function to get raster values at lat/lon points\n",
    "    def get_raster_values(lat, lon):\n",
    "        try:\n",
    "            # Convert lat/lon to raster CRS\n",
    "            x, y = transformer.transform(lon, lat)\n",
    "            row, col = rasterio.transform.rowcol(raster_transform, x, y)\n",
    "\n",
    "            # Check if coordinates are within raster bounds\n",
    "            if 0 <= row < src.height and 0 <= col < src.width:\n",
    "                return src.read(1)[row, col]  # Extract raster value\n",
    "            else:\n",
    "                return np.nan  # Out of bounds\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    # Apply raster value extraction for each row in the dataset\n",
    "    training_data[\"pm_t_f_value\"] = training_data.apply(\n",
    "        lambda row: get_raster_values(row[\"latitude\"], row[\"longitude\"]), axis=1\n",
    "    )\n",
    "\n",
    "# Save the updated dataset to a new CSV file\n",
    "output_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_pmt.csv\"\n",
    "training_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Updated training data with raster features saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a6b090-200f-4eb0-9363-ef5a9b28004f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Consolidated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "708cff4b-ff32-4b66-9b76-0a2af803d790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: af_hi_f.tif\n",
      "Processing: af_t_f.tif\n",
      "Processing: am_hi_f.tif\n",
      "Processing: am_t_f.tif\n",
      "Processing: pm_hi_f.tif\n",
      "Processing: pm_t_f.tif\n",
      "Updated training data with raster features saved to: final_merged_weather_uhi_cleaned3_hyperlocal_all.csv\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyproj import Transformer\n",
    "\n",
    "# Define paths to all raster (TIFF) files\n",
    "tif_files = {\n",
    "    \"af_hi_f\": \"af_hi_f.tif\",\n",
    "    \"af_t_f\": \"af_t_f.tif\",\n",
    "    \"am_hi_f\": \"am_hi_f.tif\",\n",
    "    \"am_t_f\": \"am_t_f.tif\",\n",
    "    \"pm_hi_f\": \"pm_hi_f.tif\",\n",
    "    \"pm_t_f\": \"pm_t_f.tif\",\n",
    "}\n",
    "\n",
    "# Load the training dataset\n",
    "training_data_path = \"final_merged_weather_uhi_cleaned3_hyperlocal.csv\"  # Update if necessary\n",
    "training_data = pd.read_csv(training_data_path)\n",
    "\n",
    "# Initialize storage for raster values\n",
    "for key in tif_files.keys():\n",
    "    training_data[key] = np.nan\n",
    "\n",
    "# Function to extract raster values at lat/lon points\n",
    "def get_raster_values(lat, lon, raster_path):\n",
    "    try:\n",
    "        with rasterio.open(raster_path) as src:\n",
    "            raster_crs = src.crs\n",
    "            transformer = Transformer.from_crs(\"EPSG:4326\", raster_crs, always_xy=True)\n",
    "\n",
    "            # Convert lat/lon to raster CRS\n",
    "            x, y = transformer.transform(lon, lat)\n",
    "            row, col = rasterio.transform.rowcol(src.transform, x, y)\n",
    "\n",
    "            # Validate coordinates within bounds\n",
    "            if 0 <= row < src.height and 0 <= col < src.width:\n",
    "                return src.read(1)[row, col]  # Extract raster value\n",
    "            else:\n",
    "                return np.nan\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# Iterate through TIFF files and extract raster values\n",
    "for key, raster_path in tif_files.items():\n",
    "    print(f\"Processing: {raster_path}\")\n",
    "    training_data[key] = training_data.apply(\n",
    "        lambda row: get_raster_values(row[\"latitude\"], row[\"longitude\"], raster_path), axis=1\n",
    "    )\n",
    "\n",
    "# Save the updated dataset to a new CSV file\n",
    "output_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_all.csv\"\n",
    "training_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Updated training data with raster features saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf55629-7d54-4918-b006-633dd62db30e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 10. Integrating PLUTO Data \n",
    "Extensive land use and geographic data at the tax lot level in comma–separated values\n",
    "https://www.nyc.gov/site/planning/data-maps/open-data/dwn-pluto-mappluto.page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5430a8bf-b76c-4ec6-a3bf-56fcbac6d6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UHI Dataset Columns: Index(['longitude', 'latitude', 'UHI Index', 'NDVI', 'EVI', 'GNDVI', 'SAVI',\n",
      "       'NDBI', 'MNDWI', 'NDWI', 'LSWI', 'BI', 'Albedo', 'IBI', 'NBAI', 'LST',\n",
      "       'nearest_building_area', 'nearest_building_perimeter',\n",
      "       'building_density', 'nearest_datetime', 'Latitude.1', 'Longitude.1',\n",
      "       'elevation [feet]', 'temp_2m [degF]', 'relative_humidity [percent]',\n",
      "       'avg_wind_speed_merge [mile/hr]', 'max_wind_speed_merge [mile/hr]',\n",
      "       'wind_speed_stddev_merge [mile/hr]', 'wind_direction_merge [degrees]',\n",
      "       'wind_direction_stddev_merge [degrees]', 'solar_insolation [W/m^2]',\n",
      "       'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
      "       'Nearest_AirTemp_C', 'Temp_Anomaly', 'af_hi_f', 'af_t_f', 'am_hi_f',\n",
      "       'am_t_f', 'pm_hi_f', 'pm_t_f'],\n",
      "      dtype='object')\n",
      "PLUTO Dataset Columns: Index(['borough', 'block', 'lot', 'cd', 'bct2020', 'bctcb2020', 'ct2010',\n",
      "       'cb2010', 'schooldist', 'council', 'zipcode', 'firecomp', 'policeprct',\n",
      "       'healthcenterdistrict', 'healtharea', 'sanitboro', 'sanitdistrict',\n",
      "       'sanitsub', 'address', 'zonedist1', 'zonedist2', 'zonedist3',\n",
      "       'zonedist4', 'overlay1', 'overlay2', 'spdist1', 'spdist2', 'spdist3',\n",
      "       'ltdheight', 'splitzone', 'bldgclass', 'landuse', 'easements',\n",
      "       'ownertype', 'ownername', 'lotarea', 'bldgarea', 'comarea', 'resarea',\n",
      "       'officearea', 'retailarea', 'garagearea', 'strgearea', 'factryarea',\n",
      "       'otherarea', 'areasource', 'numbldgs', 'numfloors', 'unitsres',\n",
      "       'unitstotal', 'lotfront', 'lotdepth', 'bldgfront', 'bldgdepth', 'ext',\n",
      "       'proxcode', 'irrlotcode', 'lottype', 'bsmtcode', 'assessland',\n",
      "       'assesstot', 'exempttot', 'yearbuilt', 'yearalter1', 'yearalter2',\n",
      "       'histdist', 'landmark', 'builtfar', 'residfar', 'commfar', 'facilfar',\n",
      "       'borocode', 'bbl', 'condono', 'tract2010', 'xcoord', 'ycoord',\n",
      "       'zonemap', 'zmcode', 'sanborn', 'taxmap', 'edesignum', 'appbbl',\n",
      "       'appdate', 'plutomapid', 'firm07_flag', 'pfirm15_flag', 'version',\n",
      "       'dcpedited', 'latitude', 'longitude', 'notes'],\n",
      "      dtype='object')\n",
      "PLUTO coordinates DataFrame shape after cleaning: (857421, 2)\n",
      "PLUTO coordinates sample:     latitude  longitude\n",
      "0  40.625779 -73.953658\n",
      "1  40.664671 -73.956901\n",
      "2  40.665104 -73.955675\n",
      "3  40.666423 -73.958074\n",
      "4  40.665062 -73.958101\n",
      "UHI Coordinates Shape: (11229, 2)\n",
      "PLUTO Coordinates Shape: (857421, 2)\n",
      "Spatial join completed. Output saved to: uhi_pluto.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# File paths (Update these to match your local setup)\n",
    "UUHI_FILE = \"final_merged_weather_uhi_cleaned3_hyperlocal_all.csv\"\n",
    "PLUTO_FILE = \"pluto_24v4_1.csv\"\n",
    "OUTPUT_FILE = \"uhi_pluto.csv\"\n",
    "\n",
    "# Load the UHI dataset\n",
    "uhi_data = pd.read_csv(UUHI_FILE)\n",
    "\n",
    "# Load the PLUTO dataset\n",
    "pluto_data = pd.read_csv(PLUTO_FILE, low_memory=False)\n",
    "\n",
    "# Print column names to debug\n",
    "print(\"UHI Dataset Columns:\", uhi_data.columns)\n",
    "print(\"PLUTO Dataset Columns:\", pluto_data.columns)\n",
    "\n",
    "# Create a new DataFrame with just latitude and longitude from PLUTO\n",
    "# Based on the output, use the 'latitude' and 'longitude' columns directly\n",
    "pluto_coords_df = pd.DataFrame()\n",
    "pluto_coords_df['latitude'] = pluto_data['latitude']\n",
    "pluto_coords_df['longitude'] = pluto_data['longitude']\n",
    "pluto_coords_df = pluto_coords_df.dropna()\n",
    "\n",
    "# Print debugging information\n",
    "print(\"PLUTO coordinates DataFrame shape after cleaning:\", pluto_coords_df.shape)\n",
    "print(\"PLUTO coordinates sample:\", pluto_coords_df.head())\n",
    "\n",
    "# Convert to 2D numpy arrays\n",
    "uhi_coords = uhi_data[['latitude', 'longitude']].values\n",
    "pluto_coords = pluto_coords_df[['latitude', 'longitude']].values\n",
    "\n",
    "# Verify shapes before KDTree\n",
    "print(\"UHI Coordinates Shape:\", uhi_coords.shape)\n",
    "print(\"PLUTO Coordinates Shape:\", pluto_coords.shape)\n",
    "\n",
    "# Build a KDTree for fast spatial lookup\n",
    "pluto_tree = cKDTree(pluto_coords)\n",
    "\n",
    "# Find the nearest PLUTO tax lot for each UHI point\n",
    "distances, indices = pluto_tree.query(uhi_coords, k=1)\n",
    "\n",
    "# Attach the closest PLUTO lot data to the UHI dataset\n",
    "uhi_data['nearest_pluto_index'] = indices\n",
    "uhi_data['pluto_distance'] = distances\n",
    "\n",
    "# Save the indices of pluto_coords_df for later merging\n",
    "pluto_coords_df = pluto_coords_df.reset_index()\n",
    "\n",
    "# Merge UHI data with corresponding PLUTO tax lot attributes\n",
    "result = pd.merge(\n",
    "    uhi_data,\n",
    "    pluto_coords_df,\n",
    "    left_on='nearest_pluto_index',\n",
    "    right_on='index',\n",
    "    how='left',\n",
    "    suffixes=('', '_pluto')\n",
    ")\n",
    "\n",
    "# Create a temporary index in the original pluto_data for merging\n",
    "pluto_data['temp_index'] = range(len(pluto_data))\n",
    "\n",
    "# Merge with the full PLUTO dataset to get all attributes\n",
    "final_result = pd.merge(\n",
    "    result,\n",
    "    pluto_data,\n",
    "    left_on=['latitude_pluto', 'longitude_pluto'],\n",
    "    right_on=['latitude', 'longitude'],\n",
    "    how='left',\n",
    "    suffixes=('', '_full_pluto')\n",
    ")\n",
    "\n",
    "# Clean up temporary columns\n",
    "columns_to_drop = ['index', 'latitude_pluto', 'longitude_pluto']\n",
    "final_result = final_result.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Save the output\n",
    "final_result.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"Spatial join completed. Output saved to: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d82d54b8-a3fa-432e-95ce-17f616c7d198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/dc70y46s5qb_49mhx2v_52dc0000gn/T/ipykernel_12125/1348038454.py:6: DtypeWarning: Columns (64,65,67,68,69,70,72,122,125) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (30749, 137)\n",
      "Found 3 completely empty columns:\n",
      "['zonedist4', 'spdist3', 'notes']\n",
      "Found 10 columns with more than 99.0% missing values:\n",
      "['zonedist3', 'zonedist4', 'overlay2', 'spdist2', 'spdist3', 'ltdheight', 'landmark', 'zmcode', 'edesignum', 'notes']\n",
      "Shape after removing completely empty columns: (30749, 134)\n",
      "Shape after removing both empty and high-missing columns: (30749, 127)\n",
      "Cleaned dataset saved to: uhi_pluto_cleaned.csv\n",
      "Stricter cleaned dataset saved to: uhi_pluto_cleaned_strict.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the merged dataset\n",
    "file_path = \"uhi_pluto.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Print original shape\n",
    "print(f\"Original dataset shape: {data.shape}\")\n",
    "\n",
    "# Method 1: Identify completely empty columns (all NaN or empty strings)\n",
    "empty_columns = []\n",
    "for column in data.columns:\n",
    "    # Check if column is all NaN\n",
    "    if data[column].isna().all():\n",
    "        empty_columns.append(column)\n",
    "    # Check if column contains strings and all are empty\n",
    "    elif data[column].dtype == 'object' and (data[column].fillna('') == '').all():\n",
    "        empty_columns.append(column)\n",
    "\n",
    "print(f\"Found {len(empty_columns)} completely empty columns:\")\n",
    "print(empty_columns)\n",
    "\n",
    "# Method 2: Identify columns with missing values above a threshold\n",
    "threshold = 0.99  # 99% missing values\n",
    "high_missing_columns = [column for column in data.columns \n",
    "                       if data[column].isna().mean() > threshold]\n",
    "\n",
    "print(f\"Found {len(high_missing_columns)} columns with more than {threshold*100}% missing values:\")\n",
    "print(high_missing_columns)\n",
    "\n",
    "# Remove completely empty columns\n",
    "data_cleaned = data.drop(columns=empty_columns)\n",
    "print(f\"Shape after removing completely empty columns: {data_cleaned.shape}\")\n",
    "\n",
    "# Optional: Also remove columns with high percentage of missing values\n",
    "data_cleaned_strict = data.drop(columns=list(set(empty_columns + high_missing_columns)))\n",
    "print(f\"Shape after removing both empty and high-missing columns: {data_cleaned_strict.shape}\")\n",
    "\n",
    "# Save the cleaned dataset\n",
    "output_file = \"uhi_pluto_cleaned.csv\"\n",
    "data_cleaned.to_csv(output_file, index=False)\n",
    "print(f\"Cleaned dataset saved to: {output_file}\")\n",
    "\n",
    "# Optional: Save the stricter cleaned dataset \n",
    "output_file_strict = \"uhi_pluto_cleaned_strict.csv\"\n",
    "data_cleaned_strict.to_csv(output_file_strict, index=False)\n",
    "print(f\"Stricter cleaned dataset saved to: {output_file_strict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15a5d5c3-8e5e-4ae6-9361-e3abb2b9d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"uhi_pluto_cleaned_strict.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define the required columns\n",
    "required_columns = [\n",
    "    'longitude', 'latitude', 'UHI Index', \n",
    "    'NDVI', 'EVI', 'GNDVI', 'SAVI', 'NDBI', 'MNDWI', 'NDWI', 'LSWI', 'BI', 'Albedo', 'IBI', 'NBAI', 'LST', \n",
    "    'nearest_building_area', 'nearest_building_perimeter', 'building_density', 'nearest_datetime', \n",
    "    'Latitude.1', 'Longitude.1', 'elevation [feet]', 'temp_2m [degF]', 'relative_humidity [percent]', \n",
    "    'avg_wind_speed_merge [mile/hr]', 'max_wind_speed_merge [mile/hr]', 'wind_speed_stddev_merge [mile/hr]', \n",
    "    'wind_direction_merge [degrees]', 'wind_direction_stddev_merge [degrees]', 'solar_insolation [W/m^2]', \n",
    "    'mean_temp','temp_deviation', 'temp_deviation_smooth', 'Nearest_AirTemp_C', 'Temp_Anomaly', \n",
    "    'af_hi_f', 'af_t_f', 'am_hi_f', 'am_t_f', 'pm_hi_f', 'pm_t_f', \n",
    "    \"bldgarea\", \"numfloors\", \"unitsres\", \"unitstotal\", \"bldgfront\", \"bldgdepth\",\n",
    "    \"lotarea\", \"residfar\", \"commfar\", \"facilfar\", \"garagearea\", \"strgearea\", \"factryarea\",\n",
    "    \"assessland\", \"yearbuilt\", \"yearalter1\", \"yearalter2\", \"temp_index\"\n",
    "]\n",
    "\n",
    "# Keep only the required columns that exist in the dataset\n",
    "df_cleaned = df[[col for col in required_columns if col in df.columns]]\n",
    "\n",
    "# Save the cleaned dataset\n",
    "cleaned_file_path = \"uhi_pluto_cleaned_filtered.csv\"\n",
    "df_cleaned.to_csv(cleaned_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac702c6c-a398-4ecc-9368-24e7e7b2230f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 11. Heat & Health Index (HHI) Data\n",
    "https://ephtracking.cdc.gov/Applications/heatTracker/?page=detail3\n",
    "\n",
    "https://catalog.data.gov/dataset/modified-zip-code-tabulation-areas-modzcta\n",
    "\n",
    "https://data.cityofnewyork.us/Health/Modified-Zip-Code-Tabulation-Areas-MODZCTA-/pri4-ifjk/about_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f274521f-eb47-4bc1-963b-3eca9d709a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved as Merged_UHI_HHI_Data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import Point\n",
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "\n",
    "# Load datasets\n",
    "uhi_data_path = \"uhi_pluto_cleaned_filtered.csv\"\n",
    "hhi_data_path = \"HHI Data 2024 United States.xlsx\"\n",
    "zip_code_data_path = \"Modified_Zip_Code_Tabulation_Areas__MODZCTA_.csv\"\n",
    "\n",
    "uhi_data = pd.read_csv(uhi_data_path)\n",
    "hhi_data = pd.read_excel(hhi_data_path, sheet_name=\"Sheet1\")\n",
    "zip_code_data = pd.read_csv(zip_code_data_path)\n",
    "\n",
    "# Convert ZIP geometries to centroids for easier spatial join\n",
    "zip_code_data[\"centroid\"] = zip_code_data[\"the_geom\"].apply(lambda x: loads(x).centroid if pd.notnull(x) else None)\n",
    "\n",
    "# Extract latitude and longitude for ZIP centroids\n",
    "zip_code_data[\"latitude\"] = zip_code_data[\"centroid\"].apply(lambda x: x.y if x else None)\n",
    "zip_code_data[\"longitude\"] = zip_code_data[\"centroid\"].apply(lambda x: x.x if x else None)\n",
    "\n",
    "# Remove invalid ZIP centroids\n",
    "zip_code_data.dropna(subset=[\"latitude\", \"longitude\"], inplace=True)\n",
    "\n",
    "# Use KDTree to find the nearest ZIP centroid for each UHI point\n",
    "uhi_coords = np.array(list(zip(uhi_data[\"latitude\"], uhi_data[\"longitude\"])))\n",
    "zip_coords = np.array(list(zip(zip_code_data[\"latitude\"], zip_code_data[\"longitude\"])))\n",
    "zip_tree = cKDTree(zip_coords)\n",
    "_, nearest_zip_idx = zip_tree.query(uhi_coords)\n",
    "\n",
    "# Assign the nearest ZIP code to each UHI point\n",
    "uhi_data[\"ZCTA\"] = zip_code_data.iloc[nearest_zip_idx][\"ZCTA\"].values\n",
    "\n",
    "# Convert ZIP code column types to string for merging\n",
    "uhi_data[\"ZCTA\"] = uhi_data[\"ZCTA\"].astype(str)\n",
    "hhi_data[\"ZCTA\"] = hhi_data[\"ZCTA\"].astype(str)\n",
    "\n",
    "# Merge UHI data with HHI data\n",
    "merged_data = uhi_data.merge(hhi_data, on=\"ZCTA\", how=\"left\")\n",
    "\n",
    "# Save the merged dataset\n",
    "merged_data.to_csv(\"Merged_UHI_HHI_Data.csv\", index=False)\n",
    "\n",
    "print(\"Merged dataset saved as Merged_UHI_HHI_Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66f1fa0-07d8-4969-aee5-fdb2f7f2654a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 12. Heat Vulnerability Index Rankings (HVI)\n",
    "https://data.cityofnewyork.us/Health/Heat-Vulnerability-Index-Rankings/4mhf-duep/about_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6ebfcee0-db5e-4c38-b717-14dabba319bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/dc70y46s5qb_49mhx2v_52dc0000gn/T/ipykernel_12125/1603968182.py:7: DtypeWarning: Columns (60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  uhi_hhi_data = pd.read_csv(uhi_hhi_data_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved as Merged_UHI_HHI_HVI_Data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "uhi_hhi_data_path = \"Merged_UHI_HHI_Data.csv\"\n",
    "hvi_data_path = \"Heat_Vulnerability_Index_Rankings_20250315.csv\"\n",
    "\n",
    "uhi_hhi_data = pd.read_csv(uhi_hhi_data_path)\n",
    "hvi_data = pd.read_csv(hvi_data_path)\n",
    "\n",
    "# Rename HVI columns for consistency\n",
    "hvi_data.rename(columns={\"ZIP Code Tabulation Area (ZCTA) 2020\": \"ZCTA\", \n",
    "                         \"Heat Vulnerability Index (HVI)\": \"HVI\"}, inplace=True)\n",
    "\n",
    "# Convert ZCTA to string for consistent merging\n",
    "uhi_hhi_data[\"ZCTA\"] = uhi_hhi_data[\"ZCTA\"].astype(str)\n",
    "hvi_data[\"ZCTA\"] = hvi_data[\"ZCTA\"].astype(str)\n",
    "\n",
    "# Merge HVI data into the existing dataset using ZCTA\n",
    "final_merged_data = uhi_hhi_data.merge(hvi_data, on=\"ZCTA\", how=\"left\")\n",
    "\n",
    "# Save the updated dataset\n",
    "final_merged_data_path = \"Merged_UHI_HHI_HVI_Data.csv\"\n",
    "final_merged_data.to_csv(final_merged_data_path, index=False)\n",
    "\n",
    "print(\"Merged dataset saved as Merged_UHI_HHI_HVI_Data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371dbc7e-7d20-46ff-a856-7868f64d9d61",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 13. Greenroof Data\n",
    "https://zenodo.org/records/1469674\n",
    "https://github.com/tnc-ny-science/NYC_GreenRoofMapping/tree/master/greenroof_gisdata/CurrentDatasets\n",
    "https://github.com/CityOfNewYork/nyc-geo-metadata/blob/main/Metadata/Metadata_BuildingFootprints.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "24d967e8-bf66-4bdc-9c09-31e0aba24485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/dc70y46s5qb_49mhx2v_52dc0000gn/T/ipykernel_12125/2089168156.py:11: DtypeWarning: Columns (60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  merged_df = pd.read_csv(merged_data_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset saved as: Merged_UHI_HHI_HVI_GreenRoof_Data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "\n",
    "# File paths\n",
    "merged_data_file = \"Merged_UHI_HHI_HVI_Data.csv\"\n",
    "green_roof_file = \"GreenRoofData2016_20180917.csv\"\n",
    "\n",
    "# Load merged UHI-HHI-HVI data\n",
    "merged_df = pd.read_csv(merged_data_file)\n",
    "\n",
    "# Load Green Roof data\n",
    "green_roof_df = pd.read_csv(green_roof_file)\n",
    "\n",
    "# Create Point objects for spatial operations\n",
    "merged_df[\"geometry\"] = merged_df.apply(lambda row: Point(row[\"longitude\"], row[\"latitude\"]), axis=1)\n",
    "green_roof_df[\"geometry\"] = green_roof_df.apply(lambda row: Point(row[\"xcoord\"], row[\"ycoord\"]), axis=1)\n",
    "\n",
    "# Convert coordinates to NumPy arrays for KDTree\n",
    "merged_coords = np.array([[point.x, point.y] for point in merged_df[\"geometry\"]])\n",
    "green_roof_coords = np.array([[point.x, point.y] for point in green_roof_df[\"geometry\"]])\n",
    "\n",
    "# Build KDTree for Green Roof Data\n",
    "tree = cKDTree(green_roof_coords)\n",
    "\n",
    "# Query the nearest green roof for each merged data point\n",
    "distances, indices = tree.query(merged_coords, k=1)\n",
    "\n",
    "# Assign the nearest green roof data to the merged dataset\n",
    "merged_df[\"distance_to_green_roof\"] = distances\n",
    "nearest_green_roofs = green_roof_df.iloc[indices].reset_index()\n",
    "\n",
    "# Select relevant columns from Green Roof data\n",
    "green_roof_features = [\"gr_area\", \"bldg_area\", \"prop_gr\", \"heightroof\", \"groundelev\"]\n",
    "merged_df = pd.concat([merged_df.reset_index(drop=True), nearest_green_roofs[green_roof_features]], axis=1)\n",
    "\n",
    "# Save the updated dataset\n",
    "output_file = \"Merged_UHI_HHI_HVI_GreenRoof_Data.csv\"\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Updated dataset saved as: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933c0e5b-c991-4c2a-8a51-ed2a50d1e870",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 14. Model Building\n",
    "Our model has been constructed to predict the Urban Heat Island (UHI) index using features from the Sentinel-2 satellite dataset, Landset dataset, and building footprint dataset as predictor variables. In the best model, we utilized ten features: band B01 (Coastal Aerosol), band B06 (Red Edge), and NDVI (Normalized Difference Vegetation Index) derived from bands B04 (Red) and B08 (Near Infrared). A random forest regression model was then trained using these features.\n",
    "    \n",
    "These features were extracted from a GeoTIFF image created by the Sentinel-2 sample notebook. For the sample model shown in this notebook, data from a single day (24th July 2021) was considered, assuming that the values of bands B01, B04, B06, and B08 for this specific date are representative of the UHI index behavior at any location. Participants should review the details of the Sentinel-2 sample notebook to gain an understanding of the data and options for modifying the output product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da808e9c-4484-41e1-9110-06234d418899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9881\n",
      "LightGBM R² Score: 0.9895\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.983970\n",
      "1    Out-of-Bag Score  0.971188\n",
      "2   Mean CV R-squared -0.067227\n",
      "3  Ensemble R-squared  0.983295\n",
      "\n",
      "Submission file saved to Submission224.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"final_merged_weather_uhi_cleaned3_hyperlocal.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission224.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ae2351e-7c1d-4b9b-83bf-bd2b3f892517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9906\n",
      "LightGBM R² Score: 0.9885\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.985202\n",
      "1    Out-of-Bag Score  0.979669\n",
      "2   Mean CV R-squared  0.463351\n",
      "3  Ensemble R-squared  0.980776\n",
      "\n",
      "Submission file saved to Submission225.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_afhi.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission225.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'af_hi_f_value'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"af_hi_f_value\"] = uhi_df.iloc[indices][\"af_hi_f_value\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'af_hi_f_value'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2162bd53-4d01-40ea-be83-2e0d99fd5ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "af_hi_f_value                       0.368574\n",
      "building_density_ratio_squared      0.078918\n",
      "building_density_ratio              0.076779\n",
      "log_building_density_ratio          0.064036\n",
      "building_density                    0.063138\n",
      "Wind_Speed_x_Building_Density       0.047465\n",
      "temp_deviation_smooth               0.041792\n",
      "building_density_LST_interaction    0.039870\n",
      "Nearest_AirTemp_C                   0.023659\n",
      "Temp_Anomaly                        0.021733\n",
      "temp_deviation                      0.019746\n",
      "temp_2m_                            0.019133\n",
      "mean_temp                           0.019016\n",
      "LST                                 0.018299\n",
      "relative_humidity_                  0.017526\n",
      "log_LST                             0.017161\n",
      "SAVI_LST_sqrt_diff                  0.014619\n",
      "solar_insolation_                   0.013876\n",
      "wind_direction_merge_               0.012292\n",
      "nearest_building_area               0.008599\n",
      "nearest_building_perimeter          0.006938\n",
      "log_building_perimeter              0.006829\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "af_hi_f_value                       0.426054\n",
      "building_density                    0.085510\n",
      "building_density_ratio              0.084766\n",
      "log_building_density_ratio          0.077345\n",
      "building_density_ratio_squared      0.074101\n",
      "Wind_Speed_x_Building_Density       0.036530\n",
      "temp_deviation_smooth               0.030988\n",
      "relative_humidity_                  0.025584\n",
      "building_density_LST_interaction    0.022881\n",
      "temp_2m_                            0.021313\n",
      "Temp_Anomaly                        0.021297\n",
      "Nearest_AirTemp_C                   0.020486\n",
      "solar_insolation_                   0.014809\n",
      "wind_direction_merge_               0.011363\n",
      "log_LST                             0.008040\n",
      "temp_deviation                      0.007829\n",
      "SAVI_LST_sqrt_diff                  0.007616\n",
      "LST                                 0.007427\n",
      "mean_temp                           0.007232\n",
      "nearest_building_area               0.003108\n",
      "nearest_building_perimeter          0.002912\n",
      "log_building_perimeter              0.002810\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9afdef1-2d7a-4530-b1d5-4f8d9768f4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9766\n",
      "LightGBM R² Score: 0.9673\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.983288\n",
      "1    Out-of-Bag Score  0.971649\n",
      "2   Mean CV R-squared -0.026794\n",
      "3  Ensemble R-squared  0.977200\n",
      "\n",
      "Submission file saved to Submission226.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_amhi.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission226.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'am_hi_f_value'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"am_hi_f_value\"] = uhi_df.iloc[indices][\"am_hi_f_value\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'am_hi_f_value'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c01332b-531e-430b-bc46-66c8449946d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "building_density_ratio_squared      0.104017\n",
      "building_density_ratio              0.103868\n",
      "log_building_density_ratio          0.093085\n",
      "building_density                    0.092655\n",
      "Wind_Speed_x_Building_Density       0.072445\n",
      "am_hi_f_value                       0.063629\n",
      "building_density_LST_interaction    0.063430\n",
      "temp_deviation_smooth               0.051936\n",
      "Nearest_AirTemp_C                   0.034641\n",
      "Temp_Anomaly                        0.033689\n",
      "LST                                 0.030794\n",
      "temp_2m_                            0.029904\n",
      "log_LST                             0.028773\n",
      "temp_deviation                      0.027235\n",
      "relative_humidity_                  0.026864\n",
      "mean_temp                           0.026789\n",
      "SAVI_LST_sqrt_diff                  0.026046\n",
      "solar_insolation_                   0.024173\n",
      "wind_direction_merge_               0.020773\n",
      "nearest_building_area               0.017057\n",
      "nearest_building_perimeter          0.014107\n",
      "log_building_perimeter              0.014090\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "building_density_ratio              0.115755\n",
      "building_density                    0.112719\n",
      "building_density_ratio_squared      0.103632\n",
      "log_building_density_ratio          0.102723\n",
      "Wind_Speed_x_Building_Density       0.061378\n",
      "am_hi_f_value                       0.056115\n",
      "building_density_LST_interaction    0.045544\n",
      "temp_deviation_smooth               0.041294\n",
      "temp_2m_                            0.039018\n",
      "Nearest_AirTemp_C                   0.037258\n",
      "Temp_Anomaly                        0.037180\n",
      "relative_humidity_                  0.035602\n",
      "solar_insolation_                   0.033243\n",
      "log_LST                             0.025468\n",
      "LST                                 0.025179\n",
      "wind_direction_merge_               0.023593\n",
      "SAVI_LST_sqrt_diff                  0.022762\n",
      "temp_deviation                      0.020149\n",
      "mean_temp                           0.019886\n",
      "nearest_building_area               0.015583\n",
      "nearest_building_perimeter          0.013060\n",
      "log_building_perimeter              0.012859\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "414cc67d-d431-40aa-b89f-d68ee8386efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9842\n",
      "LightGBM R² Score: 0.9822\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.979415\n",
      "1    Out-of-Bag Score  0.971538\n",
      "2   Mean CV R-squared  0.050022\n",
      "3  Ensemble R-squared  0.977135\n",
      "\n",
      "Submission file saved to Submission227.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_pmhi.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission227.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f_value'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_hi_f_value\"] = uhi_df.iloc[indices][\"pm_hi_f_value\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f_value'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2eabcc32-c589-449b-9908-dca38ee31b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "pm_hi_f_value                       0.127367\n",
      "building_density_ratio              0.100041\n",
      "building_density_ratio_squared      0.098921\n",
      "building_density                    0.087816\n",
      "log_building_density_ratio          0.085378\n",
      "Wind_Speed_x_Building_Density       0.068481\n",
      "building_density_LST_interaction    0.053777\n",
      "temp_deviation_smooth               0.048219\n",
      "Nearest_AirTemp_C                   0.031381\n",
      "Temp_Anomaly                        0.030903\n",
      "LST                                 0.028647\n",
      "log_LST                             0.027949\n",
      "relative_humidity_                  0.026740\n",
      "temp_2m_                            0.025893\n",
      "temp_deviation                      0.025745\n",
      "mean_temp                           0.025080\n",
      "SAVI_LST_sqrt_diff                  0.024658\n",
      "solar_insolation_                   0.023510\n",
      "wind_direction_merge_               0.018274\n",
      "nearest_building_area               0.015134\n",
      "nearest_building_perimeter          0.013105\n",
      "log_building_perimeter              0.012983\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "building_density                    0.110515\n",
      "pm_hi_f_value                       0.109680\n",
      "building_density_ratio              0.107690\n",
      "building_density_ratio_squared      0.098567\n",
      "log_building_density_ratio          0.095334\n",
      "Wind_Speed_x_Building_Density       0.056301\n",
      "temp_deviation_smooth               0.041661\n",
      "building_density_LST_interaction    0.039971\n",
      "Temp_Anomaly                        0.038281\n",
      "Nearest_AirTemp_C                   0.037893\n",
      "temp_2m_                            0.037174\n",
      "relative_humidity_                  0.034564\n",
      "solar_insolation_                   0.030455\n",
      "log_LST                             0.022732\n",
      "wind_direction_merge_               0.021712\n",
      "LST                                 0.021360\n",
      "SAVI_LST_sqrt_diff                  0.020668\n",
      "mean_temp                           0.018705\n",
      "temp_deviation                      0.018363\n",
      "nearest_building_area               0.014201\n",
      "log_building_perimeter              0.012111\n",
      "nearest_building_perimeter          0.012063\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "793dacb3-3af6-4f9f-b64c-b81f19bf30a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9827\n",
      "LightGBM R² Score: 0.9768\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.976947\n",
      "1    Out-of-Bag Score  0.981224\n",
      "2   Mean CV R-squared  0.767943\n",
      "3  Ensemble R-squared  0.971740\n",
      "\n",
      "Submission file saved to Submission228.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_aft.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission228.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'af_t_f_value'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"af_t_f_value\"] = uhi_df.iloc[indices][\"af_t_f_value\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'af_t_f_value'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "657dfaac-0b1d-4a3e-b740-8a3f05f6ba81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "af_t_f_value                        0.470651\n",
      "building_density_ratio_squared      0.073062\n",
      "building_density_ratio              0.069529\n",
      "log_building_density_ratio          0.060127\n",
      "building_density                    0.058082\n",
      "Wind_Speed_x_Building_Density       0.039668\n",
      "building_density_LST_interaction    0.037388\n",
      "temp_deviation_smooth               0.025940\n",
      "Nearest_AirTemp_C                   0.017730\n",
      "Temp_Anomaly                        0.016580\n",
      "temp_2m_                            0.014458\n",
      "LST                                 0.014408\n",
      "relative_humidity_                  0.013903\n",
      "mean_temp                           0.013536\n",
      "temp_deviation                      0.013531\n",
      "log_LST                             0.013261\n",
      "SAVI_LST_sqrt_diff                  0.010881\n",
      "solar_insolation_                   0.010277\n",
      "wind_direction_merge_               0.009048\n",
      "nearest_building_area               0.007058\n",
      "log_building_perimeter              0.005503\n",
      "nearest_building_perimeter          0.005380\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "af_t_f_value                        0.587316\n",
      "building_density_ratio              0.077341\n",
      "building_density                    0.076852\n",
      "log_building_density_ratio          0.067782\n",
      "building_density_ratio_squared      0.066234\n",
      "Wind_Speed_x_Building_Density       0.025849\n",
      "building_density_LST_interaction    0.015970\n",
      "relative_humidity_                  0.015089\n",
      "temp_2m_                            0.012474\n",
      "Temp_Anomaly                        0.010024\n",
      "Nearest_AirTemp_C                   0.010010\n",
      "temp_deviation_smooth               0.007639\n",
      "solar_insolation_                   0.005429\n",
      "SAVI_LST_sqrt_diff                  0.004317\n",
      "wind_direction_merge_               0.003673\n",
      "log_LST                             0.003582\n",
      "LST                                 0.003165\n",
      "mean_temp                           0.002017\n",
      "temp_deviation                      0.001979\n",
      "nearest_building_area               0.001116\n",
      "log_building_perimeter              0.001103\n",
      "nearest_building_perimeter          0.001039\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8131a555-c1db-48ed-a25f-36cf916890ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "41 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9803\n",
      "LightGBM R² Score: 0.9784\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.982636\n",
      "1    Out-of-Bag Score  0.971908\n",
      "2   Mean CV R-squared -0.021364\n",
      "3  Ensemble R-squared  0.979036\n",
      "\n",
      "Submission file saved to Submission229.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_amt.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission229.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'am_t_f_value'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"am_t_f_value\"] = uhi_df.iloc[indices][\"am_t_f_value\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'am_t_f_value'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1126404-277e-4e28-9f9b-28261ff2d373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "building_density_ratio_squared      0.105577\n",
      "building_density_ratio              0.104256\n",
      "log_building_density_ratio          0.091817\n",
      "building_density                    0.091026\n",
      "Wind_Speed_x_Building_Density       0.070997\n",
      "building_density_LST_interaction    0.064213\n",
      "am_t_f_value                        0.064086\n",
      "temp_deviation_smooth               0.054301\n",
      "Temp_Anomaly                        0.033814\n",
      "Nearest_AirTemp_C                   0.033700\n",
      "LST                                 0.030494\n",
      "temp_2m_                            0.030043\n",
      "log_LST                             0.028774\n",
      "relative_humidity_                  0.027739\n",
      "mean_temp                           0.027495\n",
      "temp_deviation                      0.027240\n",
      "SAVI_LST_sqrt_diff                  0.025275\n",
      "solar_insolation_                   0.022316\n",
      "wind_direction_merge_               0.021673\n",
      "nearest_building_area               0.016731\n",
      "log_building_perimeter              0.014332\n",
      "nearest_building_perimeter          0.014101\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "building_density                    0.116215\n",
      "building_density_ratio              0.112874\n",
      "building_density_ratio_squared      0.102182\n",
      "log_building_density_ratio          0.102094\n",
      "am_t_f_value                        0.062742\n",
      "Wind_Speed_x_Building_Density       0.059886\n",
      "building_density_LST_interaction    0.045080\n",
      "temp_deviation_smooth               0.042381\n",
      "temp_2m_                            0.036966\n",
      "Nearest_AirTemp_C                   0.036869\n",
      "Temp_Anomaly                        0.036331\n",
      "relative_humidity_                  0.035213\n",
      "solar_insolation_                   0.031219\n",
      "wind_direction_merge_               0.025848\n",
      "log_LST                             0.025760\n",
      "LST                                 0.024512\n",
      "SAVI_LST_sqrt_diff                  0.022197\n",
      "mean_temp                           0.019645\n",
      "temp_deviation                      0.019244\n",
      "nearest_building_area               0.016047\n",
      "log_building_perimeter              0.013486\n",
      "nearest_building_perimeter          0.013209\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "45e4918d-13c5-46b8-9962-a482282f42cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9708\n",
      "LightGBM R² Score: 0.9704\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.977006\n",
      "1    Out-of-Bag Score  0.972023\n",
      "2   Mean CV R-squared  0.052964\n",
      "3  Ensemble R-squared  0.972006\n",
      "\n",
      "Submission file saved to Submission230.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_pmt.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission230.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_t_f_value'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f_value\"] = uhi_df.iloc[indices][\"pm_t_f_value\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_t_f_value'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "395aadce-c53d-47e0-a5fd-e89d37965bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "pm_t_f_value                        0.145858\n",
      "building_density_ratio              0.102414\n",
      "building_density_ratio_squared      0.099705\n",
      "log_building_density_ratio          0.088337\n",
      "building_density                    0.088213\n",
      "Wind_Speed_x_Building_Density       0.065342\n",
      "building_density_LST_interaction    0.050847\n",
      "temp_deviation_smooth               0.045839\n",
      "Nearest_AirTemp_C                   0.029143\n",
      "Temp_Anomaly                        0.028085\n",
      "LST                                 0.027304\n",
      "log_LST                             0.026512\n",
      "temp_deviation                      0.025018\n",
      "mean_temp                           0.024435\n",
      "temp_2m_                            0.024404\n",
      "relative_humidity_                  0.024324\n",
      "SAVI_LST_sqrt_diff                  0.023797\n",
      "solar_insolation_                   0.022840\n",
      "wind_direction_merge_               0.016948\n",
      "nearest_building_area               0.014770\n",
      "log_building_perimeter              0.012954\n",
      "nearest_building_perimeter          0.012909\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "pm_t_f_value                        0.135321\n",
      "building_density                    0.108063\n",
      "building_density_ratio              0.106162\n",
      "building_density_ratio_squared      0.097817\n",
      "log_building_density_ratio          0.097734\n",
      "Wind_Speed_x_Building_Density       0.054391\n",
      "temp_deviation_smooth               0.040434\n",
      "relative_humidity_                  0.035642\n",
      "building_density_LST_interaction    0.035616\n",
      "Temp_Anomaly                        0.034155\n",
      "Nearest_AirTemp_C                   0.032578\n",
      "temp_2m_                            0.032409\n",
      "solar_insolation_                   0.029639\n",
      "log_LST                             0.022964\n",
      "LST                                 0.022494\n",
      "wind_direction_merge_               0.021573\n",
      "SAVI_LST_sqrt_diff                  0.020205\n",
      "mean_temp                           0.018225\n",
      "temp_deviation                      0.017772\n",
      "nearest_building_area               0.013187\n",
      "nearest_building_perimeter          0.011885\n",
      "log_building_perimeter              0.011732\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ee8ffa0-fb42-453a-9865-cb7a6f50ebe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "42 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "23 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9875\n",
      "LightGBM R² Score: 0.9824\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.977455\n",
      "1    Out-of-Bag Score  0.981895\n",
      "2   Mean CV R-squared  0.879511\n",
      "3  Ensemble R-squared  0.974475\n",
      "\n",
      "Submission file saved to Submission231.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_all.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission231.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f', 'am_hi_f', 'af_hi_f',\n",
    "     'pm_t_f', 'am_t_f', 'af_t_f'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f\"] = uhi_df.iloc[indices][\"pm_t_f\"].values\n",
    "submission_df[\"am_t_f\"] = uhi_df.iloc[indices][\"am_t_f\"].values\n",
    "submission_df[\"af_t_f\"] = uhi_df.iloc[indices][\"af_t_f\"].values\n",
    "submission_df[\"pm_hi_f\"] = uhi_df.iloc[indices][\"pm_hi_f\"].values\n",
    "submission_df[\"am_hi_f\"] = uhi_df.iloc[indices][\"am_hi_f\"].values\n",
    "submission_df[\"af_hi_f\"] = uhi_df.iloc[indices][\"af_hi_f\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f', 'am_hi_f', 'af_hi_f',\n",
    "     'pm_t_f', 'am_t_f', 'af_t_f'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e924018-1a54-464c-a7d0-0700307cf22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "af_t_f                              0.374413\n",
      "af_hi_f                             0.216662\n",
      "building_density_ratio_squared      0.051028\n",
      "building_density_ratio              0.050045\n",
      "pm_t_f                              0.044583\n",
      "building_density                    0.040932\n",
      "log_building_density_ratio          0.037554\n",
      "pm_hi_f                             0.029575\n",
      "Wind_Speed_x_Building_Density       0.021034\n",
      "building_density_LST_interaction    0.016682\n",
      "temp_deviation_smooth               0.015772\n",
      "am_t_f                              0.014889\n",
      "am_hi_f                             0.013671\n",
      "Temp_Anomaly                        0.007508\n",
      "log_LST                             0.006903\n",
      "Nearest_AirTemp_C                   0.006892\n",
      "temp_deviation                      0.006507\n",
      "mean_temp                           0.006454\n",
      "LST                                 0.006372\n",
      "SAVI_LST_sqrt_diff                  0.006194\n",
      "relative_humidity_                  0.005889\n",
      "temp_2m_                            0.005237\n",
      "solar_insolation_                   0.004378\n",
      "wind_direction_merge_               0.003634\n",
      "nearest_building_area               0.002749\n",
      "nearest_building_perimeter          0.002237\n",
      "log_building_perimeter              0.002205\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "af_t_f                              0.458921\n",
      "af_hi_f                             0.143833\n",
      "building_density_ratio              0.082515\n",
      "building_density_ratio_squared      0.063441\n",
      "log_building_density_ratio          0.059308\n",
      "building_density                    0.058935\n",
      "Wind_Speed_x_Building_Density       0.029616\n",
      "building_density_LST_interaction    0.015509\n",
      "relative_humidity_                  0.012741\n",
      "temp_2m_                            0.011864\n",
      "pm_t_f                              0.009907\n",
      "Temp_Anomaly                        0.007345\n",
      "Nearest_AirTemp_C                   0.006861\n",
      "temp_deviation_smooth               0.006461\n",
      "pm_hi_f                             0.005888\n",
      "am_t_f                              0.004255\n",
      "solar_insolation_                   0.004097\n",
      "wind_direction_merge_               0.003627\n",
      "SAVI_LST_sqrt_diff                  0.003080\n",
      "am_hi_f                             0.002347\n",
      "LST                                 0.001849\n",
      "log_LST                             0.001824\n",
      "temp_deviation                      0.001779\n",
      "mean_temp                           0.001576\n",
      "nearest_building_perimeter          0.000831\n",
      "nearest_building_area               0.000814\n",
      "log_building_perimeter              0.000775\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04ff5e2b-a822-4008-944d-93961a92b0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9880\n",
      "LightGBM R² Score: 0.9809\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.979351\n",
      "1    Out-of-Bag Score  0.982047\n",
      "2   Mean CV R-squared  0.853949\n",
      "3  Ensemble R-squared  0.974210\n",
      "\n",
      "Submission file saved to Submission232.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_all.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission232.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'af_hi_f', 'af_t_f'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f\"] = uhi_df.iloc[indices][\"pm_t_f\"].values\n",
    "submission_df[\"am_t_f\"] = uhi_df.iloc[indices][\"am_t_f\"].values\n",
    "submission_df[\"af_t_f\"] = uhi_df.iloc[indices][\"af_t_f\"].values\n",
    "submission_df[\"pm_hi_f\"] = uhi_df.iloc[indices][\"pm_hi_f\"].values\n",
    "submission_df[\"am_hi_f\"] = uhi_df.iloc[indices][\"am_hi_f\"].values\n",
    "submission_df[\"af_hi_f\"] = uhi_df.iloc[indices][\"af_hi_f\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'af_hi_f', 'af_t_f'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42cb28f2-abe2-43b3-aaa6-5a2ee31aab1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "af_t_f                              0.372638\n",
      "af_hi_f                             0.232059\n",
      "building_density_ratio_squared      0.058220\n",
      "building_density_ratio              0.055607\n",
      "building_density                    0.047498\n",
      "log_building_density_ratio          0.044476\n",
      "Wind_Speed_x_Building_Density       0.032102\n",
      "building_density_LST_interaction    0.024578\n",
      "temp_deviation_smooth               0.022522\n",
      "Nearest_AirTemp_C                   0.012338\n",
      "Temp_Anomaly                        0.012044\n",
      "mean_temp                           0.010007\n",
      "temp_2m_                            0.009731\n",
      "temp_deviation                      0.009180\n",
      "log_LST                             0.009047\n",
      "relative_humidity_                  0.008920\n",
      "LST                                 0.008632\n",
      "SAVI_LST_sqrt_diff                  0.007449\n",
      "solar_insolation_                   0.006593\n",
      "wind_direction_merge_               0.005890\n",
      "nearest_building_area               0.004103\n",
      "nearest_building_perimeter          0.003197\n",
      "log_building_perimeter              0.003168\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "af_t_f                              0.467180\n",
      "af_hi_f                             0.152067\n",
      "building_density                    0.076914\n",
      "building_density_ratio_squared      0.070402\n",
      "log_building_density_ratio          0.062990\n",
      "building_density_ratio              0.059796\n",
      "Wind_Speed_x_Building_Density       0.026958\n",
      "building_density_LST_interaction    0.015234\n",
      "relative_humidity_                  0.014459\n",
      "temp_2m_                            0.012567\n",
      "Nearest_AirTemp_C                   0.007257\n",
      "temp_deviation_smooth               0.006793\n",
      "Temp_Anomaly                        0.006510\n",
      "solar_insolation_                   0.004357\n",
      "wind_direction_merge_               0.003715\n",
      "SAVI_LST_sqrt_diff                  0.002655\n",
      "LST                                 0.002043\n",
      "log_LST                             0.001966\n",
      "temp_deviation                      0.001739\n",
      "mean_temp                           0.001668\n",
      "nearest_building_area               0.000940\n",
      "log_building_perimeter              0.000897\n",
      "nearest_building_perimeter          0.000894\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "917b59bc-cc56-4538-95ba-f407f4e12de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "55 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9818\n",
      "LightGBM R² Score: 0.9690\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.983066\n",
      "1    Out-of-Bag Score  0.971642\n",
      "2   Mean CV R-squared -0.007526\n",
      "3  Ensemble R-squared  0.976697\n",
      "\n",
      "Submission file saved to Submission233.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_all.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission233.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'am_hi_f', 'am_t_f'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f\"] = uhi_df.iloc[indices][\"pm_t_f\"].values\n",
    "submission_df[\"am_t_f\"] = uhi_df.iloc[indices][\"am_t_f\"].values\n",
    "submission_df[\"af_t_f\"] = uhi_df.iloc[indices][\"af_t_f\"].values\n",
    "submission_df[\"pm_hi_f\"] = uhi_df.iloc[indices][\"pm_hi_f\"].values\n",
    "submission_df[\"am_hi_f\"] = uhi_df.iloc[indices][\"am_hi_f\"].values\n",
    "submission_df[\"af_hi_f\"] = uhi_df.iloc[indices][\"af_hi_f\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'am_hi_f', 'am_t_f'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a81b1eeb-176a-44c2-af2b-9b08ae6bbf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "building_density_ratio_squared      0.105615\n",
      "building_density_ratio              0.103947\n",
      "building_density                    0.087945\n",
      "log_building_density_ratio          0.086241\n",
      "Wind_Speed_x_Building_Density       0.070316\n",
      "building_density_LST_interaction    0.061729\n",
      "am_hi_f                             0.053530\n",
      "am_t_f                              0.050030\n",
      "temp_deviation_smooth               0.049448\n",
      "Nearest_AirTemp_C                   0.031889\n",
      "Temp_Anomaly                        0.031721\n",
      "LST                                 0.028203\n",
      "temp_2m_                            0.028160\n",
      "log_LST                             0.028111\n",
      "relative_humidity_                  0.025727\n",
      "SAVI_LST_sqrt_diff                  0.025044\n",
      "mean_temp                           0.024714\n",
      "temp_deviation                      0.023490\n",
      "solar_insolation_                   0.021723\n",
      "wind_direction_merge_               0.020073\n",
      "nearest_building_area               0.016022\n",
      "nearest_building_perimeter          0.013292\n",
      "log_building_perimeter              0.013028\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "building_density                    0.114414\n",
      "building_density_ratio_squared      0.109088\n",
      "building_density_ratio              0.100505\n",
      "log_building_density_ratio          0.098282\n",
      "Wind_Speed_x_Building_Density       0.060166\n",
      "am_t_f                              0.052512\n",
      "building_density_LST_interaction    0.043214\n",
      "am_hi_f                             0.043106\n",
      "temp_deviation_smooth               0.037906\n",
      "temp_2m_                            0.036420\n",
      "Nearest_AirTemp_C                   0.034972\n",
      "Temp_Anomaly                        0.033934\n",
      "relative_humidity_                  0.033126\n",
      "solar_insolation_                   0.030342\n",
      "log_LST                             0.026094\n",
      "wind_direction_merge_               0.024768\n",
      "LST                                 0.023686\n",
      "SAVI_LST_sqrt_diff                  0.021292\n",
      "mean_temp                           0.018024\n",
      "temp_deviation                      0.017970\n",
      "nearest_building_area               0.014878\n",
      "log_building_perimeter              0.012779\n",
      "nearest_building_perimeter          0.012525\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "12215f6f-235a-43a0-ac3f-d2d6603413be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9775\n",
      "LightGBM R² Score: 0.9684\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.974426\n",
      "1    Out-of-Bag Score  0.971532\n",
      "2   Mean CV R-squared  0.073370\n",
      "3  Ensemble R-squared  0.972429\n",
      "\n",
      "Submission file saved to Submission234.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_all.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission234.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f', 'pm_t_f'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f\"] = uhi_df.iloc[indices][\"pm_t_f\"].values\n",
    "submission_df[\"am_t_f\"] = uhi_df.iloc[indices][\"am_t_f\"].values\n",
    "submission_df[\"af_t_f\"] = uhi_df.iloc[indices][\"af_t_f\"].values\n",
    "submission_df[\"pm_hi_f\"] = uhi_df.iloc[indices][\"pm_hi_f\"].values\n",
    "submission_df[\"am_hi_f\"] = uhi_df.iloc[indices][\"am_hi_f\"].values\n",
    "submission_df[\"af_hi_f\"] = uhi_df.iloc[indices][\"af_hi_f\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f', 'pm_t_f'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cfc7c8a9-f818-44da-a5ac-8aedf4128834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "pm_t_f                              0.107645\n",
      "building_density_ratio_squared      0.102393\n",
      "building_density_ratio              0.099444\n",
      "pm_hi_f                             0.089087\n",
      "building_density                    0.081901\n",
      "log_building_density_ratio          0.080126\n",
      "Wind_Speed_x_Building_Density       0.063154\n",
      "building_density_LST_interaction    0.044128\n",
      "temp_deviation_smooth               0.042695\n",
      "Nearest_AirTemp_C                   0.027034\n",
      "Temp_Anomaly                        0.026531\n",
      "LST                                 0.025717\n",
      "log_LST                             0.025027\n",
      "relative_humidity_                  0.023447\n",
      "SAVI_LST_sqrt_diff                  0.022949\n",
      "mean_temp                           0.022131\n",
      "temp_2m_                            0.021890\n",
      "solar_insolation_                   0.020871\n",
      "temp_deviation                      0.020678\n",
      "wind_direction_merge_               0.015885\n",
      "nearest_building_area               0.013204\n",
      "nearest_building_perimeter          0.012057\n",
      "log_building_perimeter              0.012007\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "building_density                    0.107970\n",
      "building_density_ratio_squared      0.102252\n",
      "pm_t_f                              0.101282\n",
      "building_density_ratio              0.091960\n",
      "log_building_density_ratio          0.090826\n",
      "pm_hi_f                             0.064972\n",
      "Wind_Speed_x_Building_Density       0.054391\n",
      "temp_deviation_smooth               0.037807\n",
      "relative_humidity_                  0.035046\n",
      "building_density_LST_interaction    0.034833\n",
      "Temp_Anomaly                        0.033398\n",
      "Nearest_AirTemp_C                   0.032566\n",
      "temp_2m_                            0.031765\n",
      "solar_insolation_                   0.029648\n",
      "log_LST                             0.022656\n",
      "LST                                 0.020461\n",
      "wind_direction_merge_               0.020032\n",
      "SAVI_LST_sqrt_diff                  0.019686\n",
      "mean_temp                           0.017001\n",
      "temp_deviation                      0.016910\n",
      "nearest_building_area               0.012183\n",
      "log_building_perimeter              0.011248\n",
      "nearest_building_perimeter          0.011106\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a7d88b3-c951-4d2d-88f0-b9bfd48ae955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "27 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "38 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9848\n",
      "LightGBM R² Score: 0.9892\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.985371\n",
      "1    Out-of-Bag Score  0.979422\n",
      "2   Mean CV R-squared  0.483797\n",
      "3  Ensemble R-squared  0.979101\n",
      "\n",
      "Submission file saved to Submission235.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_all.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission235.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f', 'am_hi_f', 'af_hi_f'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f\"] = uhi_df.iloc[indices][\"pm_t_f\"].values\n",
    "submission_df[\"am_t_f\"] = uhi_df.iloc[indices][\"am_t_f\"].values\n",
    "submission_df[\"af_t_f\"] = uhi_df.iloc[indices][\"af_t_f\"].values\n",
    "submission_df[\"pm_hi_f\"] = uhi_df.iloc[indices][\"pm_hi_f\"].values\n",
    "submission_df[\"am_hi_f\"] = uhi_df.iloc[indices][\"am_hi_f\"].values\n",
    "submission_df[\"af_hi_f\"] = uhi_df.iloc[indices][\"af_hi_f\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f', 'am_hi_f', 'af_hi_f'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "474a0dab-afb5-4687-bc9e-bbf9ab8d3d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "af_hi_f                             0.318654\n",
      "pm_hi_f                             0.073757\n",
      "building_density_ratio_squared      0.071540\n",
      "building_density_ratio              0.069850\n",
      "log_building_density_ratio          0.065565\n",
      "building_density                    0.058002\n",
      "Wind_Speed_x_Building_Density       0.047134\n",
      "temp_deviation_smooth               0.035007\n",
      "building_density_LST_interaction    0.034749\n",
      "am_hi_f                             0.034592\n",
      "Nearest_AirTemp_C                   0.018819\n",
      "Temp_Anomaly                        0.018793\n",
      "log_LST                             0.016971\n",
      "LST                                 0.016732\n",
      "mean_temp                           0.016174\n",
      "temp_deviation                      0.015773\n",
      "relative_humidity_                  0.015723\n",
      "temp_2m_                            0.014898\n",
      "SAVI_LST_sqrt_diff                  0.014468\n",
      "solar_insolation_                   0.012899\n",
      "wind_direction_merge_               0.010100\n",
      "nearest_building_area               0.007469\n",
      "nearest_building_perimeter          0.006227\n",
      "log_building_perimeter              0.006105\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "af_hi_f                             0.411666\n",
      "building_density                    0.083306\n",
      "building_density_ratio_squared      0.077213\n",
      "building_density_ratio              0.076732\n",
      "log_building_density_ratio          0.064124\n",
      "Wind_Speed_x_Building_Density       0.041637\n",
      "pm_hi_f                             0.029213\n",
      "temp_deviation_smooth               0.026409\n",
      "building_density_LST_interaction    0.023803\n",
      "relative_humidity_                  0.023135\n",
      "temp_2m_                            0.020872\n",
      "Temp_Anomaly                        0.018883\n",
      "am_hi_f                             0.018798\n",
      "Nearest_AirTemp_C                   0.018418\n",
      "solar_insolation_                   0.013445\n",
      "wind_direction_merge_               0.009861\n",
      "log_LST                             0.008003\n",
      "mean_temp                           0.006843\n",
      "SAVI_LST_sqrt_diff                  0.006744\n",
      "temp_deviation                      0.006581\n",
      "LST                                 0.006515\n",
      "nearest_building_area               0.002756\n",
      "log_building_perimeter              0.002524\n",
      "nearest_building_perimeter          0.002519\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18733442-bb40-40ed-bb4a-0cccddf6a64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "65 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9820\n",
      "LightGBM R² Score: 0.9784\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.975205\n",
      "1    Out-of-Bag Score  0.981096\n",
      "2   Mean CV R-squared  0.763708\n",
      "3  Ensemble R-squared  0.972453\n",
      "\n",
      "Submission file saved to Submission236.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_all.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission236.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_t_f', 'am_t_f', 'af_t_f'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f\"] = uhi_df.iloc[indices][\"pm_t_f\"].values\n",
    "submission_df[\"am_t_f\"] = uhi_df.iloc[indices][\"am_t_f\"].values\n",
    "submission_df[\"af_t_f\"] = uhi_df.iloc[indices][\"af_t_f\"].values\n",
    "submission_df[\"pm_hi_f\"] = uhi_df.iloc[indices][\"pm_hi_f\"].values\n",
    "submission_df[\"am_hi_f\"] = uhi_df.iloc[indices][\"am_hi_f\"].values\n",
    "submission_df[\"af_hi_f\"] = uhi_df.iloc[indices][\"af_hi_f\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_t_f', 'am_t_f', 'af_t_f'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1e9b4ca9-8ea8-4d29-80f6-e902f9927dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "af_t_f                              0.407346\n",
      "pm_t_f                              0.083147\n",
      "building_density_ratio_squared      0.066769\n",
      "building_density_ratio              0.066149\n",
      "log_building_density_ratio          0.058660\n",
      "building_density                    0.055757\n",
      "Wind_Speed_x_Building_Density       0.040894\n",
      "building_density_LST_interaction    0.030752\n",
      "am_t_f                              0.025865\n",
      "temp_deviation_smooth               0.022617\n",
      "Temp_Anomaly                        0.014455\n",
      "Nearest_AirTemp_C                   0.014218\n",
      "log_LST                             0.012678\n",
      "LST                                 0.012615\n",
      "mean_temp                           0.011644\n",
      "temp_deviation                      0.011594\n",
      "SAVI_LST_sqrt_diff                  0.011316\n",
      "relative_humidity_                  0.010938\n",
      "temp_2m_                            0.010680\n",
      "solar_insolation_                   0.008487\n",
      "wind_direction_merge_               0.007560\n",
      "nearest_building_area               0.005984\n",
      "log_building_perimeter              0.004995\n",
      "nearest_building_perimeter          0.004880\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "af_t_f                              0.573517\n",
      "building_density                    0.074413\n",
      "building_density_ratio_squared      0.069405\n",
      "building_density_ratio              0.068474\n",
      "log_building_density_ratio          0.058413\n",
      "Wind_Speed_x_Building_Density       0.033319\n",
      "pm_t_f                              0.022161\n",
      "building_density_LST_interaction    0.018610\n",
      "relative_humidity_                  0.014317\n",
      "temp_2m_                            0.011957\n",
      "Temp_Anomaly                        0.009124\n",
      "Nearest_AirTemp_C                   0.008508\n",
      "am_t_f                              0.006765\n",
      "temp_deviation_smooth               0.006156\n",
      "solar_insolation_                   0.004877\n",
      "wind_direction_merge_               0.003710\n",
      "log_LST                             0.003429\n",
      "SAVI_LST_sqrt_diff                  0.003310\n",
      "LST                                 0.003066\n",
      "mean_temp                           0.001820\n",
      "temp_deviation                      0.001707\n",
      "nearest_building_area               0.001041\n",
      "nearest_building_perimeter          0.000961\n",
      "log_building_perimeter              0.000942\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c611fd8a-5a9f-4c80-8866-59ef72db353e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9712\n",
      "LightGBM R² Score: 0.9612\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.977161\n",
      "1    Out-of-Bag Score  0.972615\n",
      "2   Mean CV R-squared  0.097822\n",
      "3  Ensemble R-squared  0.970752\n",
      "\n",
      "Submission file saved to Submission237.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_all.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission237.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_t_f', 'am_t_f'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f\"] = uhi_df.iloc[indices][\"pm_t_f\"].values\n",
    "submission_df[\"am_t_f\"] = uhi_df.iloc[indices][\"am_t_f\"].values\n",
    "submission_df[\"af_t_f\"] = uhi_df.iloc[indices][\"af_t_f\"].values\n",
    "submission_df[\"pm_hi_f\"] = uhi_df.iloc[indices][\"pm_hi_f\"].values\n",
    "submission_df[\"am_hi_f\"] = uhi_df.iloc[indices][\"am_hi_f\"].values\n",
    "submission_df[\"af_hi_f\"] = uhi_df.iloc[indices][\"af_hi_f\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_t_f', 'am_t_f'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7dd81eae-9da2-4bf4-a1db-177d476d2a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "pm_t_f                              0.137621\n",
      "building_density_ratio_squared      0.102162\n",
      "building_density_ratio              0.100631\n",
      "building_density                    0.084591\n",
      "log_building_density_ratio          0.081949\n",
      "Wind_Speed_x_Building_Density       0.063914\n",
      "am_t_f                              0.049576\n",
      "building_density_LST_interaction    0.049059\n",
      "temp_deviation_smooth               0.042615\n",
      "Temp_Anomaly                        0.027083\n",
      "Nearest_AirTemp_C                   0.027017\n",
      "LST                                 0.025169\n",
      "log_LST                             0.025022\n",
      "SAVI_LST_sqrt_diff                  0.022570\n",
      "relative_humidity_                  0.022554\n",
      "mean_temp                           0.022461\n",
      "temp_2m_                            0.022323\n",
      "temp_deviation                      0.021007\n",
      "solar_insolation_                   0.018600\n",
      "wind_direction_merge_               0.016469\n",
      "nearest_building_area               0.013690\n",
      "log_building_perimeter              0.012084\n",
      "nearest_building_perimeter          0.011833\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "pm_t_f                              0.129484\n",
      "building_density                    0.108509\n",
      "building_density_ratio_squared      0.102296\n",
      "building_density_ratio              0.092892\n",
      "log_building_density_ratio          0.091984\n",
      "Wind_Speed_x_Building_Density       0.053729\n",
      "am_t_f                              0.048369\n",
      "temp_deviation_smooth               0.036019\n",
      "building_density_LST_interaction    0.035294\n",
      "relative_humidity_                  0.031337\n",
      "Nearest_AirTemp_C                   0.031056\n",
      "temp_2m_                            0.030646\n",
      "Temp_Anomaly                        0.030359\n",
      "solar_insolation_                   0.026890\n",
      "log_LST                             0.022464\n",
      "LST                                 0.020895\n",
      "wind_direction_merge_               0.020884\n",
      "SAVI_LST_sqrt_diff                  0.019769\n",
      "mean_temp                           0.016503\n",
      "temp_deviation                      0.016205\n",
      "nearest_building_area               0.012559\n",
      "nearest_building_perimeter          0.011117\n",
      "log_building_perimeter              0.010742\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8f6b05c8-0b2c-438d-a012-66ee54089f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "31 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "34 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9770\n",
      "LightGBM R² Score: 0.9760\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.979364\n",
      "1    Out-of-Bag Score  0.972000\n",
      "2   Mean CV R-squared  0.095323\n",
      "3  Ensemble R-squared  0.975673\n",
      "\n",
      "Submission file saved to Submission238.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_all.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission238.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f', 'am_hi_f'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f\"] = uhi_df.iloc[indices][\"pm_t_f\"].values\n",
    "submission_df[\"am_t_f\"] = uhi_df.iloc[indices][\"am_t_f\"].values\n",
    "submission_df[\"af_t_f\"] = uhi_df.iloc[indices][\"af_t_f\"].values\n",
    "submission_df[\"pm_hi_f\"] = uhi_df.iloc[indices][\"pm_hi_f\"].values\n",
    "submission_df[\"am_hi_f\"] = uhi_df.iloc[indices][\"am_hi_f\"].values\n",
    "submission_df[\"af_hi_f\"] = uhi_df.iloc[indices][\"af_hi_f\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f', 'am_hi_f'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "027a852d-3671-4832-bcf0-5d592fa10355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "pm_hi_f                             0.120378\n",
      "building_density_ratio_squared      0.103411\n",
      "building_density_ratio              0.097799\n",
      "building_density                    0.083346\n",
      "log_building_density_ratio          0.081816\n",
      "Wind_Speed_x_Building_Density       0.065140\n",
      "am_hi_f                             0.052909\n",
      "building_density_LST_interaction    0.050113\n",
      "temp_deviation_smooth               0.043548\n",
      "Nearest_AirTemp_C                   0.029788\n",
      "Temp_Anomaly                        0.027791\n",
      "log_LST                             0.026554\n",
      "LST                                 0.025969\n",
      "temp_2m_                            0.023990\n",
      "relative_humidity_                  0.023781\n",
      "SAVI_LST_sqrt_diff                  0.023141\n",
      "mean_temp                           0.022613\n",
      "solar_insolation_                   0.021728\n",
      "temp_deviation                      0.021176\n",
      "wind_direction_merge_               0.016732\n",
      "nearest_building_area               0.013836\n",
      "log_building_perimeter              0.012411\n",
      "nearest_building_perimeter          0.012030\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "building_density                    0.108366\n",
      "pm_hi_f                             0.105372\n",
      "building_density_ratio_squared      0.104835\n",
      "building_density_ratio              0.094039\n",
      "log_building_density_ratio          0.092091\n",
      "Wind_Speed_x_Building_Density       0.055376\n",
      "am_hi_f                             0.046569\n",
      "temp_deviation_smooth               0.036964\n",
      "building_density_LST_interaction    0.036864\n",
      "temp_2m_                            0.034487\n",
      "relative_humidity_                  0.034163\n",
      "Temp_Anomaly                        0.033704\n",
      "Nearest_AirTemp_C                   0.033693\n",
      "solar_insolation_                   0.030182\n",
      "log_LST                             0.023425\n",
      "wind_direction_merge_               0.020957\n",
      "LST                                 0.020816\n",
      "SAVI_LST_sqrt_diff                  0.019849\n",
      "temp_deviation                      0.016646\n",
      "mean_temp                           0.016515\n",
      "nearest_building_area               0.012833\n",
      "log_building_perimeter              0.011342\n",
      "nearest_building_perimeter          0.010910\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7556e77-ccec-4447-b436-821ae3734ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.94497102 0.96617027 0.88707052        nan 0.94607881 0.9548398\n",
      " 0.96080486 0.88904483 0.88633899 0.89040439 0.88862807 0.94681322\n",
      " 0.88668233        nan 0.96615198 0.88394176 0.9550741  0.96557811\n",
      "        nan 0.94592951 0.94662592        nan 0.94564989 0.96120001\n",
      "        nan        nan 0.88988045 0.94698078        nan 0.94517184\n",
      "        nan 0.96615884 0.95926276 0.95421238 0.94566546 0.96318577\n",
      " 0.96198983        nan 0.94517184 0.94497102        nan 0.9557583\n",
      " 0.96360165 0.96589625        nan        nan 0.95610937 0.9627161\n",
      "        nan 0.96120335]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9747\n",
      "LightGBM R² Score: 0.9730\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.973921\n",
      "1    Out-of-Bag Score  0.972099\n",
      "2   Mean CV R-squared  0.129846\n",
      "3  Ensemble R-squared  0.970811\n",
      "\n",
      "Submission file saved to Submission239.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_all.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission239.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f', 'am_hi_f',\n",
    "     'pm_t_f', 'am_t_f'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Extract coordinates using the correct column names\n",
    "uhi_coords = uhi_df[['longitude', 'latitude']].values  # UHI dataset uses lowercase\n",
    "submission_coords = submission_df[['Longitude', 'Latitude']].values  # Submission dataset uses uppercase\n",
    "\n",
    "# Build a KDTree using UHI dataset\n",
    "uhi_tree = cKDTree(uhi_coords)\n",
    "\n",
    "# Query the KDTree for nearest neighbors\n",
    "_, indices = uhi_tree.query(submission_coords, k=1)  # k=1 ensures the nearest point is found\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f\"] = uhi_df.iloc[indices][\"pm_t_f\"].values\n",
    "submission_df[\"am_t_f\"] = uhi_df.iloc[indices][\"am_t_f\"].values\n",
    "submission_df[\"af_t_f\"] = uhi_df.iloc[indices][\"af_t_f\"].values\n",
    "submission_df[\"pm_hi_f\"] = uhi_df.iloc[indices][\"pm_hi_f\"].values\n",
    "submission_df[\"am_hi_f\"] = uhi_df.iloc[indices][\"am_hi_f\"].values\n",
    "submission_df[\"af_hi_f\"] = uhi_df.iloc[indices][\"af_hi_f\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f', 'am_hi_f',\n",
    "     'pm_t_f', 'am_t_f'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95931ff2-b5b6-46f9-ab68-1ac076b578a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "pm_t_f                              0.109659\n",
      "building_density_ratio_squared      0.091511\n",
      "building_density_ratio              0.089435\n",
      "log_building_density_ratio          0.079321\n",
      "pm_hi_f                             0.078861\n",
      "building_density                    0.076687\n",
      "Wind_Speed_x_Building_Density       0.059132\n",
      "building_density_LST_interaction    0.043896\n",
      "am_t_f                              0.040812\n",
      "am_hi_f                             0.036909\n",
      "temp_deviation_smooth               0.036291\n",
      "LST                                 0.024083\n",
      "log_LST                             0.023738\n",
      "Nearest_AirTemp_C                   0.022383\n",
      "Temp_Anomaly                        0.022184\n",
      "SAVI_LST_sqrt_diff                  0.021629\n",
      "mean_temp                           0.020670\n",
      "relative_humidity_                  0.019512\n",
      "temp_deviation                      0.019402\n",
      "temp_2m_                            0.018714\n",
      "solar_insolation_                   0.017423\n",
      "wind_direction_merge_               0.013978\n",
      "nearest_building_area               0.012183\n",
      "log_building_perimeter              0.010840\n",
      "nearest_building_perimeter          0.010745\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "building_density                    0.105033\n",
      "building_density_ratio              0.103005\n",
      "pm_t_f                              0.093029\n",
      "building_density_ratio_squared      0.092640\n",
      "log_building_density_ratio          0.082638\n",
      "pm_hi_f                             0.060779\n",
      "Wind_Speed_x_Building_Density       0.049390\n",
      "am_t_f                              0.041246\n",
      "building_density_LST_interaction    0.032483\n",
      "temp_deviation_smooth               0.032225\n",
      "temp_2m_                            0.030598\n",
      "Nearest_AirTemp_C                   0.029794\n",
      "relative_humidity_                  0.029430\n",
      "Temp_Anomaly                        0.027900\n",
      "am_hi_f                             0.027532\n",
      "solar_insolation_                   0.025078\n",
      "LST                                 0.020788\n",
      "log_LST                             0.019986\n",
      "wind_direction_merge_               0.019334\n",
      "SAVI_LST_sqrt_diff                  0.016702\n",
      "temp_deviation                      0.014388\n",
      "mean_temp                           0.014223\n",
      "nearest_building_area               0.011320\n",
      "nearest_building_perimeter          0.010238\n",
      "log_building_perimeter              0.010222\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66db07b3-ac97-4729-b5de-d93688b1aa6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.9452175  0.96657972 0.87880723        nan 0.9452175  0.95388724\n",
      " 0.96116925 0.87557934 0.87818029 0.87807465 0.87551371 0.94582099\n",
      " 0.87763169        nan 0.96657972 0.8699509  0.95472323 0.96583337\n",
      "        nan 0.94471725 0.94521596        nan 0.9458286  0.9612491\n",
      "        nan        nan 0.87842581 0.94605052        nan 0.94521596\n",
      "        nan 0.96657727 0.95920959 0.95463127 0.94605052 0.9637646\n",
      " 0.96193147        nan 0.94521596 0.9452175         nan 0.95596783\n",
      " 0.96401064 0.96634869        nan        nan 0.95602812 0.96321356\n",
      "        nan 0.96124302]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9752\n",
      "LightGBM R² Score: 0.9723\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.976228\n",
      "1    Out-of-Bag Score  0.972509\n",
      "2   Mean CV R-squared  0.083838\n",
      "3  Ensemble R-squared  0.972708\n",
      "\n",
      "Submission file saved to Submission240.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"final_merged_weather_uhi_cleaned3_hyperlocal_all.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission240.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_t_f', 'am_hi_f'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Extract coordinates using the correct column names\n",
    "uhi_coords = uhi_df[['longitude', 'latitude']].values  # UHI dataset uses lowercase\n",
    "submission_coords = submission_df[['Longitude', 'Latitude']].values  # Submission dataset uses uppercase\n",
    "\n",
    "# Build a KDTree using UHI dataset\n",
    "uhi_tree = cKDTree(uhi_coords)\n",
    "\n",
    "# Query the KDTree for nearest neighbors\n",
    "_, indices = uhi_tree.query(submission_coords, k=1)  # k=1 ensures the nearest point is found\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f\"] = uhi_df.iloc[indices][\"pm_t_f\"].values\n",
    "submission_df[\"am_t_f\"] = uhi_df.iloc[indices][\"am_t_f\"].values\n",
    "submission_df[\"af_t_f\"] = uhi_df.iloc[indices][\"af_t_f\"].values\n",
    "submission_df[\"pm_hi_f\"] = uhi_df.iloc[indices][\"pm_hi_f\"].values\n",
    "submission_df[\"am_hi_f\"] = uhi_df.iloc[indices][\"am_hi_f\"].values\n",
    "submission_df[\"af_hi_f\"] = uhi_df.iloc[indices][\"af_hi_f\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_t_f', 'am_hi_f'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1645385-9b2e-44a2-94bd-3e21b40b965c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.95869458 0.97483338 0.92454287        nan 0.96060755 0.96728249\n",
      " 0.97114887 0.92762809 0.92439984 0.93046172 0.92807515 0.96108028\n",
      " 0.92430511        nan 0.97530469 0.92390355 0.96754199 0.9740868\n",
      "        nan 0.96066874 0.96089433        nan 0.95922661 0.97194718\n",
      "        nan        nan 0.92941122 0.96115986        nan 0.95887747\n",
      "        nan 0.97535254 0.97019982 0.96593575 0.95921504 0.97281737\n",
      " 0.97256545        nan 0.95887747 0.95869458        nan 0.96752722\n",
      " 0.97292671 0.97460237        nan        nan 0.96790378 0.97238788\n",
      "        nan 0.97201203]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9709\n",
      "LightGBM R² Score: 0.9790\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.966824\n",
      "1    Out-of-Bag Score  0.978930\n",
      "2   Mean CV R-squared  0.296213\n",
      "3  Ensemble R-squared  0.945207\n",
      "\n",
      "Submission file saved to Submission241.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"uhi_pluto_cleaned_filtered.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission241.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_t_f', 'am_hi_f', \n",
    "     \"bldgarea\", \"numfloors\", \"unitsres\", \"unitstotal\", \"bldgfront\", \"bldgdepth\",\n",
    "     \"lotarea\", \"residfar\", \"commfar\", \"facilfar\", \"garagearea\", \"strgearea\", \"factryarea\",\n",
    "     \"assessland\", \"yearbuilt\", \"yearalter1\", \"yearalter2\", \"temp_index\"\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Extract coordinates using the correct column names\n",
    "uhi_coords = uhi_df[['longitude', 'latitude']].values  # UHI dataset uses lowercase\n",
    "submission_coords = submission_df[['Longitude', 'Latitude']].values  # Submission dataset uses uppercase\n",
    "\n",
    "# Build a KDTree using UHI dataset\n",
    "uhi_tree = cKDTree(uhi_coords)\n",
    "\n",
    "# Query the KDTree for nearest neighbors\n",
    "_, indices = uhi_tree.query(submission_coords, k=1)  # k=1 ensures the nearest point is found\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f\"] = uhi_df.iloc[indices][\"pm_t_f\"].values\n",
    "submission_df[\"am_t_f\"] = uhi_df.iloc[indices][\"am_t_f\"].values\n",
    "submission_df[\"af_t_f\"] = uhi_df.iloc[indices][\"af_t_f\"].values\n",
    "submission_df[\"pm_hi_f\"] = uhi_df.iloc[indices][\"pm_hi_f\"].values\n",
    "submission_df[\"am_hi_f\"] = uhi_df.iloc[indices][\"am_hi_f\"].values\n",
    "submission_df[\"af_hi_f\"] = uhi_df.iloc[indices][\"af_hi_f\"].values\n",
    "submission_df[\"bldgarea\"] = uhi_df.iloc[indices][\"bldgarea\"].values\n",
    "submission_df[\"numfloors\"] = uhi_df.iloc[indices][\"numfloors\"].values\n",
    "submission_df[\"unitsres\"] = uhi_df.iloc[indices][\"unitsres\"].values\n",
    "submission_df[\"unitstotal\"] = uhi_df.iloc[indices][\"unitstotal\"].values\n",
    "submission_df[\"bldgfront\"] = uhi_df.iloc[indices][\"bldgfront\"].values\n",
    "submission_df[\"bldgdepth\"] = uhi_df.iloc[indices][\"bldgdepth\"].values\n",
    "submission_df[\"lotarea\"] = uhi_df.iloc[indices][\"lotarea\"].values\n",
    "submission_df[\"residfar\"] = uhi_df.iloc[indices][\"residfar\"].values\n",
    "submission_df[\"commfar\"] = uhi_df.iloc[indices][\"commfar\"].values\n",
    "submission_df[\"facilfar\"] = uhi_df.iloc[indices][\"facilfar\"].values\n",
    "submission_df[\"garagearea\"] = uhi_df.iloc[indices][\"garagearea\"].values\n",
    "submission_df[\"strgearea\"] = uhi_df.iloc[indices][\"strgearea\"].values\n",
    "submission_df[\"factryarea\"] = uhi_df.iloc[indices][\"factryarea\"].values\n",
    "submission_df[\"assessland\"] = uhi_df.iloc[indices][\"assessland\"].values\n",
    "submission_df[\"yearbuilt\"] = uhi_df.iloc[indices][\"yearbuilt\"].values\n",
    "submission_df[\"yearalter1\"] = uhi_df.iloc[indices][\"yearalter1\"].values\n",
    "submission_df[\"yearalter2\"] = uhi_df.iloc[indices][\"yearalter2\"].values\n",
    "submission_df[\"temp_index\"] = uhi_df.iloc[indices][\"temp_index\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_t_f', 'am_hi_f', \n",
    "     \"bldgarea\", \"numfloors\", \"unitsres\", \"unitstotal\", \"bldgfront\", \"bldgdepth\",\n",
    "     \"lotarea\", \"residfar\", \"commfar\", \"facilfar\", \"garagearea\", \"strgearea\", \"factryarea\",\n",
    "     \"assessland\", \"yearbuilt\", \"yearalter1\", \"yearalter2\", \"temp_index\"\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4036934-9733-46b3-9b32-2abafd658453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "pm_t_f                              0.119197\n",
      "Wind_Speed_x_Building_Density       0.111653\n",
      "building_density_ratio              0.076816\n",
      "building_density_ratio_squared      0.076434\n",
      "log_building_density_ratio          0.072667\n",
      "building_density                    0.067788\n",
      "building_density_LST_interaction    0.053016\n",
      "temp_deviation_smooth               0.048554\n",
      "am_hi_f                             0.046984\n",
      "wind_direction_merge_               0.027610\n",
      "log_LST                             0.024376\n",
      "Temp_Anomaly                        0.022945\n",
      "LST                                 0.022631\n",
      "Nearest_AirTemp_C                   0.022249\n",
      "relative_humidity_                  0.022042\n",
      "SAVI_LST_sqrt_diff                  0.021494\n",
      "temp_2m_                            0.019538\n",
      "solar_insolation_                   0.017373\n",
      "mean_temp                           0.015244\n",
      "temp_deviation                      0.015166\n",
      "temp_index                          0.014659\n",
      "nearest_building_area               0.011920\n",
      "nearest_building_perimeter          0.011775\n",
      "log_building_perimeter              0.011205\n",
      "facilfar                            0.005371\n",
      "lotarea                             0.004676\n",
      "residfar                            0.004501\n",
      "assessland                          0.004289\n",
      "bldgarea                            0.004281\n",
      "bldgfront                           0.004119\n",
      "yearbuilt                           0.003647\n",
      "bldgdepth                           0.003638\n",
      "numfloors                           0.003476\n",
      "unitstotal                          0.002258\n",
      "unitsres                            0.002162\n",
      "commfar                             0.001434\n",
      "yearalter1                          0.001281\n",
      "garagearea                          0.000624\n",
      "strgearea                           0.000394\n",
      "yearalter2                          0.000306\n",
      "factryarea                          0.000206\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "Wind_Speed_x_Building_Density       0.135217\n",
      "pm_t_f                              0.101312\n",
      "building_density_ratio_squared      0.089328\n",
      "building_density_ratio              0.074686\n",
      "building_density                    0.068070\n",
      "log_building_density_ratio          0.054402\n",
      "temp_deviation_smooth               0.053266\n",
      "solar_insolation_                   0.048107\n",
      "building_density_LST_interaction    0.041672\n",
      "Nearest_AirTemp_C                   0.037116\n",
      "Temp_Anomaly                        0.032814\n",
      "wind_direction_merge_               0.032065\n",
      "am_hi_f                             0.030869\n",
      "relative_humidity_                  0.026558\n",
      "LST                                 0.023691\n",
      "temp_2m_                            0.023037\n",
      "log_LST                             0.020167\n",
      "SAVI_LST_sqrt_diff                  0.018721\n",
      "mean_temp                           0.010755\n",
      "temp_deviation                      0.010623\n",
      "temp_index                          0.008759\n",
      "nearest_building_area               0.007962\n",
      "nearest_building_perimeter          0.007787\n",
      "log_building_perimeter              0.007786\n",
      "facilfar                            0.007251\n",
      "residfar                            0.004780\n",
      "yearbuilt                           0.002497\n",
      "bldgdepth                           0.002428\n",
      "bldgfront                           0.002404\n",
      "lotarea                             0.002172\n",
      "commfar                             0.002006\n",
      "numfloors                           0.001970\n",
      "yearalter1                          0.001856\n",
      "assessland                          0.001715\n",
      "bldgarea                            0.001451\n",
      "unitsres                            0.001441\n",
      "unitstotal                          0.001423\n",
      "yearalter2                          0.000639\n",
      "garagearea                          0.000551\n",
      "strgearea                           0.000351\n",
      "factryarea                          0.000297\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89a175cb-88d9-4070-b20e-82ff0cdd95c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.96192351 0.97607918 0.9320127         nan 0.96192351 0.96841655\n",
      " 0.97285595 0.93060892 0.93210895 0.93150202 0.92996606 0.96246862\n",
      " 0.9315908         nan 0.97607918 0.92588573 0.96842788 0.97548861\n",
      "        nan 0.9616328  0.96213761        nan 0.96245226 0.97276727\n",
      "        nan        nan 0.93135897 0.96244043        nan 0.96213761\n",
      "        nan 0.97657284 0.97217089 0.96806595 0.96244043 0.97435783\n",
      " 0.97341914        nan 0.96213761 0.96192351        nan 0.9698218\n",
      " 0.97449211 0.97596236        nan        nan 0.97001857 0.97403947\n",
      "        nan 0.97294154]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9723\n",
      "LightGBM R² Score: 0.9694\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.965480\n",
      "1    Out-of-Bag Score  0.979798\n",
      "2   Mean CV R-squared  0.317806\n",
      "3  Ensemble R-squared  0.945357\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- assessland\n- factryarea\n- garagearea\n- strgearea\n- unitsres\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dt/dc70y46s5qb_49mhx2v_52dc0000gn/T/ipykernel_1203/4261862396.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;31m# Predict UHI Index for Submission File\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m submission_df[\"UHI Index\"] = (\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0;36m0.2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbest_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_submission\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mextra_trees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_submission\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_submission\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;34m+\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_submission\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0mensure_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2917\u001b[0m         \u001b[0mvalidated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2918\u001b[0m     \"\"\"\n\u001b[0;32m-> 2919\u001b[0;31m     \u001b[0m_check_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_estimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2920\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2921\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequired\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_feature_names\u001b[0;34m(estimator, X, reset)\u001b[0m\n\u001b[1;32m   2775\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Feature names must be in the same order as they were in fit.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- assessland\n- factryarea\n- garagearea\n- strgearea\n- unitsres\n- ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"uhi_pluto_cleaned_filtered.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission242.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_t_f', 'am_hi_f', \n",
    "     \"bldgarea\", \"numfloors\", \"bldgfront\", \"bldgdepth\",\n",
    "     \"lotarea\", \"residfar\", \"commfar\", \"facilfar\", \"temp_index\"\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Extract coordinates using the correct column names\n",
    "uhi_coords = uhi_df[['longitude', 'latitude']].values  # UHI dataset uses lowercase\n",
    "submission_coords = submission_df[['Longitude', 'Latitude']].values  # Submission dataset uses uppercase\n",
    "\n",
    "# Build a KDTree using UHI dataset\n",
    "uhi_tree = cKDTree(uhi_coords)\n",
    "\n",
    "# Query the KDTree for nearest neighbors\n",
    "_, indices = uhi_tree.query(submission_coords, k=1)  # k=1 ensures the nearest point is found\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f\"] = uhi_df.iloc[indices][\"pm_t_f\"].values\n",
    "submission_df[\"am_t_f\"] = uhi_df.iloc[indices][\"am_t_f\"].values\n",
    "submission_df[\"af_t_f\"] = uhi_df.iloc[indices][\"af_t_f\"].values\n",
    "submission_df[\"pm_hi_f\"] = uhi_df.iloc[indices][\"pm_hi_f\"].values\n",
    "submission_df[\"am_hi_f\"] = uhi_df.iloc[indices][\"am_hi_f\"].values\n",
    "submission_df[\"af_hi_f\"] = uhi_df.iloc[indices][\"af_hi_f\"].values\n",
    "submission_df[\"bldgarea\"] = uhi_df.iloc[indices][\"bldgarea\"].values\n",
    "submission_df[\"numfloors\"] = uhi_df.iloc[indices][\"numfloors\"].values\n",
    "submission_df[\"unitsres\"] = uhi_df.iloc[indices][\"unitsres\"].values\n",
    "submission_df[\"unitstotal\"] = uhi_df.iloc[indices][\"unitstotal\"].values\n",
    "submission_df[\"bldgfront\"] = uhi_df.iloc[indices][\"bldgfront\"].values\n",
    "submission_df[\"bldgdepth\"] = uhi_df.iloc[indices][\"bldgdepth\"].values\n",
    "submission_df[\"lotarea\"] = uhi_df.iloc[indices][\"lotarea\"].values\n",
    "submission_df[\"residfar\"] = uhi_df.iloc[indices][\"residfar\"].values\n",
    "submission_df[\"commfar\"] = uhi_df.iloc[indices][\"commfar\"].values\n",
    "submission_df[\"facilfar\"] = uhi_df.iloc[indices][\"facilfar\"].values\n",
    "submission_df[\"garagearea\"] = uhi_df.iloc[indices][\"garagearea\"].values\n",
    "submission_df[\"strgearea\"] = uhi_df.iloc[indices][\"strgearea\"].values\n",
    "submission_df[\"factryarea\"] = uhi_df.iloc[indices][\"factryarea\"].values\n",
    "submission_df[\"assessland\"] = uhi_df.iloc[indices][\"assessland\"].values\n",
    "submission_df[\"yearbuilt\"] = uhi_df.iloc[indices][\"yearbuilt\"].values\n",
    "submission_df[\"yearalter1\"] = uhi_df.iloc[indices][\"yearalter1\"].values\n",
    "submission_df[\"yearalter2\"] = uhi_df.iloc[indices][\"yearalter2\"].values\n",
    "submission_df[\"temp_index\"] = uhi_df.iloc[indices][\"temp_index\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_t_f', 'am_hi_f', \n",
    "     \"bldgarea\", \"numfloors\", \"bldgfront\", \"bldgdepth\",\n",
    "     \"lotarea\", \"residfar\", \"commfar\", \"facilfar\", \"temp_index\"\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f09c303e-b565-4799-9282-23b5197fb5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "pm_t_f                              0.132610\n",
      "Wind_Speed_x_Building_Density       0.131537\n",
      "building_density_ratio              0.083182\n",
      "building_density_ratio_squared      0.077356\n",
      "log_building_density_ratio          0.074333\n",
      "building_density                    0.071703\n",
      "am_hi_f                             0.048650\n",
      "building_density_LST_interaction    0.046128\n",
      "temp_deviation_smooth               0.044095\n",
      "LST                                 0.023518\n",
      "log_LST                             0.023459\n",
      "wind_direction_merge_               0.023054\n",
      "Nearest_AirTemp_C                   0.021729\n",
      "Temp_Anomaly                        0.021451\n",
      "SAVI_LST_sqrt_diff                  0.020204\n",
      "relative_humidity_                  0.019669\n",
      "temp_2m_                            0.019554\n",
      "solar_insolation_                   0.015247\n",
      "temp_deviation                      0.014517\n",
      "mean_temp                           0.013938\n",
      "temp_index                          0.013377\n",
      "nearest_building_area               0.010728\n",
      "nearest_building_perimeter          0.010422\n",
      "log_building_perimeter              0.010198\n",
      "facilfar                            0.004609\n",
      "lotarea                             0.004520\n",
      "bldgarea                            0.004296\n",
      "bldgfront                           0.003968\n",
      "residfar                            0.003874\n",
      "bldgdepth                           0.003716\n",
      "numfloors                           0.003125\n",
      "commfar                             0.001235\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "Wind_Speed_x_Building_Density       0.144004\n",
      "pm_t_f                              0.101538\n",
      "building_density_ratio_squared      0.085907\n",
      "building_density                    0.072235\n",
      "building_density_ratio              0.071823\n",
      "log_building_density_ratio          0.057185\n",
      "temp_deviation_smooth               0.054813\n",
      "solar_insolation_                   0.045634\n",
      "building_density_LST_interaction    0.041048\n",
      "Nearest_AirTemp_C                   0.033275\n",
      "Temp_Anomaly                        0.032530\n",
      "am_hi_f                             0.031988\n",
      "wind_direction_merge_               0.031203\n",
      "relative_humidity_                  0.025003\n",
      "LST                                 0.023631\n",
      "temp_2m_                            0.022910\n",
      "log_LST                             0.022317\n",
      "SAVI_LST_sqrt_diff                  0.017784\n",
      "temp_deviation                      0.011291\n",
      "mean_temp                           0.010469\n",
      "temp_index                          0.009024\n",
      "nearest_building_area               0.008878\n",
      "log_building_perimeter              0.008813\n",
      "nearest_building_perimeter          0.008165\n",
      "facilfar                            0.007579\n",
      "residfar                            0.004871\n",
      "bldgdepth                           0.003166\n",
      "bldgfront                           0.003110\n",
      "lotarea                             0.002761\n",
      "numfloors                           0.002572\n",
      "commfar                             0.002420\n",
      "bldgarea                            0.002055\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bf27749-5960-403e-bfbe-b1ba43b477e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.96382678 0.97752304 0.93618517        nan 0.96382678 0.97003595\n",
      " 0.97447708 0.93390834 0.93537948 0.93566884 0.93391421 0.96399684\n",
      " 0.93502754        nan 0.97752304 0.92955107 0.97019935 0.97721755\n",
      "        nan 0.96377853 0.96387946        nan 0.96403849 0.97441264\n",
      "        nan        nan 0.93520332 0.96416117        nan 0.96387946\n",
      "        nan 0.97795346 0.97367915 0.9700266  0.96416117 0.97583711\n",
      " 0.9750214         nan 0.96387946 0.96382678        nan 0.97128016\n",
      " 0.97589283 0.97745725        nan        nan 0.97152407 0.97554374\n",
      "        nan 0.97450844]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9755\n",
      "LightGBM R² Score: 0.9652\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.962705\n",
      "1    Out-of-Bag Score  0.980743\n",
      "2   Mean CV R-squared  0.270970\n",
      "3  Ensemble R-squared  0.947151\n",
      "\n",
      "Submission file saved to Submission243.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"uhi_pluto_cleaned_filtered.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission243.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_t_f', 'am_hi_f', \n",
    "     'temp_index'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Extract coordinates using the correct column names\n",
    "uhi_coords = uhi_df[['longitude', 'latitude']].values  # UHI dataset uses lowercase\n",
    "submission_coords = submission_df[['Longitude', 'Latitude']].values  # Submission dataset uses uppercase\n",
    "\n",
    "# Build a KDTree using UHI dataset\n",
    "uhi_tree = cKDTree(uhi_coords)\n",
    "\n",
    "# Query the KDTree for nearest neighbors\n",
    "_, indices = uhi_tree.query(submission_coords, k=1)  # k=1 ensures the nearest point is found\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f\"] = uhi_df.iloc[indices][\"pm_t_f\"].values\n",
    "submission_df[\"am_t_f\"] = uhi_df.iloc[indices][\"am_t_f\"].values\n",
    "submission_df[\"af_t_f\"] = uhi_df.iloc[indices][\"af_t_f\"].values\n",
    "submission_df[\"pm_hi_f\"] = uhi_df.iloc[indices][\"pm_hi_f\"].values\n",
    "submission_df[\"am_hi_f\"] = uhi_df.iloc[indices][\"am_hi_f\"].values\n",
    "submission_df[\"af_hi_f\"] = uhi_df.iloc[indices][\"af_hi_f\"].values\n",
    "submission_df[\"bldgarea\"] = uhi_df.iloc[indices][\"bldgarea\"].values\n",
    "submission_df[\"numfloors\"] = uhi_df.iloc[indices][\"numfloors\"].values\n",
    "submission_df[\"unitsres\"] = uhi_df.iloc[indices][\"unitsres\"].values\n",
    "submission_df[\"unitstotal\"] = uhi_df.iloc[indices][\"unitstotal\"].values\n",
    "submission_df[\"bldgfront\"] = uhi_df.iloc[indices][\"bldgfront\"].values\n",
    "submission_df[\"bldgdepth\"] = uhi_df.iloc[indices][\"bldgdepth\"].values\n",
    "submission_df[\"lotarea\"] = uhi_df.iloc[indices][\"lotarea\"].values\n",
    "submission_df[\"residfar\"] = uhi_df.iloc[indices][\"residfar\"].values\n",
    "submission_df[\"commfar\"] = uhi_df.iloc[indices][\"commfar\"].values\n",
    "submission_df[\"facilfar\"] = uhi_df.iloc[indices][\"facilfar\"].values\n",
    "submission_df[\"garagearea\"] = uhi_df.iloc[indices][\"garagearea\"].values\n",
    "submission_df[\"strgearea\"] = uhi_df.iloc[indices][\"strgearea\"].values\n",
    "submission_df[\"factryarea\"] = uhi_df.iloc[indices][\"factryarea\"].values\n",
    "submission_df[\"assessland\"] = uhi_df.iloc[indices][\"assessland\"].values\n",
    "submission_df[\"yearbuilt\"] = uhi_df.iloc[indices][\"yearbuilt\"].values\n",
    "submission_df[\"yearalter1\"] = uhi_df.iloc[indices][\"yearalter1\"].values\n",
    "submission_df[\"yearalter2\"] = uhi_df.iloc[indices][\"yearalter2\"].values\n",
    "submission_df[\"temp_index\"] = uhi_df.iloc[indices][\"temp_index\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_t_f', 'am_hi_f', \n",
    "     'temp_index'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da8b12c2-0407-48ff-839e-eb3e30c3577f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "pm_t_f                              0.136600\n",
      "Wind_Speed_x_Building_Density       0.131712\n",
      "building_density_ratio_squared      0.083885\n",
      "log_building_density_ratio          0.078859\n",
      "building_density_ratio              0.077590\n",
      "building_density                    0.071371\n",
      "temp_deviation_smooth               0.052861\n",
      "building_density_LST_interaction    0.050750\n",
      "am_hi_f                             0.048259\n",
      "log_LST                             0.025276\n",
      "LST                                 0.024281\n",
      "Nearest_AirTemp_C                   0.023020\n",
      "wind_direction_merge_               0.022507\n",
      "Temp_Anomaly                        0.021179\n",
      "SAVI_LST_sqrt_diff                  0.020538\n",
      "relative_humidity_                  0.020226\n",
      "temp_2m_                            0.019189\n",
      "solar_insolation_                   0.015804\n",
      "temp_deviation                      0.014907\n",
      "temp_index                          0.014467\n",
      "mean_temp                           0.014319\n",
      "nearest_building_area               0.011401\n",
      "log_building_perimeter              0.010516\n",
      "nearest_building_perimeter          0.010483\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "Wind_Speed_x_Building_Density       0.140864\n",
      "pm_t_f                              0.099907\n",
      "building_density_ratio_squared      0.086814\n",
      "building_density_ratio              0.078372\n",
      "building_density                    0.078141\n",
      "temp_deviation_smooth               0.059101\n",
      "log_building_density_ratio          0.053121\n",
      "solar_insolation_                   0.044302\n",
      "building_density_LST_interaction    0.041949\n",
      "Nearest_AirTemp_C                   0.037160\n",
      "Temp_Anomaly                        0.035205\n",
      "am_hi_f                             0.034146\n",
      "wind_direction_merge_               0.030866\n",
      "relative_humidity_                  0.026203\n",
      "temp_2m_                            0.025089\n",
      "LST                                 0.024040\n",
      "log_LST                             0.022727\n",
      "SAVI_LST_sqrt_diff                  0.019793\n",
      "mean_temp                           0.011853\n",
      "temp_deviation                      0.011695\n",
      "temp_index                          0.010941\n",
      "log_building_perimeter              0.009629\n",
      "nearest_building_area               0.009274\n",
      "nearest_building_perimeter          0.008808\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f01639e6-f925-440f-be10-a477118abe54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "65 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.96279178 0.97710261 0.93380689        nan 0.96279178 0.9692649\n",
      " 0.97401795 0.93064265 0.93217994 0.93132406 0.93046983 0.96316249\n",
      " 0.93177814        nan 0.97710261 0.92601222 0.96954681 0.97685867\n",
      "        nan 0.96258404 0.96294151        nan 0.963212   0.9739715\n",
      "        nan        nan 0.93183864 0.96326499        nan 0.96294151\n",
      "        nan 0.97769544 0.97325039 0.96934907 0.96326499 0.97531077\n",
      " 0.97458538        nan 0.96294151 0.96279178        nan 0.97072703\n",
      " 0.97551523 0.97711661        nan        nan 0.97085804 0.9751198\n",
      "        nan 0.9740743 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9745\n",
      "LightGBM R² Score: 0.9716\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.965370\n",
      "1    Out-of-Bag Score  0.980505\n",
      "2   Mean CV R-squared  0.286599\n",
      "3  Ensemble R-squared  0.948894\n",
      "\n",
      "Submission file saved to Submission244.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"uhi_pluto_cleaned_filtered.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission244.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_t_f',\n",
    "     'temp_index'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Extract coordinates using the correct column names\n",
    "uhi_coords = uhi_df[['longitude', 'latitude']].values  # UHI dataset uses lowercase\n",
    "submission_coords = submission_df[['Longitude', 'Latitude']].values  # Submission dataset uses uppercase\n",
    "\n",
    "# Build a KDTree using UHI dataset\n",
    "uhi_tree = cKDTree(uhi_coords)\n",
    "\n",
    "# Query the KDTree for nearest neighbors\n",
    "_, indices = uhi_tree.query(submission_coords, k=1)  # k=1 ensures the nearest point is found\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f\"] = uhi_df.iloc[indices][\"pm_t_f\"].values\n",
    "submission_df[\"am_t_f\"] = uhi_df.iloc[indices][\"am_t_f\"].values\n",
    "submission_df[\"af_t_f\"] = uhi_df.iloc[indices][\"af_t_f\"].values\n",
    "submission_df[\"pm_hi_f\"] = uhi_df.iloc[indices][\"pm_hi_f\"].values\n",
    "submission_df[\"am_hi_f\"] = uhi_df.iloc[indices][\"am_hi_f\"].values\n",
    "submission_df[\"af_hi_f\"] = uhi_df.iloc[indices][\"af_hi_f\"].values\n",
    "submission_df[\"bldgarea\"] = uhi_df.iloc[indices][\"bldgarea\"].values\n",
    "submission_df[\"numfloors\"] = uhi_df.iloc[indices][\"numfloors\"].values\n",
    "submission_df[\"unitsres\"] = uhi_df.iloc[indices][\"unitsres\"].values\n",
    "submission_df[\"unitstotal\"] = uhi_df.iloc[indices][\"unitstotal\"].values\n",
    "submission_df[\"bldgfront\"] = uhi_df.iloc[indices][\"bldgfront\"].values\n",
    "submission_df[\"bldgdepth\"] = uhi_df.iloc[indices][\"bldgdepth\"].values\n",
    "submission_df[\"lotarea\"] = uhi_df.iloc[indices][\"lotarea\"].values\n",
    "submission_df[\"residfar\"] = uhi_df.iloc[indices][\"residfar\"].values\n",
    "submission_df[\"commfar\"] = uhi_df.iloc[indices][\"commfar\"].values\n",
    "submission_df[\"facilfar\"] = uhi_df.iloc[indices][\"facilfar\"].values\n",
    "submission_df[\"garagearea\"] = uhi_df.iloc[indices][\"garagearea\"].values\n",
    "submission_df[\"strgearea\"] = uhi_df.iloc[indices][\"strgearea\"].values\n",
    "submission_df[\"factryarea\"] = uhi_df.iloc[indices][\"factryarea\"].values\n",
    "submission_df[\"assessland\"] = uhi_df.iloc[indices][\"assessland\"].values\n",
    "submission_df[\"yearbuilt\"] = uhi_df.iloc[indices][\"yearbuilt\"].values\n",
    "submission_df[\"yearalter1\"] = uhi_df.iloc[indices][\"yearalter1\"].values\n",
    "submission_df[\"yearalter2\"] = uhi_df.iloc[indices][\"yearalter2\"].values\n",
    "submission_df[\"temp_index\"] = uhi_df.iloc[indices][\"temp_index\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_t_f',\n",
    "     'temp_index'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "683afbb0-179b-4361-aa31-cc0458d78e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "pm_t_f                              0.153939\n",
      "Wind_Speed_x_Building_Density       0.126996\n",
      "building_density_ratio_squared      0.090196\n",
      "building_density_ratio              0.086027\n",
      "building_density                    0.079408\n",
      "log_building_density_ratio          0.075928\n",
      "temp_deviation_smooth               0.053572\n",
      "building_density_LST_interaction    0.049401\n",
      "Temp_Anomaly                        0.026418\n",
      "log_LST                             0.024997\n",
      "LST                                 0.024757\n",
      "Nearest_AirTemp_C                   0.023409\n",
      "relative_humidity_                  0.021964\n",
      "temp_2m_                            0.020904\n",
      "SAVI_LST_sqrt_diff                  0.020677\n",
      "wind_direction_merge_               0.020543\n",
      "mean_temp                           0.016970\n",
      "solar_insolation_                   0.016276\n",
      "temp_deviation                      0.016081\n",
      "temp_index                          0.015448\n",
      "nearest_building_area               0.012580\n",
      "log_building_perimeter              0.011949\n",
      "nearest_building_perimeter          0.011560\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "Wind_Speed_x_Building_Density       0.156972\n",
      "pm_t_f                              0.106517\n",
      "building_density_ratio_squared      0.085095\n",
      "building_density                    0.081120\n",
      "building_density_ratio              0.079597\n",
      "temp_deviation_smooth               0.056105\n",
      "log_building_density_ratio          0.054239\n",
      "solar_insolation_                   0.048512\n",
      "building_density_LST_interaction    0.041512\n",
      "Nearest_AirTemp_C                   0.035546\n",
      "Temp_Anomaly                        0.035456\n",
      "wind_direction_merge_               0.033728\n",
      "LST                                 0.024715\n",
      "relative_humidity_                  0.024464\n",
      "temp_2m_                            0.024210\n",
      "log_LST                             0.023117\n",
      "SAVI_LST_sqrt_diff                  0.020503\n",
      "temp_deviation                      0.013003\n",
      "mean_temp                           0.012787\n",
      "temp_index                          0.012232\n",
      "log_building_perimeter              0.010837\n",
      "nearest_building_perimeter          0.010426\n",
      "nearest_building_area               0.009307\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65f4e0d6-4bac-4dcd-a046-cad113350ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "27 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "38 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.96281212 0.97698654 0.92743521        nan 0.96281212 0.96925211\n",
      " 0.97385529 0.92503784 0.92726172 0.92670662 0.9245359  0.96298503\n",
      " 0.92697334        nan 0.97698654 0.92068864 0.96944116 0.97652799\n",
      "        nan 0.96252338 0.96290176        nan 0.96308056 0.97384251\n",
      "        nan        nan 0.9262058  0.96311597        nan 0.96290176\n",
      "        nan 0.97745479 0.97329676 0.9692328  0.96311597 0.97508113\n",
      " 0.97451526        nan 0.96290176 0.96281212        nan 0.97059515\n",
      " 0.97521635 0.9768389         nan        nan 0.97083386 0.97484899\n",
      "        nan 0.97395038]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM R² Score: 0.9653\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.962119\n",
      "1    Out-of-Bag Score  0.980358\n",
      "2   Mean CV R-squared  0.158215\n",
      "3  Ensemble R-squared  0.947831\n",
      "\n",
      "Submission file saved to Submission245.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"uhi_pluto_cleaned_filtered.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission245.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'am_t_f',\n",
    "     'temp_index'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Extract coordinates using the correct column names\n",
    "uhi_coords = uhi_df[['longitude', 'latitude']].values  # UHI dataset uses lowercase\n",
    "submission_coords = submission_df[['Longitude', 'Latitude']].values  # Submission dataset uses uppercase\n",
    "\n",
    "# Build a KDTree using UHI dataset\n",
    "uhi_tree = cKDTree(uhi_coords)\n",
    "\n",
    "# Query the KDTree for nearest neighbors\n",
    "_, indices = uhi_tree.query(submission_coords, k=1)  # k=1 ensures the nearest point is found\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f\"] = uhi_df.iloc[indices][\"pm_t_f\"].values\n",
    "submission_df[\"am_t_f\"] = uhi_df.iloc[indices][\"am_t_f\"].values\n",
    "submission_df[\"af_t_f\"] = uhi_df.iloc[indices][\"af_t_f\"].values\n",
    "submission_df[\"pm_hi_f\"] = uhi_df.iloc[indices][\"pm_hi_f\"].values\n",
    "submission_df[\"am_hi_f\"] = uhi_df.iloc[indices][\"am_hi_f\"].values\n",
    "submission_df[\"af_hi_f\"] = uhi_df.iloc[indices][\"af_hi_f\"].values\n",
    "submission_df[\"bldgarea\"] = uhi_df.iloc[indices][\"bldgarea\"].values\n",
    "submission_df[\"numfloors\"] = uhi_df.iloc[indices][\"numfloors\"].values\n",
    "submission_df[\"unitsres\"] = uhi_df.iloc[indices][\"unitsres\"].values\n",
    "submission_df[\"unitstotal\"] = uhi_df.iloc[indices][\"unitstotal\"].values\n",
    "submission_df[\"bldgfront\"] = uhi_df.iloc[indices][\"bldgfront\"].values\n",
    "submission_df[\"bldgdepth\"] = uhi_df.iloc[indices][\"bldgdepth\"].values\n",
    "submission_df[\"lotarea\"] = uhi_df.iloc[indices][\"lotarea\"].values\n",
    "submission_df[\"residfar\"] = uhi_df.iloc[indices][\"residfar\"].values\n",
    "submission_df[\"commfar\"] = uhi_df.iloc[indices][\"commfar\"].values\n",
    "submission_df[\"facilfar\"] = uhi_df.iloc[indices][\"facilfar\"].values\n",
    "submission_df[\"garagearea\"] = uhi_df.iloc[indices][\"garagearea\"].values\n",
    "submission_df[\"strgearea\"] = uhi_df.iloc[indices][\"strgearea\"].values\n",
    "submission_df[\"factryarea\"] = uhi_df.iloc[indices][\"factryarea\"].values\n",
    "submission_df[\"assessland\"] = uhi_df.iloc[indices][\"assessland\"].values\n",
    "submission_df[\"yearbuilt\"] = uhi_df.iloc[indices][\"yearbuilt\"].values\n",
    "submission_df[\"yearalter1\"] = uhi_df.iloc[indices][\"yearalter1\"].values\n",
    "submission_df[\"yearalter2\"] = uhi_df.iloc[indices][\"yearalter2\"].values\n",
    "submission_df[\"temp_index\"] = uhi_df.iloc[indices][\"temp_index\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'am_t_f',\n",
    "     'temp_index'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4fdda7f-bd79-4385-8fcb-442da666c85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "Wind_Speed_x_Building_Density       0.131212\n",
      "building_density_ratio_squared      0.099937\n",
      "building_density_ratio              0.093924\n",
      "building_density                    0.085671\n",
      "log_building_density_ratio          0.085205\n",
      "temp_deviation_smooth               0.063744\n",
      "am_t_f                              0.061310\n",
      "building_density_LST_interaction    0.056750\n",
      "LST                                 0.030682\n",
      "log_LST                             0.030450\n",
      "Temp_Anomaly                        0.029469\n",
      "Nearest_AirTemp_C                   0.026414\n",
      "wind_direction_merge_               0.026284\n",
      "SAVI_LST_sqrt_diff                  0.025299\n",
      "relative_humidity_                  0.024567\n",
      "temp_2m_                            0.024567\n",
      "solar_insolation_                   0.018383\n",
      "mean_temp                           0.017207\n",
      "temp_deviation                      0.017185\n",
      "temp_index                          0.014671\n",
      "nearest_building_area               0.013040\n",
      "nearest_building_perimeter          0.012096\n",
      "log_building_perimeter              0.011934\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "Wind_Speed_x_Building_Density       0.158763\n",
      "building_density_ratio_squared      0.090885\n",
      "building_density_ratio              0.081749\n",
      "building_density                    0.080913\n",
      "log_building_density_ratio          0.061426\n",
      "temp_deviation_smooth               0.060384\n",
      "am_t_f                              0.053331\n",
      "solar_insolation_                   0.049308\n",
      "building_density_LST_interaction    0.046734\n",
      "Nearest_AirTemp_C                   0.040200\n",
      "Temp_Anomaly                        0.038828\n",
      "wind_direction_merge_               0.036341\n",
      "LST                                 0.028320\n",
      "temp_2m_                            0.026772\n",
      "log_LST                             0.026535\n",
      "relative_humidity_                  0.026523\n",
      "SAVI_LST_sqrt_diff                  0.023062\n",
      "mean_temp                           0.013767\n",
      "temp_deviation                      0.013744\n",
      "nearest_building_area               0.010909\n",
      "log_building_perimeter              0.010530\n",
      "nearest_building_perimeter          0.010505\n",
      "temp_index                          0.010470\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c18c88da-f202-4ecb-b57f-bef3d974a9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.98436447 0.98590474 0.98172015        nan 0.98549831 0.98622815\n",
      " 0.98597825 0.98364424 0.98171871 0.9839153  0.9835915  0.98554425\n",
      " 0.98159669        nan 0.98621431 0.98303105 0.98608776 0.98580966\n",
      "        nan 0.98540203 0.98553695        nan 0.98450144 0.98641301\n",
      "        nan        nan 0.98374642 0.98557176        nan 0.9845483\n",
      "        nan 0.98638325 0.98604911 0.98521493 0.98451561 0.98581969\n",
      " 0.98657345        nan 0.9845483  0.98436447        nan 0.98566759\n",
      " 0.98582687 0.98586241        nan        nan 0.98573312 0.98569076\n",
      "        nan 0.98652598]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9940\n",
      "LightGBM R² Score: 0.9947\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.983469\n",
      "1    Out-of-Bag Score  0.986838\n",
      "2   Mean CV R-squared  0.866963\n",
      "3  Ensemble R-squared  0.960388\n",
      "\n",
      "Submission file saved to Submission246.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"uhi_pluto_cleaned_filtered.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission246.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f', 'am_hi_f', 'af_hi_f',\n",
    "     'pm_t_f', 'am_t_f', 'af_t_f',\n",
    "     'temp_index'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Extract coordinates using the correct column names\n",
    "uhi_coords = uhi_df[['longitude', 'latitude']].values  # UHI dataset uses lowercase\n",
    "submission_coords = submission_df[['Longitude', 'Latitude']].values  # Submission dataset uses uppercase\n",
    "\n",
    "# Build a KDTree using UHI dataset\n",
    "uhi_tree = cKDTree(uhi_coords)\n",
    "\n",
    "# Query the KDTree for nearest neighbors\n",
    "_, indices = uhi_tree.query(submission_coords, k=1)  # k=1 ensures the nearest point is found\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f\"] = uhi_df.iloc[indices][\"pm_t_f\"].values\n",
    "submission_df[\"am_t_f\"] = uhi_df.iloc[indices][\"am_t_f\"].values\n",
    "submission_df[\"af_t_f\"] = uhi_df.iloc[indices][\"af_t_f\"].values\n",
    "submission_df[\"pm_hi_f\"] = uhi_df.iloc[indices][\"pm_hi_f\"].values\n",
    "submission_df[\"am_hi_f\"] = uhi_df.iloc[indices][\"am_hi_f\"].values\n",
    "submission_df[\"af_hi_f\"] = uhi_df.iloc[indices][\"af_hi_f\"].values\n",
    "submission_df[\"bldgarea\"] = uhi_df.iloc[indices][\"bldgarea\"].values\n",
    "submission_df[\"numfloors\"] = uhi_df.iloc[indices][\"numfloors\"].values\n",
    "submission_df[\"unitsres\"] = uhi_df.iloc[indices][\"unitsres\"].values\n",
    "submission_df[\"unitstotal\"] = uhi_df.iloc[indices][\"unitstotal\"].values\n",
    "submission_df[\"bldgfront\"] = uhi_df.iloc[indices][\"bldgfront\"].values\n",
    "submission_df[\"bldgdepth\"] = uhi_df.iloc[indices][\"bldgdepth\"].values\n",
    "submission_df[\"lotarea\"] = uhi_df.iloc[indices][\"lotarea\"].values\n",
    "submission_df[\"residfar\"] = uhi_df.iloc[indices][\"residfar\"].values\n",
    "submission_df[\"commfar\"] = uhi_df.iloc[indices][\"commfar\"].values\n",
    "submission_df[\"facilfar\"] = uhi_df.iloc[indices][\"facilfar\"].values\n",
    "submission_df[\"garagearea\"] = uhi_df.iloc[indices][\"garagearea\"].values\n",
    "submission_df[\"strgearea\"] = uhi_df.iloc[indices][\"strgearea\"].values\n",
    "submission_df[\"factryarea\"] = uhi_df.iloc[indices][\"factryarea\"].values\n",
    "submission_df[\"assessland\"] = uhi_df.iloc[indices][\"assessland\"].values\n",
    "submission_df[\"yearbuilt\"] = uhi_df.iloc[indices][\"yearbuilt\"].values\n",
    "submission_df[\"yearalter1\"] = uhi_df.iloc[indices][\"yearalter1\"].values\n",
    "submission_df[\"yearalter2\"] = uhi_df.iloc[indices][\"yearalter2\"].values\n",
    "submission_df[\"temp_index\"] = uhi_df.iloc[indices][\"temp_index\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f', 'am_hi_f', 'af_hi_f',\n",
    "     'pm_t_f', 'am_t_f', 'af_t_f',\n",
    "     'temp_index'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db9c916c-2fdc-4568-9f0e-c2162e32fd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "af_t_f                              0.310481\n",
      "af_hi_f                             0.186626\n",
      "pm_hi_f                             0.080385\n",
      "Wind_Speed_x_Building_Density       0.069956\n",
      "pm_t_f                              0.057956\n",
      "building_density_ratio_squared      0.038004\n",
      "log_building_density_ratio          0.034050\n",
      "building_density_ratio              0.032901\n",
      "building_density                    0.029995\n",
      "building_density_LST_interaction    0.022832\n",
      "temp_deviation_smooth               0.020528\n",
      "am_hi_f                             0.019427\n",
      "am_t_f                              0.017371\n",
      "Nearest_AirTemp_C                   0.008376\n",
      "log_LST                             0.007846\n",
      "Temp_Anomaly                        0.007832\n",
      "LST                                 0.006910\n",
      "wind_direction_merge_               0.006339\n",
      "SAVI_LST_sqrt_diff                  0.005913\n",
      "temp_index                          0.005265\n",
      "temp_2m_                            0.005219\n",
      "temp_deviation                      0.005179\n",
      "mean_temp                           0.004352\n",
      "relative_humidity_                  0.004130\n",
      "solar_insolation_                   0.003557\n",
      "nearest_building_area               0.003239\n",
      "nearest_building_perimeter          0.002723\n",
      "log_building_perimeter              0.002608\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "af_t_f                              0.351350\n",
      "af_hi_f                             0.122321\n",
      "Wind_Speed_x_Building_Density       0.098914\n",
      "building_density_ratio_squared      0.065393\n",
      "building_density                    0.050100\n",
      "building_density_ratio              0.046413\n",
      "temp_deviation_smooth               0.039382\n",
      "log_building_density_ratio          0.035591\n",
      "building_density_LST_interaction    0.026439\n",
      "solar_insolation_                   0.023524\n",
      "Nearest_AirTemp_C                   0.023018\n",
      "Temp_Anomaly                        0.016778\n",
      "wind_direction_merge_               0.016449\n",
      "pm_t_f                              0.013120\n",
      "pm_hi_f                             0.011379\n",
      "relative_humidity_                  0.009405\n",
      "LST                                 0.008490\n",
      "temp_2m_                            0.008374\n",
      "SAVI_LST_sqrt_diff                  0.006769\n",
      "log_LST                             0.006503\n",
      "am_t_f                              0.005937\n",
      "am_hi_f                             0.004695\n",
      "log_building_perimeter              0.002170\n",
      "temp_deviation                      0.001860\n",
      "mean_temp                           0.001630\n",
      "temp_index                          0.001597\n",
      "nearest_building_perimeter          0.001364\n",
      "nearest_building_area               0.001034\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a38989-2e4e-4f5e-b193-9db28ad65f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/dc70y46s5qb_49mhx2v_52dc0000gn/T/ipykernel_12125/1106924400.py:16: DtypeWarning: Columns (59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  uhi_df = pd.read_csv(uhi_updated_path)\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "55 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.96406378 0.97826259 0.93893412        nan 0.96484607 0.97114352\n",
      " 0.97507061 0.93918955 0.93792741 0.94009723 0.9386241  0.96542426\n",
      " 0.93789749        nan 0.97823946 0.93532046 0.9711335  0.97791032\n",
      "        nan 0.96487856 0.96543861        nan 0.96438721 0.97535352\n",
      "        nan        nan 0.94050815 0.96553373        nan 0.9643843\n",
      "        nan 0.97873267 0.97452991 0.9702754  0.96442807 0.97636407\n",
      " 0.97593209        nan 0.9643843  0.96406378        nan 0.97185229\n",
      " 0.97650745 0.97809977        nan        nan 0.97201406 0.97614055\n",
      "        nan 0.97543885]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9670\n",
      "LightGBM R² Score: 0.9649\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.961652\n",
      "1    Out-of-Bag Score  0.981334\n",
      "2   Mean CV R-squared  0.345611\n",
      "3  Ensemble R-squared  0.947127\n",
      "\n",
      "Submission file saved to Submission247.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"Merged_UHI_HHI_Data.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission247.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_t_f', 'am_hi_f', \n",
    "     'temp_index',\n",
    "     'PR_RENT', 'P_RENT', 'OVERALL_RANK', 'OVERALL_SCORE', 'P_OZONE','PR_OZONE',\n",
    "     'PR_PM25', 'P_PM25', 'NBE_SCORE', 'NBE_RANK', 'POP', 'PR_HRI', 'F_HRI'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Extract coordinates using the correct column names\n",
    "uhi_coords = uhi_df[['longitude', 'latitude']].values  # UHI dataset uses lowercase\n",
    "submission_coords = submission_df[['Longitude', 'Latitude']].values  # Submission dataset uses uppercase\n",
    "\n",
    "# Build a KDTree using UHI dataset\n",
    "uhi_tree = cKDTree(uhi_coords)\n",
    "\n",
    "# Query the KDTree for nearest neighbors\n",
    "_, indices = uhi_tree.query(submission_coords, k=1)  # k=1 ensures the nearest point is found\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f\"] = uhi_df.iloc[indices][\"pm_t_f\"].values\n",
    "submission_df[\"am_t_f\"] = uhi_df.iloc[indices][\"am_t_f\"].values\n",
    "submission_df[\"af_t_f\"] = uhi_df.iloc[indices][\"af_t_f\"].values\n",
    "submission_df[\"pm_hi_f\"] = uhi_df.iloc[indices][\"pm_hi_f\"].values\n",
    "submission_df[\"am_hi_f\"] = uhi_df.iloc[indices][\"am_hi_f\"].values\n",
    "submission_df[\"af_hi_f\"] = uhi_df.iloc[indices][\"af_hi_f\"].values\n",
    "submission_df[\"bldgarea\"] = uhi_df.iloc[indices][\"bldgarea\"].values\n",
    "submission_df[\"numfloors\"] = uhi_df.iloc[indices][\"numfloors\"].values\n",
    "submission_df[\"unitsres\"] = uhi_df.iloc[indices][\"unitsres\"].values\n",
    "submission_df[\"unitstotal\"] = uhi_df.iloc[indices][\"unitstotal\"].values\n",
    "submission_df[\"bldgfront\"] = uhi_df.iloc[indices][\"bldgfront\"].values\n",
    "submission_df[\"bldgdepth\"] = uhi_df.iloc[indices][\"bldgdepth\"].values\n",
    "submission_df[\"lotarea\"] = uhi_df.iloc[indices][\"lotarea\"].values\n",
    "submission_df[\"residfar\"] = uhi_df.iloc[indices][\"residfar\"].values\n",
    "submission_df[\"commfar\"] = uhi_df.iloc[indices][\"commfar\"].values\n",
    "submission_df[\"facilfar\"] = uhi_df.iloc[indices][\"facilfar\"].values\n",
    "submission_df[\"garagearea\"] = uhi_df.iloc[indices][\"garagearea\"].values\n",
    "submission_df[\"strgearea\"] = uhi_df.iloc[indices][\"strgearea\"].values\n",
    "submission_df[\"factryarea\"] = uhi_df.iloc[indices][\"factryarea\"].values\n",
    "submission_df[\"assessland\"] = uhi_df.iloc[indices][\"assessland\"].values\n",
    "submission_df[\"yearbuilt\"] = uhi_df.iloc[indices][\"yearbuilt\"].values\n",
    "submission_df[\"yearalter1\"] = uhi_df.iloc[indices][\"yearalter1\"].values\n",
    "submission_df[\"yearalter2\"] = uhi_df.iloc[indices][\"yearalter2\"].values\n",
    "submission_df[\"temp_index\"] = uhi_df.iloc[indices][\"temp_index\"].values\n",
    "submission_df[\"PR_RENT\"] = uhi_df.iloc[indices][\"PR_RENT\"].values\n",
    "submission_df[\"P_RENT\"] = uhi_df.iloc[indices][\"P_RENT\"].values\n",
    "submission_df[\"OVERALL_RANK\"] = uhi_df.iloc[indices][\"OVERALL_RANK\"].values\n",
    "submission_df[\"OVERALL_SCORE\"] = uhi_df.iloc[indices][\"OVERALL_SCORE\"].values\n",
    "submission_df[\"P_OZONE\"] = uhi_df.iloc[indices][\"P_OZONE\"].values\n",
    "submission_df[\"PR_OZONE\"] = uhi_df.iloc[indices][\"PR_OZONE\"].values\n",
    "submission_df[\"PR_PM25\"] = uhi_df.iloc[indices][\"PR_PM25\"].values\n",
    "submission_df[\"P_PM25\"] = uhi_df.iloc[indices][\"P_PM25\"].values\n",
    "submission_df[\"NBE_SCORE\"] = uhi_df.iloc[indices][\"NBE_SCORE\"].values\n",
    "submission_df[\"NBE_RANK\"] = uhi_df.iloc[indices][\"NBE_RANK\"].values\n",
    "submission_df[\"POP\"] = uhi_df.iloc[indices][\"POP\"].values\n",
    "submission_df[\"PR_HRI\"] = uhi_df.iloc[indices][\"PR_HRI\"].values\n",
    "submission_df[\"F_HRI\"] = uhi_df.iloc[indices][\"F_HRI\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_t_f', 'am_hi_f', \n",
    "     'temp_index',\n",
    "     'PR_RENT', 'P_RENT', 'OVERALL_RANK', 'OVERALL_SCORE', 'P_OZONE','PR_OZONE',\n",
    "     'PR_PM25', 'P_PM25', 'NBE_SCORE', 'NBE_RANK', 'POP', 'PR_HRI', 'F_HRI'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bfaf3e7-de65-497a-8a7b-1d9d27c1ef03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "pm_t_f                              0.110948\n",
      "Wind_Speed_x_Building_Density       0.103453\n",
      "building_density_ratio              0.072428\n",
      "building_density_ratio_squared      0.069889\n",
      "building_density                    0.069213\n",
      "log_building_density_ratio          0.068802\n",
      "am_hi_f                             0.044326\n",
      "temp_deviation_smooth               0.042932\n",
      "building_density_LST_interaction    0.042255\n",
      "POP                                 0.025591\n",
      "wind_direction_merge_               0.022628\n",
      "log_LST                             0.020190\n",
      "LST                                 0.019944\n",
      "P_RENT                              0.019219\n",
      "NBE_RANK                            0.018366\n",
      "SAVI_LST_sqrt_diff                  0.017668\n",
      "relative_humidity_                  0.017350\n",
      "OVERALL_SCORE                       0.017265\n",
      "OVERALL_RANK                        0.016906\n",
      "NBE_SCORE                           0.016640\n",
      "PR_RENT                             0.015824\n",
      "temp_2m_                            0.014787\n",
      "temp_deviation                      0.013538\n",
      "Nearest_AirTemp_C                   0.013409\n",
      "solar_insolation_                   0.013228\n",
      "mean_temp                           0.012918\n",
      "Temp_Anomaly                        0.012702\n",
      "PR_HRI                              0.012384\n",
      "nearest_building_perimeter          0.010689\n",
      "temp_index                          0.010513\n",
      "nearest_building_area               0.010471\n",
      "log_building_perimeter              0.009890\n",
      "PR_PM25                             0.002859\n",
      "P_OZONE                             0.002707\n",
      "F_HRI                               0.002698\n",
      "PR_OZONE                            0.002686\n",
      "P_PM25                              0.002683\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "Wind_Speed_x_Building_Density       0.136211\n",
      "pm_t_f                              0.078421\n",
      "building_density_ratio_squared      0.072404\n",
      "building_density_ratio              0.060787\n",
      "building_density                    0.059972\n",
      "temp_deviation_smooth               0.049316\n",
      "solar_insolation_                   0.042893\n",
      "log_building_density_ratio          0.041776\n",
      "building_density_LST_interaction    0.033983\n",
      "POP                                 0.033306\n",
      "wind_direction_merge_               0.033059\n",
      "am_hi_f                             0.026954\n",
      "NBE_SCORE                           0.024512\n",
      "P_RENT                              0.022628\n",
      "relative_humidity_                  0.021673\n",
      "PR_RENT                             0.020247\n",
      "NBE_RANK                            0.019815\n",
      "LST                                 0.019121\n",
      "log_LST                             0.018763\n",
      "Temp_Anomaly                        0.017792\n",
      "Nearest_AirTemp_C                   0.017533\n",
      "temp_2m_                            0.017510\n",
      "SAVI_LST_sqrt_diff                  0.014281\n",
      "PR_HRI                              0.014254\n",
      "OVERALL_RANK                        0.014033\n",
      "OVERALL_SCORE                       0.013254\n",
      "mean_temp                           0.011169\n",
      "temp_deviation                      0.011103\n",
      "log_building_perimeter              0.008660\n",
      "nearest_building_area               0.008493\n",
      "nearest_building_perimeter          0.008211\n",
      "temp_index                          0.007314\n",
      "P_PM25                              0.005157\n",
      "PR_PM25                             0.004537\n",
      "P_OZONE                             0.003970\n",
      "PR_OZONE                            0.003891\n",
      "F_HRI                               0.002997\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebb70e7d-4b35-49f1-a711-10c68e550595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/dc70y46s5qb_49mhx2v_52dc0000gn/T/ipykernel_12125/3625805466.py:16: DtypeWarning: Columns (59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  uhi_df = pd.read_csv(uhi_updated_path)\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.98370183 0.98575628 0.98044238        nan 0.98473427 0.98571755\n",
      " 0.98573096 0.98215978 0.9801704  0.98234587 0.98218285 0.98486082\n",
      " 0.9801297         nan 0.9860772  0.98139461 0.98562616 0.98561076\n",
      "        nan 0.98476528 0.9849118         nan 0.98379007 0.98609272\n",
      "        nan        nan 0.98237713 0.9848993         nan 0.98378322\n",
      "        nan 0.9862157  0.98566046 0.98477764 0.98382591 0.98557264\n",
      " 0.98623626        nan 0.98378322 0.98370183        nan 0.98529877\n",
      " 0.98556532 0.98573867        nan        nan 0.98530341 0.98541815\n",
      "        nan 0.98621681]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9939\n",
      "LightGBM R² Score: 0.9937\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.982893\n",
      "1    Out-of-Bag Score  0.986704\n",
      "2   Mean CV R-squared  0.840600\n",
      "3  Ensemble R-squared  0.958379\n",
      "\n",
      "Submission file saved to Submission248.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"Merged_UHI_HHI_Data.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission248.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f', 'am_hi_f', 'af_hi_f',\n",
    "     'pm_t_f', 'am_t_f', 'af_t_f',\n",
    "     'temp_index',\n",
    "     'PR_RENT', 'P_RENT', 'OVERALL_RANK', 'OVERALL_SCORE', 'P_OZONE','PR_OZONE',\n",
    "     'PR_PM25', 'P_PM25', 'NBE_SCORE', 'NBE_RANK', 'POP', 'PR_HRI', 'F_HRI'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Extract coordinates using the correct column names\n",
    "uhi_coords = uhi_df[['longitude', 'latitude']].values  # UHI dataset uses lowercase\n",
    "submission_coords = submission_df[['Longitude', 'Latitude']].values  # Submission dataset uses uppercase\n",
    "\n",
    "# Build a KDTree using UHI dataset\n",
    "uhi_tree = cKDTree(uhi_coords)\n",
    "\n",
    "# Query the KDTree for nearest neighbors\n",
    "_, indices = uhi_tree.query(submission_coords, k=1)  # k=1 ensures the nearest point is found\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f\"] = uhi_df.iloc[indices][\"pm_t_f\"].values\n",
    "submission_df[\"am_t_f\"] = uhi_df.iloc[indices][\"am_t_f\"].values\n",
    "submission_df[\"af_t_f\"] = uhi_df.iloc[indices][\"af_t_f\"].values\n",
    "submission_df[\"pm_hi_f\"] = uhi_df.iloc[indices][\"pm_hi_f\"].values\n",
    "submission_df[\"am_hi_f\"] = uhi_df.iloc[indices][\"am_hi_f\"].values\n",
    "submission_df[\"af_hi_f\"] = uhi_df.iloc[indices][\"af_hi_f\"].values\n",
    "submission_df[\"bldgarea\"] = uhi_df.iloc[indices][\"bldgarea\"].values\n",
    "submission_df[\"numfloors\"] = uhi_df.iloc[indices][\"numfloors\"].values\n",
    "submission_df[\"unitsres\"] = uhi_df.iloc[indices][\"unitsres\"].values\n",
    "submission_df[\"unitstotal\"] = uhi_df.iloc[indices][\"unitstotal\"].values\n",
    "submission_df[\"bldgfront\"] = uhi_df.iloc[indices][\"bldgfront\"].values\n",
    "submission_df[\"bldgdepth\"] = uhi_df.iloc[indices][\"bldgdepth\"].values\n",
    "submission_df[\"lotarea\"] = uhi_df.iloc[indices][\"lotarea\"].values\n",
    "submission_df[\"residfar\"] = uhi_df.iloc[indices][\"residfar\"].values\n",
    "submission_df[\"commfar\"] = uhi_df.iloc[indices][\"commfar\"].values\n",
    "submission_df[\"facilfar\"] = uhi_df.iloc[indices][\"facilfar\"].values\n",
    "submission_df[\"garagearea\"] = uhi_df.iloc[indices][\"garagearea\"].values\n",
    "submission_df[\"strgearea\"] = uhi_df.iloc[indices][\"strgearea\"].values\n",
    "submission_df[\"factryarea\"] = uhi_df.iloc[indices][\"factryarea\"].values\n",
    "submission_df[\"assessland\"] = uhi_df.iloc[indices][\"assessland\"].values\n",
    "submission_df[\"yearbuilt\"] = uhi_df.iloc[indices][\"yearbuilt\"].values\n",
    "submission_df[\"yearalter1\"] = uhi_df.iloc[indices][\"yearalter1\"].values\n",
    "submission_df[\"yearalter2\"] = uhi_df.iloc[indices][\"yearalter2\"].values\n",
    "submission_df[\"temp_index\"] = uhi_df.iloc[indices][\"temp_index\"].values\n",
    "submission_df[\"PR_RENT\"] = uhi_df.iloc[indices][\"PR_RENT\"].values\n",
    "submission_df[\"P_RENT\"] = uhi_df.iloc[indices][\"P_RENT\"].values\n",
    "submission_df[\"OVERALL_RANK\"] = uhi_df.iloc[indices][\"OVERALL_RANK\"].values\n",
    "submission_df[\"OVERALL_SCORE\"] = uhi_df.iloc[indices][\"OVERALL_SCORE\"].values\n",
    "submission_df[\"P_OZONE\"] = uhi_df.iloc[indices][\"P_OZONE\"].values\n",
    "submission_df[\"PR_OZONE\"] = uhi_df.iloc[indices][\"PR_OZONE\"].values\n",
    "submission_df[\"PR_PM25\"] = uhi_df.iloc[indices][\"PR_PM25\"].values\n",
    "submission_df[\"P_PM25\"] = uhi_df.iloc[indices][\"P_PM25\"].values\n",
    "submission_df[\"NBE_SCORE\"] = uhi_df.iloc[indices][\"NBE_SCORE\"].values\n",
    "submission_df[\"NBE_RANK\"] = uhi_df.iloc[indices][\"NBE_RANK\"].values\n",
    "submission_df[\"POP\"] = uhi_df.iloc[indices][\"POP\"].values\n",
    "submission_df[\"PR_HRI\"] = uhi_df.iloc[indices][\"PR_HRI\"].values\n",
    "submission_df[\"F_HRI\"] = uhi_df.iloc[indices][\"F_HRI\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f', 'am_hi_f', 'af_hi_f',\n",
    "     'pm_t_f', 'am_t_f', 'af_t_f',\n",
    "     'temp_index',\n",
    "     'PR_RENT', 'P_RENT', 'OVERALL_RANK', 'OVERALL_SCORE', 'P_OZONE','PR_OZONE',\n",
    "     'PR_PM25', 'P_PM25', 'NBE_SCORE', 'NBE_RANK', 'POP', 'PR_HRI', 'F_HRI'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74cf2a9e-cd08-4b28-ac58-07f28f7cf8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "af_t_f                              0.258617\n",
      "af_hi_f                             0.195860\n",
      "pm_hi_f                             0.067207\n",
      "Wind_Speed_x_Building_Density       0.061415\n",
      "pm_t_f                              0.053525\n",
      "building_density_ratio_squared      0.036664\n",
      "building_density_ratio              0.036294\n",
      "log_building_density_ratio          0.035734\n",
      "building_density                    0.029044\n",
      "building_density_LST_interaction    0.022264\n",
      "temp_deviation_smooth               0.021050\n",
      "am_t_f                              0.016276\n",
      "am_hi_f                             0.016197\n",
      "POP                                 0.016118\n",
      "NBE_SCORE                           0.012608\n",
      "P_RENT                              0.010595\n",
      "wind_direction_merge_               0.008778\n",
      "NBE_RANK                            0.008716\n",
      "OVERALL_SCORE                       0.007622\n",
      "OVERALL_RANK                        0.007077\n",
      "PR_RENT                             0.006995\n",
      "Nearest_AirTemp_C                   0.006126\n",
      "log_LST                             0.005914\n",
      "LST                                 0.005890\n",
      "SAVI_LST_sqrt_diff                  0.005273\n",
      "Temp_Anomaly                        0.004860\n",
      "PR_HRI                              0.004793\n",
      "mean_temp                           0.004422\n",
      "relative_humidity_                  0.004393\n",
      "temp_deviation                      0.004212\n",
      "temp_2m_                            0.004055\n",
      "solar_insolation_                   0.003957\n",
      "temp_index                          0.003363\n",
      "log_building_perimeter              0.002694\n",
      "nearest_building_area               0.002598\n",
      "nearest_building_perimeter          0.002326\n",
      "PR_PM25                             0.001572\n",
      "F_HRI                               0.001492\n",
      "P_PM25                              0.001407\n",
      "PR_OZONE                            0.001007\n",
      "P_OZONE                             0.000990\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "af_t_f                              0.330315\n",
      "af_hi_f                             0.124287\n",
      "Wind_Speed_x_Building_Density       0.107203\n",
      "building_density_ratio_squared      0.052462\n",
      "building_density                    0.045154\n",
      "building_density_ratio              0.035059\n",
      "log_building_density_ratio          0.028353\n",
      "temp_deviation_smooth               0.025834\n",
      "building_density_LST_interaction    0.025546\n",
      "solar_insolation_                   0.019949\n",
      "POP                                 0.016018\n",
      "wind_direction_merge_               0.014670\n",
      "P_RENT                              0.013253\n",
      "pm_t_f                              0.012669\n",
      "NBE_SCORE                           0.011562\n",
      "PR_RENT                             0.011284\n",
      "pm_hi_f                             0.010926\n",
      "Nearest_AirTemp_C                   0.010528\n",
      "OVERALL_RANK                        0.010031\n",
      "NBE_RANK                            0.009940\n",
      "relative_humidity_                  0.009554\n",
      "OVERALL_SCORE                       0.008919\n",
      "Temp_Anomaly                        0.008638\n",
      "temp_2m_                            0.007397\n",
      "SAVI_LST_sqrt_diff                  0.006357\n",
      "log_LST                             0.006172\n",
      "LST                                 0.005483\n",
      "am_t_f                              0.004884\n",
      "am_hi_f                             0.004843\n",
      "PR_HRI                              0.004464\n",
      "P_PM25                              0.004455\n",
      "PR_PM25                             0.003886\n",
      "log_building_perimeter              0.001696\n",
      "nearest_building_perimeter          0.001535\n",
      "mean_temp                           0.001441\n",
      "temp_deviation                      0.001270\n",
      "F_HRI                               0.001053\n",
      "temp_index                          0.000769\n",
      "PR_OZONE                            0.000745\n",
      "P_OZONE                             0.000708\n",
      "nearest_building_area               0.000689\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7da0091-82dd-40f7-a4c7-e4c6cf1bfd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/dc70y46s5qb_49mhx2v_52dc0000gn/T/ipykernel_12125/2747135514.py:16: DtypeWarning: Columns (59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  uhi_df = pd.read_csv(uhi_updated_path)\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.98461015 0.98599534 0.98228825        nan 0.98539605 0.98614932\n",
      " 0.98607977 0.98338322 0.98206918 0.98374199 0.98336366 0.98544352\n",
      " 0.98191746        nan 0.98621265 0.98281546 0.98602162 0.98591032\n",
      "        nan 0.98519569 0.9854426         nan 0.98464304 0.98637316\n",
      "        nan        nan 0.98387045 0.98549027        nan 0.98467962\n",
      "        nan 0.98648535 0.98615586 0.98539119 0.9846659  0.98586066\n",
      " 0.98648699        nan 0.98467962 0.98461015        nan 0.9857976\n",
      " 0.98586524 0.98594889        nan        nan 0.98580164 0.98576149\n",
      "        nan 0.98648566]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9932\n",
      "LightGBM R² Score: 0.9946\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.983026\n",
      "1    Out-of-Bag Score  0.986885\n",
      "2   Mean CV R-squared  0.862830\n",
      "3  Ensemble R-squared  0.959652\n",
      "\n",
      "Submission file saved to Submission249.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"Merged_UHI_HHI_Data.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission249.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f', 'am_hi_f', 'af_hi_f',\n",
    "     'pm_t_f', 'am_t_f', 'af_t_f',\n",
    "     'temp_index',\n",
    "     'PR_RENT', 'P_RENT', 'OVERALL_RANK', 'OVERALL_SCORE',\n",
    "     'NBE_SCORE', 'NBE_RANK', 'POP', 'PR_HRI'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Extract coordinates using the correct column names\n",
    "uhi_coords = uhi_df[['longitude', 'latitude']].values  # UHI dataset uses lowercase\n",
    "submission_coords = submission_df[['Longitude', 'Latitude']].values  # Submission dataset uses uppercase\n",
    "\n",
    "# Build a KDTree using UHI dataset\n",
    "uhi_tree = cKDTree(uhi_coords)\n",
    "\n",
    "# Query the KDTree for nearest neighbors\n",
    "_, indices = uhi_tree.query(submission_coords, k=1)  # k=1 ensures the nearest point is found\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f\"] = uhi_df.iloc[indices][\"pm_t_f\"].values\n",
    "submission_df[\"am_t_f\"] = uhi_df.iloc[indices][\"am_t_f\"].values\n",
    "submission_df[\"af_t_f\"] = uhi_df.iloc[indices][\"af_t_f\"].values\n",
    "submission_df[\"pm_hi_f\"] = uhi_df.iloc[indices][\"pm_hi_f\"].values\n",
    "submission_df[\"am_hi_f\"] = uhi_df.iloc[indices][\"am_hi_f\"].values\n",
    "submission_df[\"af_hi_f\"] = uhi_df.iloc[indices][\"af_hi_f\"].values\n",
    "submission_df[\"bldgarea\"] = uhi_df.iloc[indices][\"bldgarea\"].values\n",
    "submission_df[\"numfloors\"] = uhi_df.iloc[indices][\"numfloors\"].values\n",
    "submission_df[\"unitsres\"] = uhi_df.iloc[indices][\"unitsres\"].values\n",
    "submission_df[\"unitstotal\"] = uhi_df.iloc[indices][\"unitstotal\"].values\n",
    "submission_df[\"bldgfront\"] = uhi_df.iloc[indices][\"bldgfront\"].values\n",
    "submission_df[\"bldgdepth\"] = uhi_df.iloc[indices][\"bldgdepth\"].values\n",
    "submission_df[\"lotarea\"] = uhi_df.iloc[indices][\"lotarea\"].values\n",
    "submission_df[\"residfar\"] = uhi_df.iloc[indices][\"residfar\"].values\n",
    "submission_df[\"commfar\"] = uhi_df.iloc[indices][\"commfar\"].values\n",
    "submission_df[\"facilfar\"] = uhi_df.iloc[indices][\"facilfar\"].values\n",
    "submission_df[\"garagearea\"] = uhi_df.iloc[indices][\"garagearea\"].values\n",
    "submission_df[\"strgearea\"] = uhi_df.iloc[indices][\"strgearea\"].values\n",
    "submission_df[\"factryarea\"] = uhi_df.iloc[indices][\"factryarea\"].values\n",
    "submission_df[\"assessland\"] = uhi_df.iloc[indices][\"assessland\"].values\n",
    "submission_df[\"yearbuilt\"] = uhi_df.iloc[indices][\"yearbuilt\"].values\n",
    "submission_df[\"yearalter1\"] = uhi_df.iloc[indices][\"yearalter1\"].values\n",
    "submission_df[\"yearalter2\"] = uhi_df.iloc[indices][\"yearalter2\"].values\n",
    "submission_df[\"temp_index\"] = uhi_df.iloc[indices][\"temp_index\"].values\n",
    "submission_df[\"PR_RENT\"] = uhi_df.iloc[indices][\"PR_RENT\"].values\n",
    "submission_df[\"P_RENT\"] = uhi_df.iloc[indices][\"P_RENT\"].values\n",
    "submission_df[\"OVERALL_RANK\"] = uhi_df.iloc[indices][\"OVERALL_RANK\"].values\n",
    "submission_df[\"OVERALL_SCORE\"] = uhi_df.iloc[indices][\"OVERALL_SCORE\"].values\n",
    "submission_df[\"P_OZONE\"] = uhi_df.iloc[indices][\"P_OZONE\"].values\n",
    "submission_df[\"PR_OZONE\"] = uhi_df.iloc[indices][\"PR_OZONE\"].values\n",
    "submission_df[\"PR_PM25\"] = uhi_df.iloc[indices][\"PR_PM25\"].values\n",
    "submission_df[\"P_PM25\"] = uhi_df.iloc[indices][\"P_PM25\"].values\n",
    "submission_df[\"NBE_SCORE\"] = uhi_df.iloc[indices][\"NBE_SCORE\"].values\n",
    "submission_df[\"NBE_RANK\"] = uhi_df.iloc[indices][\"NBE_RANK\"].values\n",
    "submission_df[\"POP\"] = uhi_df.iloc[indices][\"POP\"].values\n",
    "submission_df[\"PR_HRI\"] = uhi_df.iloc[indices][\"PR_HRI\"].values\n",
    "submission_df[\"F_HRI\"] = uhi_df.iloc[indices][\"F_HRI\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f', 'am_hi_f', 'af_hi_f',\n",
    "     'pm_t_f', 'am_t_f', 'af_t_f',\n",
    "     'temp_index',\n",
    "     'PR_RENT', 'P_RENT', 'OVERALL_RANK', 'OVERALL_SCORE',\n",
    "     'NBE_SCORE', 'NBE_RANK', 'POP', 'PR_HRI'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f9791ce-a49e-4dcc-bf45-089e7444b1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "af_t_f                              0.300913\n",
      "af_hi_f                             0.185218\n",
      "pm_hi_f                             0.067789\n",
      "Wind_Speed_x_Building_Density       0.062703\n",
      "pm_t_f                              0.055280\n",
      "building_density_ratio_squared      0.037056\n",
      "building_density_ratio              0.031122\n",
      "building_density                    0.030138\n",
      "log_building_density_ratio          0.029116\n",
      "building_density_LST_interaction    0.018041\n",
      "temp_deviation_smooth               0.017531\n",
      "am_hi_f                             0.015837\n",
      "POP                                 0.015567\n",
      "am_t_f                              0.013882\n",
      "NBE_SCORE                           0.011133\n",
      "NBE_RANK                            0.010898\n",
      "P_RENT                              0.008541\n",
      "PR_RENT                             0.008278\n",
      "wind_direction_merge_               0.008065\n",
      "OVERALL_SCORE                       0.007118\n",
      "OVERALL_RANK                        0.006964\n",
      "relative_humidity_                  0.005626\n",
      "SAVI_LST_sqrt_diff                  0.005222\n",
      "LST                                 0.005089\n",
      "log_LST                             0.004908\n",
      "Nearest_AirTemp_C                   0.004841\n",
      "Temp_Anomaly                        0.004623\n",
      "PR_HRI                              0.004091\n",
      "temp_deviation                      0.003844\n",
      "mean_temp                           0.003639\n",
      "solar_insolation_                   0.003275\n",
      "temp_2m_                            0.003002\n",
      "nearest_building_area               0.002908\n",
      "temp_index                          0.002767\n",
      "log_building_perimeter              0.002520\n",
      "nearest_building_perimeter          0.002457\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "af_t_f                              0.334564\n",
      "af_hi_f                             0.123735\n",
      "Wind_Speed_x_Building_Density       0.106373\n",
      "building_density_ratio_squared      0.055399\n",
      "building_density                    0.041475\n",
      "building_density_ratio              0.040523\n",
      "building_density_LST_interaction    0.027690\n",
      "log_building_density_ratio          0.026797\n",
      "temp_deviation_smooth               0.026135\n",
      "solar_insolation_                   0.025498\n",
      "POP                                 0.016719\n",
      "wind_direction_merge_               0.015952\n",
      "NBE_SCORE                           0.013474\n",
      "pm_hi_f                             0.012437\n",
      "pm_t_f                              0.012238\n",
      "P_RENT                              0.011575\n",
      "PR_RENT                             0.011557\n",
      "Temp_Anomaly                        0.011254\n",
      "NBE_RANK                            0.009360\n",
      "Nearest_AirTemp_C                   0.009173\n",
      "OVERALL_SCORE                       0.008983\n",
      "relative_humidity_                  0.007887\n",
      "OVERALL_RANK                        0.007597\n",
      "temp_2m_                            0.006506\n",
      "LST                                 0.006254\n",
      "log_LST                             0.005407\n",
      "SAVI_LST_sqrt_diff                  0.005333\n",
      "am_t_f                              0.004759\n",
      "PR_HRI                              0.004219\n",
      "am_hi_f                             0.003386\n",
      "log_building_perimeter              0.001571\n",
      "nearest_building_perimeter          0.001474\n",
      "mean_temp                           0.001389\n",
      "temp_deviation                      0.001265\n",
      "nearest_building_area               0.001241\n",
      "temp_index                          0.000802\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7781050-d748-41d9-af21-5c7d619ec0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/dc70y46s5qb_49mhx2v_52dc0000gn/T/ipykernel_12125/3499605581.py:16: DtypeWarning: Columns (59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  uhi_df = pd.read_csv(uhi_updated_path)\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "55 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.98479306 0.98608452 0.98256224        nan 0.98479306 0.98575342\n",
      " 0.98621401 0.98223153 0.98255233 0.98259131 0.98214048 0.98487045\n",
      " 0.98246476        nan 0.98608452 0.98148656 0.98565882 0.98592054\n",
      "        nan 0.98485668 0.9848989         nan 0.98490594 0.98611854\n",
      "        nan        nan 0.9824856  0.98491146        nan 0.9848989\n",
      "        nan 0.98653497 0.98618772 0.98554966 0.98491146 0.98599064\n",
      " 0.98634036        nan 0.9848989  0.98479306        nan 0.98589854\n",
      " 0.98600608 0.98601047        nan        nan 0.9859565  0.98587097\n",
      "        nan 0.98622514]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9912\n",
      "LightGBM R² Score: 0.9942\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.968005\n",
      "1    Out-of-Bag Score  0.986922\n",
      "2   Mean CV R-squared  0.846916\n",
      "3  Ensemble R-squared  0.953136\n",
      "\n",
      "Submission file saved to Submission250.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"Merged_UHI_HHI_Data.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission250.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f', 'am_hi_f', 'af_hi_f',\n",
    "     'pm_t_f', 'am_t_f', 'af_t_f',\n",
    "     'temp_index',\n",
    "     'PR_RENT', 'P_RENT',\n",
    "     'NBE_SCORE', 'NBE_RANK', 'POP', 'PR_HRI'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Extract coordinates using the correct column names\n",
    "uhi_coords = uhi_df[['longitude', 'latitude']].values  # UHI dataset uses lowercase\n",
    "submission_coords = submission_df[['Longitude', 'Latitude']].values  # Submission dataset uses uppercase\n",
    "\n",
    "# Build a KDTree using UHI dataset\n",
    "uhi_tree = cKDTree(uhi_coords)\n",
    "\n",
    "# Query the KDTree for nearest neighbors\n",
    "_, indices = uhi_tree.query(submission_coords, k=1)  # k=1 ensures the nearest point is found\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f\"] = uhi_df.iloc[indices][\"pm_t_f\"].values\n",
    "submission_df[\"am_t_f\"] = uhi_df.iloc[indices][\"am_t_f\"].values\n",
    "submission_df[\"af_t_f\"] = uhi_df.iloc[indices][\"af_t_f\"].values\n",
    "submission_df[\"pm_hi_f\"] = uhi_df.iloc[indices][\"pm_hi_f\"].values\n",
    "submission_df[\"am_hi_f\"] = uhi_df.iloc[indices][\"am_hi_f\"].values\n",
    "submission_df[\"af_hi_f\"] = uhi_df.iloc[indices][\"af_hi_f\"].values\n",
    "submission_df[\"bldgarea\"] = uhi_df.iloc[indices][\"bldgarea\"].values\n",
    "submission_df[\"numfloors\"] = uhi_df.iloc[indices][\"numfloors\"].values\n",
    "submission_df[\"unitsres\"] = uhi_df.iloc[indices][\"unitsres\"].values\n",
    "submission_df[\"unitstotal\"] = uhi_df.iloc[indices][\"unitstotal\"].values\n",
    "submission_df[\"bldgfront\"] = uhi_df.iloc[indices][\"bldgfront\"].values\n",
    "submission_df[\"bldgdepth\"] = uhi_df.iloc[indices][\"bldgdepth\"].values\n",
    "submission_df[\"lotarea\"] = uhi_df.iloc[indices][\"lotarea\"].values\n",
    "submission_df[\"residfar\"] = uhi_df.iloc[indices][\"residfar\"].values\n",
    "submission_df[\"commfar\"] = uhi_df.iloc[indices][\"commfar\"].values\n",
    "submission_df[\"facilfar\"] = uhi_df.iloc[indices][\"facilfar\"].values\n",
    "submission_df[\"garagearea\"] = uhi_df.iloc[indices][\"garagearea\"].values\n",
    "submission_df[\"strgearea\"] = uhi_df.iloc[indices][\"strgearea\"].values\n",
    "submission_df[\"factryarea\"] = uhi_df.iloc[indices][\"factryarea\"].values\n",
    "submission_df[\"assessland\"] = uhi_df.iloc[indices][\"assessland\"].values\n",
    "submission_df[\"yearbuilt\"] = uhi_df.iloc[indices][\"yearbuilt\"].values\n",
    "submission_df[\"yearalter1\"] = uhi_df.iloc[indices][\"yearalter1\"].values\n",
    "submission_df[\"yearalter2\"] = uhi_df.iloc[indices][\"yearalter2\"].values\n",
    "submission_df[\"temp_index\"] = uhi_df.iloc[indices][\"temp_index\"].values\n",
    "submission_df[\"PR_RENT\"] = uhi_df.iloc[indices][\"PR_RENT\"].values\n",
    "submission_df[\"P_RENT\"] = uhi_df.iloc[indices][\"P_RENT\"].values\n",
    "submission_df[\"OVERALL_RANK\"] = uhi_df.iloc[indices][\"OVERALL_RANK\"].values\n",
    "submission_df[\"OVERALL_SCORE\"] = uhi_df.iloc[indices][\"OVERALL_SCORE\"].values\n",
    "submission_df[\"P_OZONE\"] = uhi_df.iloc[indices][\"P_OZONE\"].values\n",
    "submission_df[\"PR_OZONE\"] = uhi_df.iloc[indices][\"PR_OZONE\"].values\n",
    "submission_df[\"PR_PM25\"] = uhi_df.iloc[indices][\"PR_PM25\"].values\n",
    "submission_df[\"P_PM25\"] = uhi_df.iloc[indices][\"P_PM25\"].values\n",
    "submission_df[\"NBE_SCORE\"] = uhi_df.iloc[indices][\"NBE_SCORE\"].values\n",
    "submission_df[\"NBE_RANK\"] = uhi_df.iloc[indices][\"NBE_RANK\"].values\n",
    "submission_df[\"POP\"] = uhi_df.iloc[indices][\"POP\"].values\n",
    "submission_df[\"PR_HRI\"] = uhi_df.iloc[indices][\"PR_HRI\"].values\n",
    "submission_df[\"F_HRI\"] = uhi_df.iloc[indices][\"F_HRI\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "\n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'nearest_building_area',\n",
    "     'nearest_building_perimeter',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'relative_humidity_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_building_perimeter',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f', 'am_hi_f', 'af_hi_f',\n",
    "     'pm_t_f', 'am_t_f', 'af_t_f',\n",
    "     'temp_index',\n",
    "     'PR_RENT', 'P_RENT',\n",
    "     'NBE_SCORE', 'NBE_RANK', 'POP', 'PR_HRI'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4eee5b1b-7449-427f-b8fc-5e45ff2e5d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "af_t_f                              0.261223\n",
      "af_hi_f                             0.185089\n",
      "pm_hi_f                             0.073968\n",
      "Wind_Speed_x_Building_Density       0.062903\n",
      "pm_t_f                              0.061207\n",
      "building_density_ratio_squared      0.036833\n",
      "building_density_ratio              0.032626\n",
      "building_density                    0.031207\n",
      "log_building_density_ratio          0.030670\n",
      "building_density_LST_interaction    0.022622\n",
      "temp_deviation_smooth               0.021095\n",
      "am_hi_f                             0.017681\n",
      "POP                                 0.017144\n",
      "am_t_f                              0.014726\n",
      "NBE_RANK                            0.012450\n",
      "NBE_SCORE                           0.011845\n",
      "P_RENT                              0.011800\n",
      "PR_RENT                             0.011275\n",
      "wind_direction_merge_               0.008713\n",
      "Temp_Anomaly                        0.006721\n",
      "Nearest_AirTemp_C                   0.006578\n",
      "LST                                 0.006281\n",
      "SAVI_LST_sqrt_diff                  0.005978\n",
      "PR_HRI                              0.005942\n",
      "relative_humidity_                  0.005900\n",
      "log_LST                             0.005398\n",
      "temp_2m_                            0.004850\n",
      "solar_insolation_                   0.004825\n",
      "mean_temp                           0.004734\n",
      "temp_deviation                      0.004704\n",
      "temp_index                          0.003755\n",
      "nearest_building_area               0.003544\n",
      "log_building_perimeter              0.003005\n",
      "nearest_building_perimeter          0.002712\n",
      "dtype: float64\n",
      "\n",
      "Extra Trees Feature Importances:\n",
      "af_t_f                              0.333764\n",
      "af_hi_f                             0.125464\n",
      "Wind_Speed_x_Building_Density       0.108945\n",
      "building_density_ratio_squared      0.055092\n",
      "building_density                    0.048215\n",
      "building_density_ratio              0.036715\n",
      "temp_deviation_smooth               0.029919\n",
      "log_building_density_ratio          0.026395\n",
      "building_density_LST_interaction    0.023498\n",
      "solar_insolation_                   0.020647\n",
      "P_RENT                              0.019685\n",
      "POP                                 0.017256\n",
      "wind_direction_merge_               0.015784\n",
      "NBE_SCORE                           0.015292\n",
      "PR_RENT                             0.015205\n",
      "NBE_RANK                            0.011485\n",
      "pm_t_f                              0.011338\n",
      "Temp_Anomaly                        0.010501\n",
      "pm_hi_f                             0.010321\n",
      "Nearest_AirTemp_C                   0.010196\n",
      "relative_humidity_                  0.008262\n",
      "temp_2m_                            0.007578\n",
      "log_LST                             0.006650\n",
      "PR_HRI                              0.006031\n",
      "LST                                 0.005203\n",
      "am_t_f                              0.004634\n",
      "SAVI_LST_sqrt_diff                  0.004532\n",
      "am_hi_f                             0.004288\n",
      "temp_deviation                      0.001491\n",
      "nearest_building_perimeter          0.001445\n",
      "mean_temp                           0.001409\n",
      "log_building_perimeter              0.001199\n",
      "temp_index                          0.000833\n",
      "nearest_building_area               0.000731\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "rf_importances = pd.Series(importances_rf, index=feature_names).sort_values(ascending=False)\n",
    "et_importances = pd.Series(importances_et, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(rf_importances)\n",
    "\n",
    "print(\"\\nExtra Trees Feature Importances:\")\n",
    "print(et_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3328b26-d7d4-420d-b260-a844db2e4fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/dc70y46s5qb_49mhx2v_52dc0000gn/T/ipykernel_4708/1061573828.py:16: DtypeWarning: Columns (60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  uhi_df = pd.read_csv(uhi_updated_path)\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/helenhsu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.98612676 0.98622208 0.9853894         nan 0.98643043 0.98688172\n",
      " 0.98668833 0.9860195  0.98538463 0.98604638 0.98597046 0.98657783\n",
      " 0.98538482        nan 0.98630029 0.98570487 0.98675414 0.98609789\n",
      "        nan 0.98654524 0.98662546        nan 0.98620625 0.98675039\n",
      "        nan        nan 0.98610237 0.98660518        nan 0.98624909\n",
      "        nan 0.98669362 0.98664234 0.98635174 0.98619883 0.98628272\n",
      " 0.98685312        nan 0.98624909 0.98612676        nan 0.98664353\n",
      " 0.98633525 0.98613235        nan        nan 0.98671863 0.98623692\n",
      "        nan 0.9868744 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R² Score: 0.9921\n",
      "LightGBM R² Score: 0.9949\n",
      "\n",
      "Model Performance Metrics:\n",
      "               Metric     Score\n",
      "0           R-squared  0.988833\n",
      "1    Out-of-Bag Score  0.987113\n",
      "2   Mean CV R-squared  0.926308\n",
      "3  Ensemble R-squared  0.960562\n",
      "\n",
      "Submission file saved to Submission269.csv\n",
      "\n",
      "Feature importances saved to feature_importances.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# Load the Updated Dataset (Excluding Latitude & Longitude as Features)\n",
    "# -------------------------\n",
    "uhi_updated_path = \"Merged_UHI_HHI_HVI_GreenRoof_SVI_UHII_Data.csv\"\n",
    "submission_path = \"Submission_template.csv\"\n",
    "submission_updated_path = \"Submission269.csv\"\n",
    "\n",
    "uhi_df = pd.read_csv(uhi_updated_path)\n",
    "\n",
    "# Fix column names (remove special characters)\n",
    "uhi_df.columns = (\n",
    "    uhi_df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # Remove content in brackets\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Feature Engineering: Adding Interactions & Transformations\n",
    "# -------------------------\n",
    "uhi_df[\"building_density_ratio\"] = uhi_df[\"building_density\"] / (uhi_df[\"nearest_building_area\"] + 1)\n",
    "uhi_df[\"log_building_perimeter\"] = np.log1p(uhi_df[\"nearest_building_perimeter\"])\n",
    "uhi_df[\"log_LST\"] = np.log1p(uhi_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "uhi_df[\"log_building_density_ratio\"] = np.log1p(uhi_df[\"building_density_ratio\"])\n",
    "uhi_df[\"building_density_LST_interaction\"] = uhi_df[\"building_density\"] * uhi_df[\"LST\"]\n",
    "uhi_df[\"building_density_ratio_squared\"] = uhi_df[\"building_density_ratio\"] ** 2\n",
    "uhi_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(uhi_df[\"SAVI\"] - uhi_df[\"LST\"]))\n",
    "uhi_df[\"Wind_Speed_x_Building_Density\"] = uhi_df[\"avg_wind_speed_merge_\"] * uhi_df[\"building_density\"]\n",
    "\n",
    "uhi_df[\"temp_range\"] = uhi_df[\"af_hi_f\"] - uhi_df[\"af_t_f\"]  \n",
    "uhi_df[\"am_pm_temp_diff\"] = uhi_df[\"pm_t_f\"] - uhi_df[\"am_t_f\"]  \n",
    "uhi_df[\"hi_temp_diff\"] = uhi_df[\"af_hi_f\"] - uhi_df[\"am_hi_f\"] \n",
    "uhi_df[\"weighted_temp\"] = (0.6 * uhi_df[\"af_t_f\"]) + (0.4 * uhi_df[\"pm_t_f\"])\n",
    "uhi_df[\"temp_rate_change\"] = (uhi_df[\"af_t_f\"] - uhi_df[\"am_t_f\"]) / 12  \n",
    "\n",
    "# -------------------------\n",
    "# Feature Selection (Excludes Latitude & Longitude)\n",
    "# -------------------------\n",
    "X = uhi_df[\n",
    "    ['LST',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f', 'am_hi_f', 'af_hi_f',\n",
    "     'pm_t_f', 'am_t_f', 'af_t_f',\n",
    "     'temp_index',\n",
    "     'temp_range', 'am_pm_temp_diff', 'hi_temp_diff', 'weighted_temp', 'temp_rate_change'\n",
    "     ]\n",
    "]\n",
    "y = uhi_df[\"UHI_Index\"]\n",
    "\n",
    "# -------------------------\n",
    "# Train-Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# -------------------------\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, oob_score=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, cv=5, n_iter=50, \n",
    "    scoring=\"r2\", n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Use the Best Model\n",
    "# -------------------------\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Model Evaluation\n",
    "# -------------------------\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "oob_score = best_rf.oob_score_\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring=\"r2\")\n",
    "mean_cv_score = cv_scores.mean()\n",
    "\n",
    "# -------------------------\n",
    "# Ensemble Learning (Extra Trees)\n",
    "# -------------------------\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=500, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R² Score: {r2_xgb:.4f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")\n",
    "\n",
    "# Combine Predictions (Averaging Random Forest & Extra Trees)\n",
    "y_pred_ensemble_test = (\n",
    "    0.2 * best_rf.predict(X_test) +\n",
    "    0.6 * extra_trees.predict(X_test) +\n",
    "    0.1 * xgb_model.predict(X_test) +\n",
    "    0.1 * lgb_model.predict(X_test)\n",
    ")\n",
    "\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble_test)\n",
    "\n",
    "# -------------------------\n",
    "# Display Model Performance\n",
    "# -------------------------\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Metric\": [\"R-squared\", \"Out-of-Bag Score\", \"Mean CV R-squared\", \"Ensemble R-squared\"],\n",
    "    \"Score\": [r2, oob_score, mean_cv_score, r2_ensemble]\n",
    "})\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# -------------------------\n",
    "# Update Submission File with Predictions (Excluding Lat/Lon as Features)\n",
    "# -------------------------\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Extract coordinates using the correct column names\n",
    "uhi_coords = uhi_df[['longitude', 'latitude']].values  # UHI dataset uses lowercase\n",
    "submission_coords = submission_df[['Longitude', 'Latitude']].values  # Submission dataset uses uppercase\n",
    "\n",
    "# Build a KDTree using UHI dataset\n",
    "uhi_tree = cKDTree(uhi_coords)\n",
    "\n",
    "# Query the KDTree for nearest neighbors\n",
    "_, indices = uhi_tree.query(submission_coords, k=1)  # k=1 ensures the nearest point is found\n",
    "\n",
    "# Assign nearest features from UHI dataset to submission file\n",
    "submission_df[\"NDVI\"] = uhi_df.iloc[indices][\"NDVI\"].values\n",
    "submission_df[\"EVI\"] = uhi_df.iloc[indices][\"EVI\"].values\n",
    "submission_df[\"GNDVI\"] = uhi_df.iloc[indices][\"GNDVI\"].values\n",
    "submission_df[\"SAVI\"] = uhi_df.iloc[indices][\"SAVI\"].values\n",
    "submission_df[\"NDBI\"] = uhi_df.iloc[indices][\"NDBI\"].values\n",
    "submission_df[\"MNDWI\"] = uhi_df.iloc[indices][\"MNDWI\"].values\n",
    "submission_df[\"NDWI\"] = uhi_df.iloc[indices][\"NDWI\"].values\n",
    "submission_df[\"LSWI\"] = uhi_df.iloc[indices][\"LSWI\"].values\n",
    "submission_df[\"BI\"] = uhi_df.iloc[indices][\"BI\"].values\n",
    "submission_df[\"Albedo\"] = uhi_df.iloc[indices][\"Albedo\"].values\n",
    "submission_df[\"IBI\"] = uhi_df.iloc[indices][\"IBI\"].values\n",
    "submission_df[\"LST\"] = uhi_df.iloc[indices][\"LST\"].values\n",
    "submission_df[\"nearest_building_area\"] = uhi_df.iloc[indices][\"nearest_building_area\"].values\n",
    "submission_df[\"nearest_building_perimeter\"] = uhi_df.iloc[indices][\"nearest_building_perimeter\"].values\n",
    "submission_df[\"building_density\"] = uhi_df.iloc[indices][\"building_density\"].values\n",
    "submission_df[\"elevation_\"] = uhi_df.iloc[indices][\"elevation_\"].values\n",
    "submission_df[\"temp_2m_\"] = uhi_df.iloc[indices][\"temp_2m_\"].values\n",
    "submission_df[\"relative_humidity_\"] = uhi_df.iloc[indices][\"relative_humidity_\"].values\n",
    "submission_df[\"avg_wind_speed_merge_\"] = uhi_df.iloc[indices][\"avg_wind_speed_merge_\"].values\n",
    "submission_df[\"max_wind_speed_merge_\"] = uhi_df.iloc[indices][\"max_wind_speed_merge_\"].values\n",
    "submission_df[\"wind_speed_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_speed_stddev_merge_\"].values\n",
    "submission_df[\"wind_direction_merge_\"] = uhi_df.iloc[indices][\"wind_direction_merge_\"].values\n",
    "submission_df[\"wind_direction_stddev_merge_\"] = uhi_df.iloc[indices][\"wind_direction_stddev_merge_\"].values\n",
    "submission_df[\"solar_insolation_\"] = uhi_df.iloc[indices][\"solar_insolation_\"].values\n",
    "submission_df[\"mean_temp\"] = uhi_df.iloc[indices][\"mean_temp\"].values\n",
    "submission_df[\"temp_deviation\"] = uhi_df.iloc[indices][\"temp_deviation\"].values\n",
    "submission_df[\"temp_deviation_smooth\"] = uhi_df.iloc[indices][\"temp_deviation_smooth\"].values\n",
    "submission_df[\"Nearest_AirTemp_C\"] = uhi_df.iloc[indices][\"Nearest_AirTemp_C\"].values\n",
    "submission_df[\"Temp_Anomaly\"] = uhi_df.iloc[indices][\"Temp_Anomaly\"].values\n",
    "submission_df[\"pm_t_f\"] = uhi_df.iloc[indices][\"pm_t_f\"].values\n",
    "submission_df[\"am_t_f\"] = uhi_df.iloc[indices][\"am_t_f\"].values\n",
    "submission_df[\"af_t_f\"] = uhi_df.iloc[indices][\"af_t_f\"].values\n",
    "submission_df[\"pm_hi_f\"] = uhi_df.iloc[indices][\"pm_hi_f\"].values\n",
    "submission_df[\"am_hi_f\"] = uhi_df.iloc[indices][\"am_hi_f\"].values\n",
    "submission_df[\"af_hi_f\"] = uhi_df.iloc[indices][\"af_hi_f\"].values\n",
    "submission_df[\"bldgarea\"] = uhi_df.iloc[indices][\"bldgarea\"].values\n",
    "submission_df[\"numfloors\"] = uhi_df.iloc[indices][\"numfloors\"].values\n",
    "submission_df[\"unitsres\"] = uhi_df.iloc[indices][\"unitsres\"].values\n",
    "submission_df[\"unitstotal\"] = uhi_df.iloc[indices][\"unitstotal\"].values\n",
    "submission_df[\"bldgfront\"] = uhi_df.iloc[indices][\"bldgfront\"].values\n",
    "submission_df[\"bldgdepth\"] = uhi_df.iloc[indices][\"bldgdepth\"].values\n",
    "submission_df[\"lotarea\"] = uhi_df.iloc[indices][\"lotarea\"].values\n",
    "submission_df[\"residfar\"] = uhi_df.iloc[indices][\"residfar\"].values\n",
    "submission_df[\"commfar\"] = uhi_df.iloc[indices][\"commfar\"].values\n",
    "submission_df[\"facilfar\"] = uhi_df.iloc[indices][\"facilfar\"].values\n",
    "submission_df[\"garagearea\"] = uhi_df.iloc[indices][\"garagearea\"].values\n",
    "submission_df[\"strgearea\"] = uhi_df.iloc[indices][\"strgearea\"].values\n",
    "submission_df[\"factryarea\"] = uhi_df.iloc[indices][\"factryarea\"].values\n",
    "submission_df[\"assessland\"] = uhi_df.iloc[indices][\"assessland\"].values\n",
    "submission_df[\"yearbuilt\"] = uhi_df.iloc[indices][\"yearbuilt\"].values\n",
    "submission_df[\"yearalter1\"] = uhi_df.iloc[indices][\"yearalter1\"].values\n",
    "submission_df[\"yearalter2\"] = uhi_df.iloc[indices][\"yearalter2\"].values\n",
    "submission_df[\"temp_index\"] = uhi_df.iloc[indices][\"temp_index\"].values\n",
    "submission_df[\"PR_RENT\"] = uhi_df.iloc[indices][\"PR_RENT\"].values\n",
    "submission_df[\"P_RENT\"] = uhi_df.iloc[indices][\"P_RENT\"].values\n",
    "submission_df[\"OVERALL_RANK\"] = uhi_df.iloc[indices][\"OVERALL_RANK\"].values\n",
    "submission_df[\"OVERALL_SCORE\"] = uhi_df.iloc[indices][\"OVERALL_SCORE\"].values\n",
    "submission_df[\"P_OZONE\"] = uhi_df.iloc[indices][\"P_OZONE\"].values\n",
    "submission_df[\"PR_OZONE\"] = uhi_df.iloc[indices][\"PR_OZONE\"].values\n",
    "submission_df[\"PR_PM25\"] = uhi_df.iloc[indices][\"PR_PM25\"].values\n",
    "submission_df[\"P_PM25\"] = uhi_df.iloc[indices][\"P_PM25\"].values\n",
    "submission_df[\"NBE_SCORE\"] = uhi_df.iloc[indices][\"NBE_SCORE\"].values\n",
    "submission_df[\"NBE_RANK\"] = uhi_df.iloc[indices][\"NBE_RANK\"].values\n",
    "submission_df[\"POP\"] = uhi_df.iloc[indices][\"POP\"].values\n",
    "submission_df[\"PR_HRI\"] = uhi_df.iloc[indices][\"PR_HRI\"].values\n",
    "submission_df[\"F_HRI\"] = uhi_df.iloc[indices][\"F_HRI\"].values\n",
    "submission_df[\"HVI\"] = uhi_df.iloc[indices][\"HVI\"].values\n",
    "submission_df[\"gr_area\"] = uhi_df.iloc[indices][\"gr_area\"].values\n",
    "submission_df[\"bldg_area\"] = uhi_df.iloc[indices][\"bldg_area\"].values\n",
    "submission_df[\"prop_gr\"] = uhi_df.iloc[indices][\"prop_gr\"].values\n",
    "submission_df[\"heightroof\"] = uhi_df.iloc[indices][\"heightroof\"].values\n",
    "submission_df[\"groundelev\"] = uhi_df.iloc[indices][\"groundelev\"].values\n",
    "submission_df[\"NBAI\"] = uhi_df.iloc[indices][\"NBAI\"].values\n",
    "submission_df[\"UHII_Value\"] = uhi_df.iloc[indices][\"UHII_Value\"].values\n",
    "\n",
    "\n",
    "# Feature Engineering for Submission Data\n",
    "submission_df[\"building_density_ratio\"] = submission_df[\"building_density\"] / (submission_df[\"nearest_building_area\"] + 1)\n",
    "submission_df[\"log_building_perimeter\"] = np.log1p(submission_df[\"nearest_building_perimeter\"])\n",
    "submission_df[\"log_LST\"] = np.log1p(submission_df[\"LST\"])  # log(LST + 1) to avoid log(0)\n",
    "submission_df[\"log_building_density_ratio\"] = np.log1p(submission_df[\"building_density_ratio\"])\n",
    "submission_df[\"building_density_LST_interaction\"] = submission_df[\"building_density\"] * submission_df[\"LST\"]\n",
    "submission_df[\"building_density_ratio_squared\"] = submission_df[\"building_density_ratio\"] ** 2\n",
    "submission_df[\"SAVI_LST_sqrt_diff\"] = np.sqrt(np.abs(submission_df[\"SAVI\"] - submission_df[\"LST\"]))\n",
    "submission_df[\"Wind_Speed_x_Building_Density\"] = submission_df[\"avg_wind_speed_merge_\"] * submission_df[\"building_density\"]\n",
    "submission_df[\"temp_range\"] = submission_df[\"af_hi_f\"] - submission_df[\"af_t_f\"]  \n",
    "submission_df[\"am_pm_temp_diff\"] = submission_df[\"pm_t_f\"] - submission_df[\"am_t_f\"]  \n",
    "submission_df[\"hi_temp_diff\"] = submission_df[\"af_hi_f\"] - submission_df[\"am_hi_f\"] \n",
    "submission_df[\"weighted_temp\"] = (0.6 * submission_df[\"af_t_f\"]) + (0.4 * submission_df[\"pm_t_f\"])\n",
    "submission_df[\"temp_rate_change\"] = (submission_df[\"af_t_f\"] - submission_df[\"am_t_f\"]) / 12  \n",
    "\n",
    "# Select Features for Prediction (Excluding Lat/Lon)\n",
    "X_submission = submission_df[\n",
    "    ['LST',\n",
    "     'building_density',\n",
    "     'temp_2m_',\n",
    "     'wind_direction_merge_',\n",
    "     'solar_insolation_',\n",
    "     'building_density_ratio',\n",
    "     'log_LST',\n",
    "     'log_building_density_ratio',\n",
    "     'building_density_LST_interaction',\n",
    "     'building_density_ratio_squared',\n",
    "     'SAVI_LST_sqrt_diff',\n",
    "     'Wind_Speed_x_Building_Density', \n",
    "     'mean_temp', 'temp_deviation', 'temp_deviation_smooth',\n",
    "     'Nearest_AirTemp_C', 'Temp_Anomaly',\n",
    "     'pm_hi_f', 'am_hi_f', 'af_hi_f',\n",
    "     'pm_t_f', 'am_t_f', 'af_t_f',\n",
    "     'temp_index',\n",
    "     'temp_range', 'am_pm_temp_diff', 'hi_temp_diff', 'weighted_temp', 'temp_rate_change'\n",
    "     ]\n",
    "]\n",
    "\n",
    "# Predict UHI Index for Submission File\n",
    "submission_df[\"UHI Index\"] = (\n",
    "    0.2*best_rf.predict(X_submission) + 0.6*extra_trees.predict(X_submission) + 0.1*xgb_model.predict(X_submission) \n",
    "    + 0.1*lgb_model.predict(X_submission)\n",
    ")\n",
    "\n",
    "# Save the Updated Submission File\n",
    "submission_df[['Longitude', 'Latitude', 'UHI Index']].to_csv(submission_updated_path, index=False)\n",
    "print(f\"\\nSubmission file saved to {submission_updated_path}\")\n",
    "\n",
    "# Extract feature importances\n",
    "importances_rf = best_rf.feature_importances_\n",
    "importances_et = extra_trees.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature importances\n",
    "feature_names = X.columns\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Random Forest Importance': importances_rf,\n",
    "    'Extra Trees Importance': importances_et\n",
    "})\n",
    "\n",
    "# Sort by Random Forest importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by=\"Random Forest Importance\", ascending=False)\n",
    "\n",
    "# Save feature importances to CSV\n",
    "feature_importance_df.to_csv(\"feature_importances269.csv\", index=False)\n",
    "print(\"\\nFeature importances saved to feature_importances.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
